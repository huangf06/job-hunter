{
  "source": "LinkedIn",
  "profile": "all",
  "scraped_at": "2026-02-05T01:48:34.661493",
  "total_jobs": 49,
  "with_jd": 49,
  "jobs": [
    {
      "title": "Machine Learning Manager - GenAI Foundation Models",
      "company": "Booking.com",
      "location": "Amsterdam, North Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4362462847/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.302616",
      "description": "About the job\n\nAbout Us: At Booking.com, data drives our decisions. Technology is at our core. And innovation is everywhere. But our company is more than datasets, lines of code or A/B tests. We’re the thrill of the first night in a new place. The excitement of the next morning. The friends you encounter. The journeys you take. The sights you see. And the memories you make. Through our products, partners and people, we make it easier for everyone to experience the world.\n\nLeadership/Team Quote:\n\nThe team is at the forefront of Generative AI innovation, driving solutions for travel-related chatbots, text generation and summarization applications, Q&A systems, and free-text search.\n\nThe team you are applying to is spearheading a research effort to develop leading LLMs, specifically designed for the travel domain.\n\nThis pioneering initiative combines cutting-edge AI research with practical applications, focusing on creating tailored solutions that redefine how travelers plan, book, and experience their journeys.\n\nRole Description:\n\nIn this role, you will lead a team of Machine Learning Scientists and Engineers dedicated to building, training, and deploying cutting-edge Generative AI models. This includes developing foundation models trained on Booking.com’s extensive textual data and creating fine-tuned models designed to tackle complex travel-related tasks. Your leadership will play a pivotal role in advancing the application of AI to transform the travel experience for millions of customers.\n\nAs a technical manager, you should be passionate about GenAI technology, keep up to date with recent breakthroughs in the field, define and shape the team’s ML roadmap, and not be afraid to get your hands dirty with code when needed.\n\nYou are expected to be the focal point for all technical aspects, make sure your team members deliver on their tasks, and work together with other stakeholders to define and shape the roadmap of our products. You will work independently and will also be responsible for making technical decisions within your team.\n\nWhen it comes to management, your expertise in handling people will motivate and inspire them to reach outstanding success! You should have experience in developing people. You will mentor and coach your team while working closely with a Product Manager.\n\nKey Job Responsibilities and Duties:\n\nLeadership in LLM Development- Build, Guide and mentor a team of ML scientists and ML engineers in the development, fine-tuning, and deployment of large language models (LLMs) tailored for the travel domain.\nExpertise in the engineering aspects of deploying LLMs at scale with minimal latency. This includes optimizing model performance, scalability, and efficiency to meet the demands of real-time, high-traffic applications.\nDefine and communicate the technical vision and strategy for LLM-related initiatives, ensuring alignment with company goals and customer needs.\nFoster a culture of collaboration, innovation, and excellence within the team.\nPrioritize work in collaboration with Product Managers, depending on business needs and keeping stakeholders aligned at all times.\nTranslate machine learning vision and strategy into planning and execution, and ensure timely delivery of their plans.\nDevelop innovative ML models, algorithms, and engineering approaches or identify existing ones, with the potential to impact our business.\nDesign and execute applied research plans to understand, apply, test, evolve, and generalize these technologies into reusable frameworks.\nTranslate business problems into viable, reliable and robust ML and AI solutions, accounting for constraints of the production environment.\nMonitor product health, performance and business impact and act accordingly when requirements are not met.\nIdentify underlying issues and opportunities across domains and situations that are not obviously related through application of structured thinking and logic.\nSolve issues by applying methods and insights gained from a variety of disciplines, navigating a variety of environments.\nMake things happen by maintaining motivation and conveying a sense of urgency, focusing on outcomes and accomplishments, while respecting the need to balance long- and short-term goals, by applying influencing techniques and decision making skills.\nDrive, coach and mentor others through evidence and clear communication, explaining advanced technical concepts in simpler terms.\nContinuously evolve your craft. Keep up to date with industry and academic standard methodologies, periodically explore new technologies, introduce them to the machine learning community and promote their application in areas where they can generate impact.\nActively contribute to Machine Learning at Booking.com through training, exploration of new technologies, interviewing, onboarding and mentoring colleagues.\nPush for improvements, scaling and extending machine learning tooling and infrastructure, collaborating with central teams.\n\nQualification",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data EngineerData Engineer",
      "company": "Ariad",
      "location": "Amsterdam Area (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4367165381/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.361294",
      "description": "About the job\n\nOur client is a global leader in consumer electronics, known for its cutting-edge innovation and data-driven approach to digital transformation. As data becomes increasingly central to business strategy, this role offers a unique opportunity to shape the future of data infrastructure and analytics within a fast-paced, high-impact environment.\n\nOur client is looking for a technically skilled and collaborative professional to join their team as a Data Engineer. In this role, you will be responsible for building and optimising data pipelines, enabling AI workflows, and supporting data visualisation initiatives across multiple divisions.\n\nYou’ll work closely with another data engineer and collaborate with stakeholders across business, marketing, analytics, and global teams. If you’re passionate about data architecture, automation, and driving innovation, we encourage you to apply for this opportunity.\n\nWhat you will be doing:\n\nDesign and maintain scalable data engineering pipelines using GCP, Azure, and local servers.\nTransform raw data into clean, reusable datasets for business analysts and stakeholders.\nAutomate ETL/ELT processes to ensure data accuracy and relevance.\nPerform data aggregation, filtering, and manipulation to support business needs.\nTroubleshoot and maintain BI tools and guide junior team members.\nManage data warehouse governance and access control.\nDevelop and document technical architecture and security standards.\nSupport dashboard and report creation using BI tools like Power BI.\nCollaborate with stakeholders to align data solutions with business goals.\nPromote data-driven strategies in an accessible and intuitive way across teams.\n\nWhat you bring:\n\nAmbition to further develop your career in data engineering and analytics.\nProven experience in data engineering, data warehousing, and BI (3+ years).\nPast experience in the consumer electronics industry is a plus.\nYour strengths include ETL, data modelling, and cloud computing.\nWorking experience with tools such as Python, SQL, Airflow, dbt, Power BI, and cloud platforms (GCP, Azure, Databricks) is essential.\nStrong stakeholder management and communication skills are needed in this job.\nFluent in English; Dutch is a plus.\nExperience with Git, CI/CD, Linux, and Office tools (Excel, Word, PowerPoint).\nAbility to manage multiple projects and build strong relationships across teams.\nPreferred: experience with RPA, web scraping, real-time pipelines, and GitHub page management.\n\nThe offer:\n\nLong term Contractor collaboration. Mission of 12months with possibilities of extensions.\nDigital recruitment process and onboarding to the company.\nWork for a well-known global brand with a strong presence in the consumer electronics market.\nYou will have the opportunity to work with a collaborative and innovative team focused on data excellence.\nWorking from home: Flexible remote possibilities depending on team needs.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Machine Learning EngineerMachine Learning Engineer",
      "company": "Group-IB",
      "location": "EMEA (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4359539000/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.422005",
      "description": "About the job\n\nWe are looking for an experienced Machine Learning Engineer to strengthen our Fraud Protection team within a multinational cybersecurity company. The primary mission of this role is to analyze banking transactions to detect and prevent fraud and to enhance existing fraud detection algorithms.\n\nA key focus of the position is graph-based transactional analysis, including identifying complex relationships in financial data such as cryptocurrency flows. You may also contribute to broader graph-related tasks, for example building GraphRAG components for AI-driven agents.\n\nTech Stack\n\nPython 3.8+\nData analysis & modeling: pandas, scikit-learn, PyTorch\nGraph libraries/frameworks: NetworkX, PyG, Neo4j, AWS Neptune (any of these)\nDatabases (nice to have): Elasticsearch, Cassandra, ClickHouse\nGit, Docker\nAWS ecosystem\n\nResponsibilities\n\nIdentify and formalize scenarios to be covered by the transactional antifraud system, especially in the AML domain.\nConduct research on cutting-edge ML models and techniques for fraud and anomaly detection in transactional data.\nBuild ML models (classic, graph-based, neural networks) and integrate them into the Fraud Protection platform.\nDevelop production-ready source code (primarily in Python; Go experience is a plus).\nDocument and present research findings.\n\nThis role is perfect for you if you:\n\nHave a solid foundation in transactional data analysis.\nUnderstand neural networks (CNNs, RNNs, etc.), classical ML algorithms, and where to apply them—especially Graph ML (node embeddings, link prediction, GNNs).\nHave hands-on experience with frameworks such as PyTorch or Keras/TensorFlow.\nAre proficient in both IDE-based and terminal-based development.\nHave experience designing and building ETL pipelines.\nHave a research-oriented mindset and enjoy experimentation.\n\nPreferred:\n\nStrong documentation and presentation skills.\nExperience with MLOps practices.\nExperience writing production-ready asynchronous Python code.\n\nWhy choose Group-IB\n\nYour happiness is important to us. We want every single team member to be happy.\nContinuing professional development. At Group-IB, you can choose from various paths to growth: progress as an expert, advance to a management position, try your hand in another department, relocate abroad, or launch a new business area at Group-IB.\nA team with extensive international expertise. Do you have experience but are looking for exciting challenges? By choosing us, you will be choosing complex tasks and continuously improving your skills in a fast-growing international company.\nGlobally recognized technologies. Group-IB's offices are located in seven countries and our products and services are sold in 60 countries. What’s more, Gartner, IDC, and Forrester have ranked our technologies among the best in their class. We work with over 450 international partners and about 500 clients.\nA culture created by each of us. Group-IB’s employees speak many different languages and understand one another. We respect each other's beliefs, share common values, and strive toward the happiness of every employee.\nEconomic stability. Group-IB's sustainable growth helps rapidly develop careers that would take years to progress as far as most other companies.\n\nWhat else you should know\n\nHealth. If anything goes wrong, don’t worry — we offer health insurance.\nCertificates and training courses. Group-IB specialists hold over 1,000 professional certificates, including CEH, CISSP, OSCP, GIAC, MCFE, BSI, as well as some rare ones that would be a source of pride for experts in forensics, penetration testing, and reverse engineering worldwide. We have an incentive program that helps employees achieve certifications at the company's expense.\nChallenges. A wide selection of GIB programs helps you improve soft skills, gain new competencies, and receive monetary rewards.\nThe initiative is rewarded. At Group-IB, you can bring your most daring ideas to life. The company encourages technical blogging, writing articles, building sports teams, and other creative activities.\n\nSounds like you? Apply now!",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Senior Data Engineer",
      "company": "Team EIFFEL",
      "location": "Arnhem, Gelderland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4368766479/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.487005",
      "description": "About the job\n\nAls Data Engineer bij EIFFEL verbind je systemen en mensen. Je bouwt bruggen tussen complexe data en waardevolle inzichten. Bij ons bepaal jij hoe je jezelf ontwikkelt - of je nu specialist wordt in één domein of verschillende technieken verkent.\n\nDit ga je doen\n\nData stroomt door elke organisatie. Jij zorgt dat deze data op de juiste plek landt en bruikbaar wordt voor de business. Je werkt aan uitdagende projecten bij grote organisaties zoals de Rabobank, waar je datawarehouse-omgevingen ontwikkelt.\n\nJe verzamelt en beheert data uit verschillende bronnen zoals databases, logbestanden en externe API's;\nJe werkt met moderne tools en technieken zoals SQL, Python, Cloudplatforms Azure/AWS, Snowflake;\nJe ontsluit databronnen voor eindgebruikers zoals in uiteenlopende sectoren;\nJe transformeert en modelleert data zodat het direct toepasbaar is voor BI-analyses;\nJe gebruikt jouw basiskennis van BI-tools voor een optimale samenwerking met analisten;\nJe hebt bij voorkeur kennis van dimensioneel modelleren;\nJe bouwt mee aan onze dienstverlening en begeleidt actief junior en medior consultants.\n\nJe bent fit for the job als je...\n\nEen ervaren professional bent die verder kijkt dan de techniek. Je ziet kansen voor verbetering en pakt ze met beide handen aan.\n\nMinimaal 5 jaar werkervaring in een soortgelijke functie hebt;\nMinimaal een afgeronde hbo-opleiding richting Business IT & Management of vergelijkbaar hebt;\nRuime ervaring met ETL/ELT zoals Data factory, DBT, Airflow en Postman hebt;\nErvaring met (Restful) API developmen en data integraties hebt;\nErvaring met CI/CD en versiebeheer via GIT hebt;\nErvaring hebt met AVG-wetgeving en begrijpt hoe data hierin opgezet moet worden;\nIn het bezit bent van een rijbewijs B;\nBeschikt over communicatieve vaardigheden in het Nederlands, zowel mondeling als schriftelijk.\nFor English speaking candidates: our consultants need to be able to communicate in Dutch at a minimum of C1 level, spoken and written.\n\nDit krijg je van ons\n\nWe bieden een salaris tussen de €4.000,- en €7.000,- bruto per maand op basis van 40 uur per week passend bij jouw ervaring en expertise.\n\nDit zijn wij\n\nGroot in interim-capaciteit, steengoed in consultancy. We versterken organisaties precies waar het nodig is, of het nu gaat om een bank, gemeente of ziekenhuis. Door slimmer te werken. Door ideeën van papier naar praktijk te brengen. En door de juiste mensen op de juiste plek te zetten. Voor grote transformaties én snelle oplossingen. Van multinational tot start-up, als professional bij EIFFEL werk je overal.\n\nJe wordt onderdeel van Team Analytics, een groeiend team van gedreven professionals. Samen zetten jullie datagedreven werken centraal bij verschillende organisaties door heel Nederland. Bij EIFFEL wordt op vrijdagen een samenwerkdag gehanteerd in ons clubhuis in Arnhem. Deze staan in het teken van kennisdeling met collega's in het werkveld en binding houden met Team EIFFEL als werkgever. Kanttekening is dat wanneer de opdrachtgever jou op vrijdag verwacht bij hen op kantoor, dit uiteraard voor gaat.\n\nEIFFEL is onderdeel van Team EIFFEL, een community van 3000 experts in de wereld van interim, consultancy en projectmanagement. Met opdrachten in 24 kennisdomeinen bij 600 opdrachtgevers en meer trainingen dan je je kunt voorstellen, helpen onze Performance Managers jou een carrièrepad uit te stippelen dat zich naar jouw ambitie en levensfase vormt.\n\nDeze Skills Komen Van Pas\n\nSQL\nRESTful API development\nKennis van programma's en portfolio's\nKennis van BI-tools\nETL processen\n\nJe combineert technische expertise met sterke communicatieve vaardigheden. Je schakelt makkelijk tussen verschillende niveaus - van technisch specialist tot eindgebruiker. Je bent nieuwsgierig naar nieuwe ontwikkelingen en deelt graag kennis met collega's.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Senior Data EngineerSenior Data Engineer",
      "company": "Near.U",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4368757575/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.543121",
      "description": "About the job\n\nAbout Us\n\nWe are Near.U, We strive to develop our solutions by observing the best practices of our craft this means enabling our company to iterate our products fast and stay ahead. We are looking to grow our Team with a Senior Data Engineer.\n\nAbout the Role\n\nWe are looking for a Data Engineer to manage and evolve a Enterprise Data platform.\n\nYou will play a key role in technical operations, data platform evolution, and enterprise data projects, working closely with business and IT stakeholders in an agile environment.\n\nThis role combines operational responsibility with design, advisory, and continuous improvement activities on the Data platform.\n\nBecause we work with various customers, you are also expected to be able to adapt to different environments. Near.U is an international trademark of MoOngy with a very inclusive culture. We are looking for people that share those values with us and can work well across teams and individual roles.\n\nWhat You Bring To The Position\n\nProven experience as a Data Engineer in enterprise environments\nStrong experience with the Microsoft Data stack (e.g. Data Lake, Azure Data services, Power BI)\nHands-on experience with ETL/ELT pipelines, data transformation, and data modeling\nExperience operating and supporting production data platforms\nUnderstanding of data security, governance, and compliance principles\nExperience working in agile delivery models\nAbility to work autonomously while collaborating with distributed teams\nGood level of English.\n\nQualifications\n\nDegree in Computer Engineering or similar\n\nKey Responsibilities\n\nMonitor, maintain, and troubleshoot the Data environment using alerts and monitoring tools\nAct as an expert for problem resolution and platform enhancements during ongoing operations\nSupport and maintain the Data environment, including:\n\nETL / ELT pipelines\nData staging and transformation\nPower BI datasets and reports\nExcel-based sources migrating to a cloud-based data mart\n\nContribute to the continuous improvement of the Data platform and data engineering best practices\nParticipate in the selection, design, and development of the Data Lake and integrated application architecture\nDefine and improve interfaces between source systems and the Data platform\nProvide design, exploration, and advisory support on data initiatives\nParticipate in enterprise Data projects as part of a data product team\nDeploy new Data products in an agile manner, contributing to backlog refinement, planning, and prioritization\nEnsure delivery aligns with business priorities and capacity constraints\nContribute to platform governance, administration, and change management\nEnsure a secure-by-design approach, staying up to date with data security standards and regulations\nEnsure architecture and development comply with internal and regulatory requirements\nDesign and implement automation and monitoring capabilities to improve operational performance\nEnsure reliable, secure, and efficient data operations supporting business and employee needs\nUndertake additional tasks assigned by management, with autonomy on the technical scope\nActively contribute to knowledge sharing and best practices within the data community\n\nPlease note: Our Engineering team is predominantly based in Portugal, nevertheless this position is currently also open to residents in EU.\n\nMoOngy Group is an Equal Opportunity employer. All applicants will be considered without regard for race, colour, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Computer Vision Engineer - MLOpsComputer Vision Engineer - MLOps",
      "company": "DeepRec.ai",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4369218686/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.601437",
      "description": "About the job\n\nComputer Vision Engineer - MLOps\n\nLocation: Remote - (Must be EU based)\n\nSalary: Base salary + equity\n\nWe are hiring a Computer Vision Engineer to join a robotics company building intelligent, flexible robots for real manufacturing environments. This role is focused on production systems. You will be working on perception pipelines that run 24/7 on deployed robotic cells.\n\nThe robots follow a modular architecture where new capabilities are continuously added, such as object recognition, grasp point estimation, anomaly detection, and task specific behaviours. As the system scales, the ML and MLOps foundations become critical. This role exists to own and extend those foundations.\n\nWhat you will be doing\n\nDesign, build, and deploy 2D and 3D computer vision systems used in live production environments. This includes image classification, object detection, semantic and instance segmentation, metric learning, and smart filtering.\nTake models end to end, from data and training through to deployment, optimisation, and monitoring.\nContribute directly to an in house MLOps platform that supports data ingestion, experiment tracking, model versioning, deployment, and observability across multiple robotic capabilities.\nWork closely with robotics and hardware focused teams and help ensure models run efficiently and reliably on edge and production hardware. Over time, this includes model conversion and optimisation using tools such as ONNX and TensorRT.\n\nWhat we are looking for\n\nThis is a production engineering role. We are looking for someone who has built ML systems before.\n\nNon-negotiable experience:\n\nHands-on experience working with visual data in production systems (2D and/or 3D computer vision).\nProven production ML experience: you have taken models from training through deployment and supported them in live environments.\nStrong Linux fundamentals, including working over SSH and operating production infrastructure.\nYou have built MLOps systems, not just used them. This includes ownership of data pipelines, experiment tracking, model versioning, deployment, and monitoring.\nSolid understanding of how models actually work under the hood. You are comfortable reasoning about backpropagation, gradients, network architectures, and debugging model behaviour when things go wrong.\n\nNice to have:\n\nExperience with robotics, autonomous systems, or other edge-deployed ML.\nSynthetic data generation and the ability to design efficient data collection strategies.\nModel conversion and optimisation workflows using ONNX and/or TensorRT.\nExperience with ROS, Kubernetes, and cloud platforms.\n\nWhy apply?\n\nThis role offers a rare combination of real-world impact and deep technical ownership. You are not optimising isolated models or working on disconnected experiments. You are helping define the perception and MLOps foundations for intelligent robotic systems that are already operating in production and will continue to scale over time.\n\nEngineers work in pods with clear ownership and the opportunity to grow into leading entire problem areas. Progression and compensation are tied to impact rather than tenure. The environment is fast-moving and flexible, with intense periods of work when needed, and a strong emphasis on transparency and alignment.\n\nThis is a role for someone who wants to see their work move quickly from code to real machines on real factory floors.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Machine Learning EngineerMachine Learning Engineer",
      "company": "Deepdesk",
      "location": "Rotterdam, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4358897102/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:21.659396",
      "description": "About the job\n\nAbout Deepdesk\n\nDeepdesk builds real-time AI assistance that empowers customer service agents across chat, email, and voice. Our Agent Assist solution leverages cutting-edge machine learning, NLP, and voice technologies to deliver instant suggestions, rewriting, context understanding, and emerging agentic AI capabilities.\n\nWe are shaping the next generation of intelligent customer support through fast, production-grade systems that work seamlessly across multilingual and omnichannel environments.\n\nRole Overview\n\nWe’re looking for a Machine Learning Engineer to develop and optimise the ML intelligence behind Deepdesk’s Agent Assist platform. This role is perfect for someone who thrives in fast-paced, production environments and wants to work on impactful, real-time AI systems.\n\nYou’ll design and deploy ML/NLP models, enhance voice/STT pipelines, and collaborate closely with engineering to push the boundaries of agentic AI. Your work will directly improve how customer service agents communicate across chat, email, and voice.\n\nKey Responsibilities\n\nBuild and optimise ML and NLP models for real-time agent assist.\nDevelop algorithms for search, autocomplete, ranking, and rewriting.\nImplement and refine multilingual and omnichannel (text + voice) capabilities.\nIntegrate, tune, and deploy Speech-to-Text (STT) pipelines for voice-based use cases.\nRun experiments, model evaluations, and performance tuning.\nDesign scalable ML infrastructure, monitoring, and production-ready components.\nWork closely with engineering to shape new agentic AI workflows.\n\nMust-haves\n\nStrong Python development and algorithmic skills.\nExperience in ML or NLP (e.g., embeddings, classification, transformers).\nHands-on expertise with PyTorch or TensorFlow.\nAbility to build clean, reliable, production-grade ML components.\n\nNice-to-haves\n\nExperience with voice/STT models (Whisper, wav2vec2, DeepSpeech, etc.).\nBackground in agent assist, conversational AI, or agentic AI systems.\nFamiliarity with Kubeflow, MLOps, or Google Cloud Platform (GCP).\n\nTech Stack\n\nPython · TensorFlow · PyTorch · Scikit-learn · SpaCy · Kubeflow · GCP · Whisper / wav2vec2",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "AI Engineer",
      "company": "Solvinity",
      "location": "Amersfoort, Utrecht, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4358887291/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:24.358725",
      "description": "About the job\n\nAI is geen hype meer, maar een gamechanger. Bij Solvinity gaan we AI inzetten waar het écht verschil maakt: processen automatiseren, engineers ontlasten, en complexe vragen beantwoorden. Jij bent de engineer die dit mogelijk maakt. Je bouwt slimme integraties tussen ServiceNow, GitLab, security tooling en onze infrastructuur. Je creëert AI-agents die niet alleen taken uitvoeren, maar ook de context begrijpen.\n\nAls AI Engineer bij Solvinity ben je de pionier van een compleet nieuw vakgebied binnen ons bedrijf. Het team van engineers wordt door onze klanten geprezen, en jij gaat ervoor zorgen dat ze nóg effectiever hun werk kunnen doen. Dit doe je door slimme AI-oplossingen te bouwen die informatie uit verschillende systemen combineren en daarmee bruikbare inzichten geven en taken automatiseren.\n\nJe hebt een passie voor AI, maar je bent vooral pragmatisch. Je weet dat de mooiste AI-oplossing waardeloos is als hij niet betrouwbaar werkt of moeilijk te onderhouden is. Je combineert kennis van LLMs, prompt engineering, RAG-architecturen en MCP-servers met stevige development skills in Python. API-integraties en data-pipelines bouwen is voor jou second nature.\n\nJe pioniert graag, maar verliest niet uit het oog dat jouw oplossingen straks door anderen gebruikt en onderhouden moeten worden. Je denkt in producten, niet in proof-of-concepts. De vraag is niet óf je AI wilt toepassen, maar hoe je dat op een verantwoorde en effectieve manier doet. Je skillset ga je zeker nog verder ontwikkelen, want als Solvineer kun je dat!\n\nDe dag van een AI Engineer bij Solvinity is gevuld met uitdagende projecten: een mooie mix van onderzoek, ontwikkeling en integratie. Je bouwt AI-oplossingen die ons bedrijf slimmer maken:\n\nJe ontwikkelt slimme call routing en escalatie-mechanismen\nJe bouwt een AI-assistent die generieke vragen beantwoordt en aan onze knowledge base koppelt\nJe zorgt dat calls compleet zijn: de AI vraagt door als essentiële informatie ontbreekt\nJe ontwikkelt een contract agent die contractdetails doorzoekbaar maakt\n\"Welke contracten lopen de komende 6 maanden af?\" wordt een simpele vraag\nJe integreert AI met GitLab, Wireshark/pcap data en monitoring tooling\nDoor middel van integratie worden complexe vragen opeens snel beantwoord\n\nWat verwachten we van jou?\n\nSterke kennis van Python en moderne AI/ML frameworks (LangChain, OpenAI API, etc.)\nErvaring met LLMs, prompt engineering en RAG-architecturen\nBekend met API-integraties en het bouwen van data pipelines\nKennis van vector databases en semantic search\nErvaring met Git, CI/CD en containerization (Docker/Kubernetes)\nJe snapt hoe je AI-modellen evalueert en monitort\nJe denkt in producten en oplossingen, niet alleen in technologie\nJe bent pragmatisch: de beste oplossing is degene die werkt én onderhoudbaar is\nJe bent bewust van privacy, security en AI-ethics\nUitstekende Nederlandse en Engelse spreek- en schrijfvaardigheid\n\nWat krijg je:\n\n€ 3.822 - € 5997,- bruto p/m (afhankelijk van kennis en ervaring);\nBoeiend en uitdagend werk in een professionele werkomgeving waar collegialiteit en samenwerken de sfeer bepalen, en je je werkweek flexibel kunt invullen;\nSolvinity investeert in jouw ontwikkeling en het najagen van jouw passies met opleidingen en trainingen en geeft je de ruimte om je talenten te ontplooien;\nEen cultuur die innovatie, samenwerking en continue ontwikkeling bevordert;\n32 tot 40-urige werkweek;\nReiskostenvergoeding of thuiswerkvergoeding\nHybride werken vanuit huis en ons kantoor in Amersfoort\n80% pensioenbijdrage werkgever;\n26 vakantiedagen met de mogelijkheid tot uitbreiding;\nEen vitaliteitsregeling waarbij we tot 300 euro per jaar jouw sportactiviteiten financieren.\n\nGroeipad:\n\nSolvinity biedt ruime ontwikkelmogelijkheden aan, zoals functiegerelateerde basis- en loopbaanopleidingen. Na twee jaar in dienst heb je €1000 extra aan opleidingsbudget dat je zelf mag spenderen. Je kunt hierbij denken aan seminars, coaching, NLP of inhoudelijke cursussen, zo lang het maar in het bedrijfsbelang is. Jaarlijks bespreek je jouw persoonlijke opleidingsplan.\n\nWat zijn Solvineers?\n\nOnze mensen zijn IT-specialisten met een nieuwsgierige, kritische, slimme en coachende instelling. Maar een Solvineer heeft ook soft skills als empathie en teamgeest: we zijn allround teamspelers en hechte collega's. \"Nooit stoppen met leren\" is ons motto, daarom bieden we Solvineers trainingen, meet-ups en evenementen om op de hoogte te blijven en nieuwe vaardigheden te leren.\n\nHoe bereik je ons?\n\nPassen we bij elkaar? Wil je ons daarvan overtuigen? Reageer dan via de sollicitatiebutton of mail met Cynthia, onze Recruiter via recruitment@solvinity.com.\n\nWerken bij Solvinity\n\nSolvinity biedt Secure Managed Cloud Services, met name gericht op organisaties met hoge beveiligingseisen, waaronder de (rijks-)overheid, gemeenten en vooraanstaande financiële en zakelijke dienstverleners. We onderscheiden ons door innovatieve managed cloud oplossingen, cybersecurity-expertise en een ui",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data engineerData engineer",
      "company": "Alpina Group",
      "location": "Leusden, Utrecht, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4325187225/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:24.405326",
      "description": "About the job\n\nBen jij een ervaren data engineer die graag de toekomst van data binnen een groeiende organisatie vormgeeft? Jij speelt een sleutelrol bij de overgang van onze on-prem BI-omgevingen naar een moderne Azure Lakehouse-architectuur. Met jouw expertise zorg je voor stabiele dashboards en rapportages, terwijl je samen met collega’s de datastrategie van morgen bouwt.\n\nBij ons draait het niet alleen om wat je kunt, maar ook om wie je bent. Dus: ben jij die proactieve Data Engineer die met ons het verschil maakt?\n\nJouw rol in het team\n\nAls data engineer bij Alpina werk je aan de stabiliteit van onze bestaande Microsoft BI-omgeving én draag je bij aan de migratie naar Azure Lakehouse. Jij zorgt ervoor dat data betrouwbaar en beschikbaar is voor strategische inzichten.\n\nJij beheert en optimaliseert onze huidige on-prem Microsoft BI-omgevingen.\nJij ontwikkelt, onderhoudt en deployt SSIS-pakketten voor ETL-processen.\nJij werkt met SSRS en SSAS (Tabular en Multidimensional) en voert performance tuning uit.\nJij onderhoudt dimensionele modellen zoals star schema’s.\nJij ondersteunt de migratie naar een Azure Lakehouse omgeving en denkt mee over versiebeheer en CI/CD-trajecten.\n\nWat wij jou bieden\n\nEen werkweek van 32 tot 40 uur.\nDirect een arbeidsovereenkomst voor onbepaalde tijd.\nEen bruto maandsalaris van €5.021,- tot €6.275,- op basis van 40 uur.\nMogelijkheid tot hybride werken met als standplaats Leusden.\nEen leasefietsregeling.\nEen reiskostenvergoeding van € 0,21 per km met de auto, € 0,25 per km met de fiets of te voet, en reizen met het OV in de 2e klas wordt volledig vergoed.\n27 vakantiedagen als je 40 uur werkt.\nPersoonlijk Keuzebudget (PKB): Jij bepaalt zelf hoe je een deel van je arbeidsvoorwaarden inzet: meer verlof, extra salaris of een opleiding.\nAlpina Academy: Toegang tot trainingen, cursussen en opleidingen, o.a. op het gebied van vakkennis, AI, persoonlijke groei of leiderschap.\nKorting op financiële producten: Denk aan verzekeringen, hypotheken, taxaties en aan- of verkoop van je woning.\n\nMaak kennis met Alpina Group\n\nJij komt te werken binnen Alpina Group, een landelijk werkende organisatie met sterke regionale wortels. Je werkt in een dynamisch team van 16 collega’s verspreid over meerdere kantoren, met één maandelijkse samenkomst in Leusden. Het team is informeel, betrokken en innovatief, met ruimte voor eigen initiatief en verbetervoorstellen.\n\nMet 1.500 collega’s op ruim 40 locaties zorgt Alpina group dat klanten volledig worden ontzorgd in financiële dienstverlening. Geen stropdassenmentaliteit, maar een informele sfeer waarin ondernemerschap en proactiviteit belangrijker zijn dan hiërarchie. En met een doel: dat jij hier alles mag worden behalve ongelukkig.\n\nWat jij in huis hebt\n\nMinimaal 5 jaar relevante werkervaring in data engineering.\nAantoonbare ervaring met Microsoft SQL Server en het schrijven van geoptimaliseerde T-SQL queries.\nRuime ervaring met SSIS, SSRS en SSAS (Tabular/Multidimensional).\nGrondige kennis van datawarehousing en dimensioneel modelleren.\nProactieve houding en in staat om zelfstandig én in teamverband te werken aan dataoplossingen.\nGoede sociale vaardigheden en een uitstekende beheersing van de Nederlandse taal in woord en geschrift.\n\nWat we als pluspunt zien\n\nErvaring met migratie van SSRS-pakketten richting de cloud.\nErvaring met Git of andere versiebeheersystemen; kennis van CI/CD-trajecten.\nErvaring in en kennis van Azure DevOps.\nKennis van Databricks, DBT of Azure Data Factory.\n\nDurf jij het aan?\n\nSolliciteer vandaag nog of neem contact op met Demi Kemperman via telefoonnummer 06-51057153 voor meer informatie.\n\nAcquisitie naar aanleiding van deze advertentie wordt niet op prijs gesteld.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Principal AI EngineerPrincipal AI Engineer",
      "company": "Infogain Poland",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4358035249/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:24.452322",
      "description": "About the job\n\nProject Info\n\nWe are building a proprietary, industrial-grade AI platform to tackle the \"last mile\" of Generative AI: guaranteeing correctness in complex domains.\n\nWe are not looking for a \"Prompt Engineer\" or an API integrator. We are seeking a Research-Grade Engineer (Masters/PhD preferred) who combines deep theoretical knowledge of NLP with the ability to architect scalable, production-ready systems. You will function as the technical lead of this platform, working directly with the CTO to define the next generation of code intelligence.\n\nCurrent LLMs are excellent at creativity but struggle with the strict logical consistency required for enterprise software. Your challenge is to bridge this gap. You will design systems that can handle massive context windows, maintain semantic integrity across thousands of files, and deliver verifiable accuracy.\n\nYou will define the methodologies to constrain Generative AI with strict structural rules, answering the hard question: How do we build a system that possesses the flexibility of a neural network but the reliability of a compiler?\n\nResponsibilities\n\nArchitecture Design: Architect high-reliability inference systems that solve the \"hallucination problem\" inherent in Large Language Models. You will move beyond out-of-the-box solutions to build defensible, proprietary IP.\nAdvanced NLP Strategy: Define the strategy for domain adaptation and long-context reasoning. You will perform first-principles analysis to select the right approach (RAG, Fine-Tuning, or novel methods) based on rigorous benchmarking.\nEvaluation & Verification: Design and build proprietary evaluation frameworks to rigorously measure the performance and safety of our models before they touch client code.\nTechnical Standards: Mentor the engineering team on the mathematical underpinnings of Transformer architectures and current SOTA research.\n\nJob Requirements\n\nAdvanced Degree: Masters or PhD in Computer Science, AI, or related field (or equivalent top-tier research lab experience).\nAdvanced LLM Internals: You understand the specific failure modes of modern architectures regarding long-context recall, reasoning drift, and hallucination triggers in complex logic. You don't just fine-tune; you know how to mathematically constrain model outputs to ensure high-fidelity results.\nApplied Research: 8+ years of experience, with a track record of taking complex ML research and deploying it into production environments.\nBeyond APIs: Proven expertise in architecting autonomous agentic systems that go beyond simple retrieval. You have designed multi-agent orchestrators involving planning, tool use (function calling), and self-correction loops to solve multi-step reasoning problems reliably.\nEngineering Excellence: Strong proficiency in Python. You write clean, modular, object-oriented code, not just \"notebook scripts.\"\n\nPreferred Experience\n\nInterest in Code Generation, Program Analysis, or Semantic Parsing.\nExperience with open-source LLM orchestration (LangChain, DSPy, LlamaIndex) but with a critical understanding of their limitations.\nPublished research or technical blog posts on Applied NLP\n\nBenefits\n\nGeneral benefits - depends on the form of employment\n\nHybrid work model combining office & remote work\nAttractively located office with collaboration spaces\nOnsite parking space for employees\nReferral program with financial bonus\nLife Insurance\nBudget for development (including language courses and others), clear career path with the possibility to gain experience in international environment\nAccess to internal Learning Platform with multiple trainings oriented for professional growth\n\nLifestyle benefits:\n\nAccess to MyBenefit platform (Multisport included)\nTeam Building activities\nCharity initiatives\nWorking environment promoting diversity and inclusion\n\nHealth benefits:\n\nPrivate medical care - Platinum Package",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Lead Machine Learning Operations",
      "company": "Stedin",
      "location": "Rotterdam, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4369093876/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:24.497157",
      "description": "About the job\n\nDeze vacature is ingeschaald in schaal C10.\n\nJouw energie in de plus\n\nIn deze rol bepaal jij de technische koers van ons ML/AI platform en zorg je dat onze machine learning producten betrouwbaar, schaalbaar en toekomstbestendig zijn.\n\nWaarom Werken Bij Stedin Jou Energie Oplevert\n\nWerken aan een platform dat direct bijdraagt aan de energietransitie.\nGrote technische verantwoordelijkheid en ruimte om richting te bepalen.\nSamenwerken met ambitieuze data en ML experts binnen een groeiende data organisatie.\n\nWerk om trots op te zijn\n\nAls Lead ML Operations ben jij verantwoordelijk voor het technisch en operationeel eigenaarschap van ons ML/AI platform. Je borgt kwaliteit, stabiliteit en compliance, terwijl je het MLOps team inhoudelijk aanstuurt en ons platform continu doorontwikkelt. Zo speel je een cruciale rol in het realiseren van betrouwbare ML producten die Stedin helpen de energietransitie mogelijk te maken.\n\nEen dag als Lead ML Operations\n\nJe start met een sync met Data Office en bespreekt de nieuwste ontwikkelingen en impact daarvan op het platform.\nJe overlegt met het MLOps team over de nieuwe feature store opzet.\nJe stemt met het IT infra team af welke impact deze wijzigingen hebben op onze infrastructuur.\nJe luncht gezellig met collega’s buiten of in het bedrijfsrestaurant.\nJe werkt aan de kwartaalplanning met leads en product owners, beantwoordt mails en hebt een bila met een junior engineer.\n\nHier laad jij van op\n\nAlle financiële arbeidsvoorwaarden op een rij, weet je meteen waar je aan toe bent:\n\nEen bruto maandsalaris tussen € X.XXX,- en € X.XXX,- (bij 40 uur), 24,5 vakantiedagen en pensioenopbouw bij ABP waarbij wij 70% van de premie betalen.\nBovenop je salaris ontvang je een persoonlijk budget van 24% (incl. 8% vakantiegeld). In onze rekentool zie je hoe dit werkt.\nJaarlijks € 700,- (bruto) voor je eigen energie, zoals sport of vitaliteit.\nEen laptop en telefoon, of € 30,- netto per maand bij gebruik van je eigen telefoon.\n\nDaar komt dit nog bovenop\n\nModerne thuiswerkfaciliteiten plus € 2,40 thuiswerkvergoeding; we werken 50% thuis en 50% op kantoor.\nReizen met de ov vrijregeling of flexibele reisregeling – combineren mag.\nJouw ontwikkeling staat centraal: trainingen, opleidingen en events.\n\nVol energie vooruit met team Machine Learning\n\nJe komt te werken in het Machine Learning team binnen Data Office, een groeiende club experts op het gebied van Machine Learning, Artificial Intelligence en Data. We helpen elkaar verder met code reviews, technische sparsessies en veel samenwerking met business en IT teams. Je werkt afwisselend thuis en op kantoor in Rotterdam, waar een hechte en professionele sfeer hangt.\n\nMet deze kwaliteiten groei jij hier verder\n\nJe hebt visie, technisch leiderschap en kunt schakelen tussen strategie en detail. Je overziet afhankelijkheden, bewaakt kwaliteit en weet je team inhoudelijk te versterken.\n\nVerder Heb Je\n\nEen WO/HBO opleiding in Kunstmatige Intelligentie, Informatica of een vergelijkbaar vakgebied.\nMinimaal 5 jaar ervaring in data science en/of machine learning.\nExpert level skills in Python, Spark, Azure, Azure Data Lake Storage, Databricks, Kubernetes, Apache Airflow en MLOps tooling.\n\nZet de stap naar jouw volgende uitdaging\n\nWe kijken ernaar uit je te ontmoeten.\n\nDit Is Nog Goed Om Te Weten\n\nJe mag een motivatiebrief meesturen, dat hoeft niet.\nJe werkt in principe 40 uur per week; 32 uur is ook mogelijk.\nDe uiterste datum om te reageren voor deze vacature is 12 februari, reageer dus voor die tijd als je interesse hebt in de functie.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data Engineer BI Diverse Stafafdelingen",
      "company": "Nederlandse Spoorwegen",
      "location": "Utrecht, Utrecht, Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4368250536/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:24.542625",
      "description": "About the job\n\nWerken bij NS als data engineer betekent impact maken met data op duurzame mobiliteit en veiligheid, in een hecht multidisciplinair team, met sterke ontwikkelkansen.-\n\nDaarom wil je als Data Engineer werken bij NS\n\nAls data engineer bij NS werk je met moderne tools zoals Snowflake, Azure en Power BI binnen een gezellig scrumteam. Samen zorg je ervoor dat belangrijke informatie uit verschillende databronnen beschikbaar is voor dashboards, analyses en het nemen van goede beslissingen.\nJe draagt direct bij aan een data-gedreven NS en volop kansen om jezelf verder te ontwikkelen.\nMet je team maak je informatieproducten voor verschillende afdelingen, zoals Corporate Security en HRN CIS, waardoor je echt iets betekent voor het dagelijks reilen en zeilen bij NS.\n\n\"Jeroen: “Het mooiste aan deze functie is dat je met moderne data‑technologie direct bijdraagt aan miljoenen reizigers. Geen dag is hetzelfde, en in ons team helpen we elkaar continu groeien.”\"\n\nDit ga je doen als Data Engineer\n\nAls data engineer werk je samen met een multidisciplinair team, bestaande uit data engineers en informatieanalisten. Samen ontwikkel en onderhoud je informatieproducten voor diverse interne klanten binnen de Stafafdelingen van NS. Enkele voorbeelden hiervan zijn:\n\nCorporate Security: deze afdeling focust zich op de veiligheid van NS-terreinen en -gebouwen.\nInkoop: hier breng je in kaart waar NS geld aan uitgeeft, van een bos bloemen voor een zieke collega tot de aanschaf van een nieuwe trein.\nConcernhuisvesting: deze afdeling zorgt dat er parkeerplaatsen zijn voor het rijdend personeel en biedt ondersteuning, bijvoorbeeld als een koffieautomaat in storing raakt.\nHRN CIS (HoofdRailNet Concessie Informatie Systeem): NS heeft voor de concessieperiode 2025-2033 een informatiesysteem ingericht, waarin onder andere reizigerspunctualiteit en zitplaatskans per aankomststation worden vastgelegd en maandelijks gepubliceerd.\n\nAls Data Engineer werk je intensief samen met collega’s in de keten, zoals architecten, je eigen team, andere data teams binnen de afdeling en de business. Je vervult een essentiële rol in het bouw- en deliveryproces, waarbij je verantwoordelijk bent voor het ontwikkelen en in productie nemen van informatieproducten. Je denkt mee in oplossingen en stimuleert verbeteringen.\n\nJe bent door je leergierigheid, teamgeest, motivatie en je ‘aanpakken en doorpakken’-mentaliteit, van onschatbare waarde bij:\n\nHet ontsluiten van nieuwe databronnen, zowel gestructureerd als ongestructureerd.\nHet verwerken en modelleren van ontsloten data.\nHet ontwikkelen van datamarts op basis van deze data.\nHet uitvoeren van ETL/ELT-processen binnen Snowflake met SQL en Python.\nHet ontwerpen en realiseren van een effectief dataplatform van bron tot eindgebruiker.\nHet schrijven van robuuste code met controles voor verwerking en datakwaliteit.\nHet zorgen voor een vlekkeloze productielancering met geteste, gedocumenteerde oplossingen en monitoring.\nHet maken van dashboards en rapportages in Power BI, in nauwe samenwerking met gebruikers.\n\nHier ga je werken\n\nIn ons hoofdkantoor, op loopafstand van station Utrecht Centraal, of vanuit huis maak je deel uit van een zelf organiserend scrumteam binnen de afdeling Data, Innovatie & Analyse (DIA). Binnen DIA werkt een mix van ervaringen en persoonlijkheden, die elkaar graag opzoeken om met elkaar te sparren en kennis te delen. De afdeling geeft gebruikers betrouwbaar inzicht om tot juiste acties te komen door het verzamelen, combineren, analyseren en presenteren van informatie.\n\nBij NS vinden we diversiteit en inclusie belangrijk, het maakt samenwerken leuker en het resultaat wordt er vaak beter van. Wat jouw achtergrond of levensovertuiging is, maakt dan ook niet uit: we zijn vooral benieuwd naar jouw visie op de functie van Data Engineer.\n\nDit zijn de functie-eisen\n\nJe hebt een afgeronde HBO- of WO-opleiding en minstens drie jaar werkervaring als Data Engineer in een ETL/BI/DWH-omgeving.\nJe bent bekend met het visualiseren van data en hebt minstens drie jaar ervaring met Power BI, inclusief het werken met DAX en M-query.\nJe beschikt over aantoonbare kennis van object-, conceptueel en dimensioneel datamodelleren.\nJe hebt ruime ervaring met data-integratie, deployment automation, versiebeheer en ETL-processen, bijvoorbeeld met Azure Data Factory.\nJe hebt diepgaande kennis van Cloud DWH-oplossingen zoals Snowflake en SQL, en werkt vlot met Azure DevOps/GIT, CICD en Agile Scrum.\nJe bent communicatief sterk in het Nederlands, weet soepel te schakelen tussen business en techniek, neemt initiatief en betrekt anderen bij het behalen van doelen.\nJe bent kritisch, neemt verantwoordelijkheid voor sprintresultaten, ondersteunt je teamgenoten, en ziet het geven en ontvangen van feedback als een kans om samen te groeien.\n\nBij NS vinden we het belangrijk dat we elkaar durven aanspreken en ons altijd kunnen uitspreken. We zoeken collega’s met lef, die open staan voor verandering. Voor deze functie zijn dit a",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "BI Lead Business Data Engineer (NOT REMOTE)",
      "company": "Ricoh UK",
      "location": "Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4351594635/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:24.587565",
      "description": "About the job\n\nAbout The Role\n\nWe’re looking for a BI Lead Data Engineer to lead the design and delivery of our EMEA Supply Chain data and reporting infrastructure. You’ll build and oversee scalable, secure data pipelines and models using Microsoft Fabric and Azure, turning raw data into reliable, business-ready insights. This role bridges business and IT and plays a key role in how Ricoh makes data-driven decisions.\n\nWhat You will Do?\n\nDesign the data architecture across bronze, silver, gold layers.\nBuild and maintain data pipelines and semantic models in Azure and Microsoft Fabric as well as reports in PBI.\nEnsure data quality, governance, security, and performance.\nManage and mentor a small team of data engineers.\nCollaborate closely with Supply Chain, Finance, 3PLs, and IT teams.\nDrive the BI development roadmap and support reporting across 24 countries.\n\nWhat you bring?\n\n5+ years in BI/data engineering roles, with team leadership experience.preferably in an SC or manufacturing environment\nStrong knowledge of Azure Data Services, Microsoft Fabric, Power BI.\nIdeally experience with Snowflake, Phyton and DBT\nExperience in data modeling, governance, and pipeline development.\nAbility to work cross-functionally and translate business needs into data solutions.\nExcellent communication and problem-solving skills.\n\nWhat we offer:\n\nAs a BI Lead Data Engineer at Ricoh, you’ll enjoy:\n\nSalary based on experience (range: €4900 - €6800) with a performance-based bonus (max. 12%).\n25 vacation days + 6 ADV days\nTravel allowance and a solid pension scheme\nUnlimited access to e-learnings and opportunities for international growth\nAn innovative, international work environment focused on teamwork and continuous improvement\nA supportive, motivated team that values collaboration and impact\n\nWhy Ricoh?\n\nAt Ricoh, we empower digital workplaces with innovative technology. This is your chance to make a real impact in a collaborative, forward-thinking environment where data drives change across Europe.\n\nReady for the next step?\n\nIf you have any questions about the position, please contact Timothy (Recruiter) via\n\n📞 +31 6 15486346\n\n✉️timothy.van.thoff@ricoh.nl",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data Engineer",
      "company": "WeTravel",
      "location": "Amsterdam Area (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4369087594/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:29.812818",
      "description": "About the job\n\nHi! 👋 I’m Tara, BI Manager at WeTravel, based in the US 🇺🇸 I work closely with teams across Product, Finance, Sales, and Operations, and data sits at the center of almost everything we do. As WeTravel continues to grow globally, the complexity and importance of our data grows with it.\n\nWe’re looking for a curious, impact-driven Data Engineer to help us scale our data platform and make sure teams across the company can rely on clean, trustworthy, well-modeled data to do their best work.\n\nThis role is ideal for someone who enjoys building reliable systems, digging into messy data, and improving the foundations that analytics and decision-making depend on.\n\nAbout WeTravel\n\nWeTravel is building the leading booking and payments platform for group travel and multi-day tour operators.\n\nTravel organizers around the world use WeTravel to create trip proposals, manage bookings, and securely process payments, without relying on spreadsheets, emails, or fragmented tools. Our platform helps them focus on what matters most: creating meaningful travel experiences.\n\nAs WeTravel grows, data plays a critical role in how we understand our product, support our customers, and make better decisions across the business. From payments and revenue to product usage and subscriptions, reliable data is essential to everything we do.\n\nWhat’s the role\n\nThis Data Engineer role sits at the intersection of engineering and analytics, with a strong focus on data infrastructure, pipelines, and reliability.\n\nYou’ll work alongside our existing Data Engineer to design, build, and maintain the systems that move data from raw sources into our data warehouse, where it can be safely used by Analytics, Product, Finance, and Go-To-Market teams.\n\nThis is not an analytics or reporting role. Your primary responsibility is to ensure that data is accurate, available, and scalable, so others can confidently use it downstream.\n\nWhat you’ll do day-to-day\n\nDesign, build, and maintain scalable ELT/ETL pipelines ingesting data from product databases, third-party tools, and external partners\nOwn and evolve WeTravel’s data warehouse and data models to support analytics, dashboards, and downstream use cases\nEnsure data quality, reliability, and observability through testing, monitoring, documentation, and proactive issue detection\nSupport analytics and BI use cases related to subscriptions, payments, revenue, churn, and cohort analysis by delivering clean, well-structured data\nOptimize data performance, cost, and scalability as data volume and complexity grow\nEstablish and promote best practices for data modeling, naming conventions, and governance\nWork closely with Analytics, Product, Finance, and Engineering teams to translate data needs into durable, maintainable solutions\n\nWork is prioritized through a centralized process, so you can focus on execution and reliability rather than ad-hoc stakeholder requests.\n\nHow we work\n\nOur data team balances ownership with collaboration.\n\nYou’ll have autonomy to design and improve data infrastructure, while working closely with BI, Analytics, and Engineering partners to solve real business problems. We operate in bi-weekly sprints, prioritize work intentionally, and focus on building systems that are resilient and easy to maintain.\n\nWe care deeply about doing things the right way: clean data models, thoughtful documentation, and pipelines teams can trust. Your work will be visible, impactful, and used daily across the company.\n\nWe’re a growing team, still figuring things out, and we value people who are comfortable with that ambiguity and enjoy improving systems over time.\n\nYou should apply if you have\n\nBasic Qualifications\n\n3+ years of experience as a Data Engineer or in a role heavily focused on data pipelines and data warehouses\nStrong SQL skills and experience modeling data for analytics and reporting\nExperience with modern cloud data warehouses such as Snowflake, BigQuery, or Redshift\nFamiliarity with ELT tools like Fivetran or Airbyte, and transformation frameworks such as dbt\nProficiency in at least one programming language commonly used in data engineering, such as Python\nUnderstanding of data quality, testing, and monitoring concepts\nAbility to work independently, take initiative, and communicate clearly with non-technical partners\n\nNice to have\n\nExperience in SaaS, fintech, or subscription-based businesses\nFamiliarity with product analytics or experimentation data\nExposure to BI tools such as Tableau, Looker, or Mode\nExperience supporting metrics like MRR, churn, expansion, and cohort retention\nBackground in enabling self-serve analytics for business teams\n\nYou might not be the right fit if you\n\nAre primarily interested in analytics, dashboards, or reporting ownership\nPrefer highly structured environments with fixed processes and little ambiguity\nExpect to work mainly on greenfield architecture rather than improving existing systems\nAre uncomfortable owning production pipelines and being accountable ",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Senior Data EngineerSenior Data Engineer",
      "company": "Full Orbit",
      "location": "Haarlem, North Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4368305638/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:29.861623",
      "description": "About the job\n\nHeb jij een passie voor het ontwikkelen van dataoplossingen die daadwerkelijk bijdrage aan waarde voor de klant? Wil je meebouwen aan moderne datamanagement oplossingen en herken je zaken als Data Lake, Lakehouse en Data Warehouses? Ben je in staat om ML/AI concepten te vertalen naar daadwerkelijk werkende programmatuur?\n\nWij zijn op zoek naar een senior Data Engineer met een goed begrip van de verschillende concepten en een brede beheersing van relevante tools. Het gaat jou niet perse om de tools, maar om de oplossing. Heb jij een passie voor het vakgebied en een handson mentaliteit dan willen we je graag in ons team.\n\nWat ga je doen?\n\nAls Senior Data Engineer ontwerp, ontwikkel en beheer je geavanceerde data-oplossingen. Je zorgt ervoor dat onze klanten optimaal gebruikmaken van hun data. Je werkt aan:\n\nData ontsluiten uit diverse bronnen en het modelleren ervan\nHet opzetten van schaalbare infrastructuren met verschillende tools zoals MS Fabric, Azure Synapse, Databricks, Azure Data Factory, Oracle Data Integrator en Oracle OCI Data Integration\nHet creëren van krachtige inzichten met SQL, Python en visualisatie-tools zoals Power BI, Tableau en Qlik\nAdviseren over data-platformen en analytics\nCoachen van collega’s en bijdragen aan Agile-teams\nHybride werken: vanuit ons kantoor in Haarlem, bij de klant of thuis\n\nWat breng je mee?\n\nAfgeronde hbo- of wo-opleiding\nUitstekende beheersing van Nederlands en Engels\nMinimaal 5 jaar ervaring in een data-gedreven omgeving\nErvaring met Python, SQL, PL/SQL (pré)\nKennis van Data Factory, Data Fabric, Snowflake, Databricks en Oracle Data Integrator (pré)\nBekend met analytics-tools (Power BI, Tableau, Oracle Analytics)\nErvaring met cloudplatformen (Azure, AWS, GCP, Oracle OCI)\nInteresse/ervaring met AI (o.a. OpenAI, Oracle AI)\nKennis van data-opslagconcepten (Data Lake, Lakehouse, Data Mesh, etc.)\nErvaring met automatisering (CI/CD, Terraform, Ansible, scripting, API-first)\nBekwaam in data-modellering, governance, architectuur en security\n\nWat bieden we jou?\n\nAantrekkelijk salaris, afhankelijk van je vaardigheden en ervaring\nOpleidingen die aansluiten bij je carrierepad en regelmatig kennissessies\nEindjaarsbonus op basis van bedrijfsprestaties\nAantrekkelijke arbeidsvoorwaarden met keuzemogelijkheden\nMobiliteitsregeling: keuze voor leaseauto of vervoersbudget\nApple Laptop, mobiel abonnement\nTegemoetkoming bij de aanschaf van mobile en tablet\nNetto onkostenvergoeding\nThuiswerkregeling\nJaarlijks uitje",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data EngineerData Engineer",
      "company": "Online Payment Platform",
      "location": "Delft, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4368734200/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:29.908935",
      "description": "About the job\n\n3 reasons you should join our team as Data Engineer\n\nData is your playground - and ours too. With over 10 million users and billions of transactions per month, your work directly influences the decisions that shape OPP’s future.\nYou won’t just build pipelines - you’ll help shape the foundation of a brand-new data warehouse from scratch. This is your chance to leave a mark on a critical company-wide initiative.\nJoin a fast-growing fintech with all the right ingredients: a collaborative culture, tech-minded peers, and the energy of a scale-up - backed by Worldline.\n\nWhat started as five people, a small office, and a few nerf guns has now grown into one of Europe’s fastest-growing fintechs. With 150+ colleagues, offices in Delft, Berlin, and London, and Worldline as a partner, we have the perfect mix: the resources of a global player with the energy of a scale-up. At OPP, we build the technology that powers the next generation of e-commerce. From eBay to Ikea, billions in transactions already flow through our systems. We don’t just handle payments—we enable platforms to accept, hold, and disburse funds securely.\n\nAs a Data Engineer, you’ll join our dedicated data team in Delft, working closely with the CTO, Data Analysts, a Data Engineer, and the DevOps/Development team. Your primary mission? Build and deliver the ongoing initiative for a robust and scalable data warehouse to support better, faster decision-making. You’ll design and optimize data pipelines, ensure data quality, support data governance, and automate infrastructure with Terraform. In the short term, your focus will be on getting our data warehouse live. In the long-term, you'll enable analytics and data-driven strategies that help us outperform competitors and stay fast on our feet.\n\nYour track record tells us\n\nYou bring at least 5 years of experience in data (platform) engineering, preferably within high-traffic or fintech environments.\nYou have an Bachelors degree in a relevant technical field.\nYour toolbox includes advanced SQL (including window functions), Terraform, Python (Airflow, PySpark), and AWS services (Athena, Kinesis, Lambda).\nYou have strong experience with developing and maintaining robust data ingestion pipelines with APIs, cloud services, and third-party systems.\nYou’re familiar with data modeling (star/snowflake schemas) and GitLab CI/CD.\nYou take ownership of end-to-end data pipelines, value collaboration with data analysts and developers, and troubleshoot like a pro.\nDetail-oriented, proactive, and a team player who thrives in cross-functional setups.\n\nOur offer\n\nA total yearly salary of up to €95.000.\nA modern, flexible workplace with hybrid working.\n24 vacation days and 2 supercharge-me-days ⚡.\n12-month contract with the possibility of permanent extension.\nThe tools you need: a MacBook, home office setup, and NS Business Card.\nAn attractive bike plan if you work 24 hours or more.\nA developers-only office at Lange Geer 26, within walking distance of our sales and product teams in the heart of Delft.\nA great work atmosphere with catered lunches and regular team drinks.\n\nFrom contact to contract\n\nWant to know more about our projects?\n\nSend your credentials our way and let’s talk. More info? Direct your questions to Gijs Cooijmans at gijs.cooijmans@onlinepaymentplatform.com. Or give him a WhatsApp message at +31 6 20019821.\n\n👋 it's me Mike, your hiring manager for this role\n\nDid you know our APIs are called millions of times a day? Will you help keep our platform lightning-fast? Let’s connect!",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data EngineerData Engineer",
      "company": "SkillRecruit",
      "location": "Amsterdam, North Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4368718708/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:29.953621",
      "description": "About the job\n\nRole: Data Engineer\n\nLocations :Amsterdam ,Netherlands\n\nMinimum Experience: 8+\n\nType FTE\n\nSkill Set\n\nJava, spark, AWS, Web Services Rest API, Kafka, Data Engineering\n\nSkill to Evaluate\n\nJava, spark, Web Services Rest API, Kafka, Data Engineering, Snowflake, Python, SQL, AWS/Azure\n\nJob Description\n\nThe ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines that support our data analytics and machine learning initiatives. The Data Engineer will collaborate with cross-functional teams to ensure the availability, quality, and reliability of data across various platforms.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Principal ML Systems Engineer | GCP · MLOps · Applied ML | B2B · EU Remote | €80K - €100K",
      "company": "Joppy",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4368723457/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:29.999388",
      "description": "About the job\n\nOne of the companies we collaborate with at Joppy is looking for someone who doesn’t just train models, but builds and operates ML systems in production end-to-end.\n\nFull ownership: from understanding the business problem and engineering the data, to deploying, monitoring, and continuously improving models in real manufacturing and operational environments.\n\n🌍 Remote from anywhere in the EU\n\n✈️ One week per quarter in the USA (all expenses covered)\n\n🤝 B2B contract\n\n🔧 What you will actually do\n\nDesign predictive, prescriptive, and optimization models for maintenance, quality, and supply chain\nBuild data pipelines, feature pipelines, and inference services\nDeploy models as APIs, batch jobs, and streaming workloads in GCP\nImplement monitoring, drift detection, and retraining strategies\nTranslate ambiguous operational problems into measurable ML solutions\nWork closely with technical and operations teams\n\n🎯 Must-have\n\n10+ years across ML engineering, data engineering, and production systems\nProven experience delivering end-to-end ML systems beyond notebooks\nStrong background in classical ML and applied statistics (not LLM-centric)\nProduction-grade Python and strong SQL skills\nGCP experience: BigQuery, Dataflow/Beam, Airflow/Composer, Docker, Kubernetes\nHands-on MLOps, CI/CD, model versioning, and monitoring\nAbility to work under a B2B contract and travel to the USA quarterly\n\nAbout Joppy\n\nJoppy is a technology recruitment platform built for developers by developers.\n\n✅ No CV is required. Just say what you know and what you want.\n\n✅ Anonymous profile by default.\n\n✅ You choose who can talk to you. Companies cannot write to you until you accept their offer.\n\n✅ Only relevant offers that match your preferences. No more Javascript offers for Java developers.\n\n✅ Get rewarded if you get hired.\n\nKeep an eye on tech job opportunities anonymously and find the job that makes you happy.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "AI Engineer",
      "company": "Royal Terberg Group",
      "location": "Houten, Utrecht, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4346182717/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:30.051273",
      "description": "About the job\n\nAs an AI Engineer at Terberg Special Vehicles, you’ll work in a multidisciplinary product team on the innovative “Mechanic of the Future” platform.\n\nYour Impact\n\nDo you want to help shape the digital future of our service technicians? You’ll develop, integrate, and maintain advanced AI solutions that directly contribute to more efficient service, improved customer satisfaction, and a future-proof organization. You’ll have the freedom to pioneer, innovate, and truly make a difference within a family-owned company with international ambitions.\n\nWhat will you do?\n\nDesign, build, and maintain scalable data pipelines (batch and real-time) and retrieval-augmented generation (RAG) pipelines.\nIntegrate and manage data from diverse sources (cloud and on-premises), including setting up vector databases and embedding models.\nPerform data preprocessing, feature engineering, model training, and evaluation using Python, (No)SQL, (Py)Spark, Azure Data Factory, Databricks, and relevant AI/ML libraries.\nFine-tune and evaluate large language models (LLMs) for domain-specific tasks, including prompt engineering.\nApply CI/CD, version control, and documentation for structured and reproducible development.\nEnsure reliable, secure, and compliant data flows and AI models, following governance and ethical AI principles.\nMonitor and optimize the performance and cost-efficiency of data pipelines and AI models.\nCollaborate with software engineers, data scientists, product owners, and business stakeholders to deliver high-quality AI solutions.\nDocument model behavior, performance metrics, and decision logic for transparency and reproducibility.\n\nYour Profile\n\nBachelor’s or Master’s degree in a relevant field (Computer Science, Data Science, Software Engineering).\nAt least 3 years of experience as an AI/Data Engineer or similar role.\nExperience with Azure Data Factory, Databricks, Python, (No)SQL, (Py)Spark, and CI/CD.\nKnowledge of building and maintaining data pipelines, vector databases, and embedding models.\nProactive, independent, and strong communicator; you enjoy working in an agile team and take initiative.\nQuality, security, and compliance are important to you, and you are always looking for improvement and innovation.\n\nWhat do we offer?\n\nA key role in an innovative team shaping Terberg’s digital transformation.\nWork at a family-owned company with a friendly atmosphere, short lines of communication, and international ambitions.\nFriday afternoons off, excellent employment conditions according to the Metal & Technology Collective Labor Agreement.\nOpportunities for personal development via the Terberg Academy.\nHybrid working is possible.\nDirect influence on the future of our products and services.\n\nAs a colleague at Terberg, you will enjoy a great role at one of the most prominent and largest manufacturing companies in the Netherlands. We work from Monday to Friday morning, leaving Friday afternoons free. The atmosphere in our family-owned company is pleasant, and you’ll be part of a motivated team. We value your input, and your ideas are always heard. Staying up-to-date in your field is important to us; you’ll have access to numerous training and growth opportunities through the Terberg Academy. This position comes with an excellent benefits package and we adhere to the Metal and Technology Collective Labor Agreement (CAO).\n\nIs this your dreamjob?\n\nAre you the AI Engineer who will help us make the Mechanic of the Future a reality? Apply directly via our website or contact Bjorn Frank, 0031-6-42 52 27 74 for more information. You can also contact Diederik Stratenus at +31 6 51 49 12 05. We look forward to your contribution to our team!\n\nTerberg Special Vehicles is a global leader in the development, production, and service of specialized vehicles. As a family business, we have been committed to our people for over 150 years! Innovation is our strength, and sustainability is our answer. Since 2014, we have been investing in electrically powered vehicles and are actively testing hydrogen solutions. We aim to care for our environment responsibly so that future generations can also enjoy a good life on our planet.\n\nWe do not appreciate acquisition efforts in response to this vacancy. Unsolicited submissions of candidates will not be taken into consideration.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Principal Data Engineer - PerfectScale by DoiT",
      "company": "DoiT",
      "location": "Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4325427560/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:30.096273",
      "description": "About the job\n\nLocation\n\nOur Principal Data Engineer will be an integral part of our Engineering teams in EMEA. This role is based remotely as a full-time employee in the UK, Ireland, Estonia, the Netherlands, Sweden, and Israel. We are also open to contractors in East Europe and Portugal.\n\nWho We Are\n\nDoiT is a global technology company that works with cloud-driven organizations to leverage the cloud to drive business growth and innovation. We combine data, technology, and human expertise to ensure our customers operate in a well-architected and scalable state - from planning to production.\n\nDelivering DoiT Cloud Intelligence, the only solution that integrates advanced technology with human intelligence, we help our customers solve complex multicloud problems and drive efficiency.\n\nWith decades of multicloud experience, we have specializations in Kubernetes, GenAI, CloudOps, and more. An award-winning strategic partner of AWS, Google Cloud, and Microsoft Azure, we work alongside more than 4,000 customers worldwide.\n\nAbout DoiT's PerfectScale Platform\n\nDoiT offers PerfectScale, a pioneering Kubernetes optimization and management solution that empowers DevOps, SRE, and Platform Engineering teams to optimize cloud performance while minimizing costs. We combine advanced AI technology with SME-human expertise to help organizations achieve peak Kubernetes efficiency.\n\nThe solution delivers a seamless onboarding experience, an intuitive UI, and a powerful autonomous optimization engine that ensures Kubernetes environments run efficiently with minimal human intervention.\n\nThe Opportunity\n\nAs a Principal Data Engineer, you will be both a hands-on contributor and a key architectural leader. You will design and build large-scale backend services and high-throughput data pipelines while also shaping the long-term technical direction of PerfectScale’s platform. This role combines deep technical ownership with active contribution to critical code, infrastructure, and performance-sensitive workloads.\n\nResponsibilities\n\nSystem Ownership: Design, build, and deploy large-scale distributed systems and high-throughput data pipelines using Go and cloud-native technologies.\nArchitecture & Code: Lead system-wide architectural decisions, focusing on data flow, performance, and resilience. Actively contribute to the codebase with high quality code.\nTechnical Leadership: Lead major technical initiatives, reduce technical debt and ensure the platform meets the reliability and scalability SLAs. Champion best engineering practices, code quality, testing and maintainability.\nCollaborate with product and engineering teams and R&D management to define the technical roadmap, review architecture and mentor junior engineers\n\nQualifications\n\nExperience: 8+ years of backend engineering experience, with 3+ years architecting high-load systems or data pipelines in a production environment.\nBackend Stack: Deep expertise in distributed systems using modern languages (Go, Java, Rust, or Python).\nData Systems: Strong, hands-on experience with relational and analytical databases (Postgres, ClickHouse is preferred).\nCloud-Native: Proven experience with microservices, containers, and modern DevOps practices (Docker, Kubernetes, GitOps, CI/CD).\nSkills: Demonstrated ability to combine hands-on coding with architectural leadership, including strong debugging, benchmarking, and performance optimization skills.\n\nBonus Points\n\nDeep Golang expertise\nDeep Kubernetes Knowledge\nExperience with modern data engineering technologies: Spark, Trino, Iceberg, Parquet, ClickHouse, DBT\nDBA background (relational, OLAP, columnar)\nExpertise in telemetry and time series\nCloud expertise (AWS, GCP, Azure)\n\nAre you a Do'er?\n\nBe your truest self. Work on your terms. Make a difference.\n\nWe are home to a global team of incredible talent who work remotely and have the flexibility to have a schedule that balances your work and home life. We embrace and support leveling up your skills professionally and personally.\n\nWhat does being a Do’er mean? We’re all about being entrepreneurial, pursuing knowledge, and having fun! Click here to learn more about our core values.\n\nSounds too good to be true? Check out our Glassdoor Page.\n\nWe thought so too, but we’re here and happy we hit that ‘apply’ button.\n\nFull-time employee benefits include:\n\nUnlimited PTO\nFlexible Working Options\nHealth Insurance\nParental Leave\nEmployee Stock Option Plan\nHome Office Allowance\nProfessional Development Stipend\nPeer Recognition Program\n\nMany Do'ers, One Team\n\nDoiT unites as Many Do'ers, One Team, where diversity is more than a goal—it's our strength. We actively cultivate an inclusive, equitable workplace, recognizing that each unique perspective enhances our innovation. By celebrating differences, we create an environment where every individual feels valued, contributing to our collective success.",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "IT Data Engineer",
      "company": "ABN AMRO Bank N.V.",
      "location": "Amsterdam, North Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4361501776/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:37.945920",
      "description": "About the job\n\nAt a glance\n\nAre you a technical expert and enthusiastic person who inspires others to create innovative solutions? Then we need your help, in making ABN AMRO a personal bank in a digital age!\n\nHow are you going to shape innovation, advancements, and projects within your department? Our employees get the freedom to grow and experiment. You support and guide them, so they can become the technical experts that contribute to a future-proof bank. We work hybrid, which means you and your team can flexibly decide where and when you can work most comfortable and effectively (either working from Home or Office).\n\nAll-in-all, working at ABN AMRO means that you contribute to projects that matter and impact millions of customers! Are you up for the challenge?\n\nYour job\n\nYou will be part of a team specifically focused on future-proof technologies and frameworks to help accelerate the bank’s strategy and initiatives.\n\nIn this role, you will oversee designing, developing, and implementing ETL frameworks & data pipelines that helps other teams deliver their data to their consumers with the main goal of being efficient and cost effective. You will be responsible for developing and reviewing software solutions that are deployed in Azure Cloud using a variety of technologies such as: Databricks, Kafka, Airflow etc.\n\nYou will be part of diverse Agile/Scrum DevOps team and have end-to-end responsibility, for developing, managing, and maintaining functionalities in the Credit Capability Team area.\n\nWorking environment\n\nAt ABN AMRO, we strive to be a personal bank in a digital age. That strategy is also brought to life in how we work ourselves. Hence, we offer hybrid working as the new normal. This offers you the flexibility to decide when and where can work most comfortably and effectively. Of course, we offer you the right resources you need to set up a good home office. For example, an ergonomic chair, desk, and laptop.\n\nYour profile\n\nYou feel at home in a technical environment and are always up to date on the latest technologies. Do you think you're a fit? Check your profile and apply if you recognize yourself (partially) in them:\n\nDevelopment skills:\n\nAtleast 7 years of experience working with Azure.\nExperience with Python, Pyspark, Typescript and willingness to learn other programming languages\nExperience with Databricks, Azure Devops.\nExperience with Airflow.\nKnowledge on streaming technologies (Kafka) is highly desireable.\nExperience with deploying and creating Azure infrastructure. (Biceps or Terraform)\n\nOps skills:\n\nKnowledge of change and incident management for e.g. in Servicenow.\n\nSoft skills:\n\nEnglish proficiency\nWorking experience with Scrum/Agile principles\nGood communicator.\n\nWe are offering\n\nYou are given every opportunity and independence to demonstrate your professional expertise in a no-nonsense environment and to further develop yourself. We attach great value to personal development and thereby offer you many training and development opportunities. In addition:\n\nA good monthly salary based on a 36-40 hour working week.\nThe Benefit Budget is 11% of your salary. The Benefit Budget allows you to acquire additional employment benefits. If you make no purchases or reservations in the Benefit Shop in a given month, you are paid one twelfth of your Benefit Budget that month.\nFive weeks of vacation per year. You have the option to purchase an additional four weeks per year.\nPersonal development Budget of € 1,000 per year, which you can accumulate up to € 3,000.\nPossibility to work from home (in consultation with your team and depending on your position).\nAn annual public transport pass with free public transportation throughout the Netherlands.\nAn excellent pension scheme.\n\nInterested?\n\nAre you interested? Then respond online to this vacancy. For more information, you can contact Ramzi Alashabi (Chapter Lead Data) at ramzi.alashabi@nl.abnamro.com. We would like to get to know you.\n\nYour Future: Inclusive, Innovative, Sustainable\n\nDisclaimer external recruitment agencies",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Machine Learning Research Engineer",
      "company": "Understanding Recruitment",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4358802550/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:37.990914",
      "description": "About the job\n\nMachine Learning Research Engineer\n\nAbout Unitary\n\nUnitary is a fast-growing AI startup building Virtual Agents that combine deterministic systems, LLM reasoning, and human-in-the-loop expertise to automate complex trust & safety workflows. Our platform processes millions of images and videos daily for enterprise customers, enabling safer and more reliable decisions at scale.\n\nBacked by Creandum and Plural, with $25M+ raised, we’re scaling quickly and defining the future of intelligent, accountable automation online.\n\nThe Role\n\nWe’re hiring a Machine Learning Research Engineer to shape the next generation of Virtual Agents. You’ll lead the development of an “Agent Factory” — a system that transforms captured workflows into scalable, production-ready agents by unifying code, orchestration, and AI reasoning.\n\nWorking at the intersection of research and engineering, you’ll prototype, validate, and productionise systems that allow AI to autonomously construct and optimise complex software workflows.\n\nWhat You’ll Do\n\nDesign and build the Agent Factory to create, deploy, and manage Virtual Agents\nDevelop frameworks for code generation, evaluation, and workflow automation\nIntegrate LLM-based reasoning with deterministic Python systems\nRun experiments to benchmark and improve automation quality\nPartner with platform, ML, and customer teams to deploy at scale\nInfluence Unitary’s technical roadmap and agentic AI research direction\n\nAbout You\n\nStrong Python expertise with experience in LLMs, Agentic AI, or code-generation systems\nSolid engineering foundations across software design, testing, and MLOps/DevOps\nComfortable moving between research, prototyping, and production systems\nCurious, pragmatic, and highly collaborative in fast-moving environments\n\nBonus: Experience with workflow orchestration (Temporal), browser automation (Playwright),\n\nCI/CD, Terraform, or scaling ML systems in production.\n\nWhy Unitary\n\nRemote-first across Europe\nCompetitive salary + meaningful equity\nFlexible working and generous parental/sick leave\nAnnual budgets for learning and wellbeing\nThree team off-sites per year across London or Europe",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "AI Engineer",
      "company": "KPN",
      "location": "Rotterdam, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4361333913/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:38.041360",
      "description": "About the job\n\nBen jij een ervaren AI-professional met een passie voor Generatieve AI en automatisering? Sluit je aan bij het AI for Corporate team van KPN\n\nJouw rol als AI Engineer\n\nBen jij een AI-engineer die net zo makkelijk met business-stakeholders schakelt als met technische teams? Iemand die energie krijgt van co-creëren met de business, processen doorgronden, kansen spotten én oplossingen bedenken en bouwen? Dan zoeken we jou! Als Medior AI Engineer in ons AI for Corporate team:\n\nOntwerp en bouw je Generatieve AI- en NLP-oplossingen die interne processen in HR & Finance slimmer, sneller en AI-Native maken.\nWerk je aan concrete use-cases zoals AI-agents voor HR/Finance, geautomatiseerd factuurscannen, goedkeuringsworkflows en voorspellende modellen.\nNeem je zelfstandig eigenaarschap over features — van idee tot productie — met focus op schaalbare, betrouwbare en maintainable AI-services.\nBen je een brugbouwer tussen tech en non-tech, durf je te challengen, stel je kritische vragen en bouw je sterke domein-connectie en begrip op.\nCombineer je AI-expertise met productie-mindset en software engineering-kwaliteit.\n\nTeam & werkmodel\n\nWe werken hybride met flexibele thuiswerk-opties. We ontmoeten elkaar op maandagen in Rotterdam en op donderdagen in Amsterdam. Daarnaast organiseren we regelmatig AI-knowledge-sharing en community events.\n\nDit is je team\n\nCorporate Insights & Analytics (CIA) is de data- en AI-motor binnen KPN. Met zo’n 40 professionals — van developers en data scientists tot consultants, data engineers, scrum masters en product owners — werken we verspreid over vijf Scrum-teams aan interne digitale innovatie. Je wordt onderdeel van het AI for Corporate team binnen Group Business Services, een hechte en ondernemende groep van zes AI-specialisten die AI-oplossingen bouwt voor HR & Finance. Binnen dezelfde afdeling werk je ook nauw samen met het Anaplan-, Oracle Reporting-, Managed Dashboarding- en Data-team én met KPN’s snelgroeiende AI-community van 50+ AI-engineers en data scientists.\n\nWat breng\n\njij ons?\n\nJe bent een Medior AI Engineer die technologie én business-impact laat samenkomen. Je werkt zelfstandig, neemt initiatief en krijgt energie van het oplossen van echte corporate uitdagingen binnen HR & Finance. Dankzij je consultant-uitstraling en engineering-achtergrond bouw je vertrouwen op bij stakeholders en vertaal je ideeën naar AI-oplossingen die schaalbaar, betrouwbaar en productie-ready zijn — precies waar Corporate Insights & Analytics (CIA) voor staat.\n\nDit breng je mee:\n\nEen afgeronde master in AI of Computer Science\n2–5 jaar ervaring met AI/ML-oplossingen in productie-omgevingen (bij voorkeur binnen enterprise-domeinen zoals CIA)\nConsultant mindset of uitstraling: je werkt graag samen met de business om oplossingen te bedenken én te bouwen\nSterke software engineering-basis met ervaring in production-grade Python\nErvaring met Docker en container-based development\nCloud-ervaring, bij voorkeur met Azure\nBekend met API-integraties en CI/CD-deployment flows\nNLP-ervaring of pipelines is een plus\nGewend om te schakelen tussen tech- en non-tech-teams, stakeholders te challengen en domein-begrip op te bouwen\n\nJouw kracht in samenwerking:\n\nJe denkt vanuit mogelijkheden én concrete oplossingen, niet alleen modellen\nJe communiceert helder met developers, data scientists en zakelijke stakeholders binnen CIA\nJe bent analytisch scherp, pragmatisch in je aanpak en technisch sterk in uitvoering\nJe bouwt connectie met het domein om oplossingen te maken die echt landen\n\nWaarom jij bij CIA past:\n\nJe bent niet alleen iemand die bouwt — je bent iemand die begrijpt, verbindt, adviseert én realiseert. Binnen Corporate Insights & Analytics (CIA) krijg je de ruimte om jouw expertise om te zetten in AI-services die interne processen verbeteren en meetbare waarde leveren aan de organisatie.\n\nKlaar voor impact binnen CIA? Sluit je aan bij ons team en help KPN’s interne dienstverlening AI-Native en toekomstbestendig te maken.\n\nGoede beheersing van de Nederlandse taal is vereist voor deze functie/ Proficiency in Dutch (spoken and written) is required for this role.\n\nWat krijg je\n\nvan ons?\n\nNatuurlijk hebben we als werkgever jou ook veel te bieden. Dit krijg je van ons:\n\nEen bruto maandsalaris van minimaal € 5.038,- en maximaal € 7.575,- afhankelijk van je werkervaring, op basis van 40 uur\nVaste 13e maand, een deel krijg je maandelijks uitbetaald en een deel in januari van het volgende jaar. Óf je zet het in voor een FLEX & BOOST doel naar keuze! Klik hier om er meer over te lezen\nJaarlijks een individuele en collectieve verhoging conform onze CAO\n€ 1500 per jaar aan inzetbaarheidsbudget dat je naar eigen inzicht mag gebruiken voor bijvoorbeeld trainingen, coaching en cursussen\nFlexibele vrije dagen: onze collega’s mogen zelf (in samenspraak met de manager) bepalen hoe zij met verlof omgaan\nEen goede werk-privé balans (zoals 2 dagen kantoor, 3 dagen thuis, transitieverlof, feestdagwissel naar een feestdag van",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Data Engineer",
      "company": "Nationale-Nederlanden",
      "location": "The Hague, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4368713311/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:28:38.087298",
      "description": "About the job\n\nIs het jouw passie om op basis van data waarde toe te voegen voor zowel de klant als jouw collega’s? Ben jij een topper in het bouwen van data pipelines en sta je open voor veranderingen en nieuwe technieken? Wil jij direct resultaat zien van jouw acties? Dan ben jij de Data Engineer die wij zoeken!\n\nAls Data Engineer binnen het schade intermediaire bedrijf ben je verantwoordelijk voor de vertaalslag van ruwe data naar gestructureerde bestanden. Je modelleert data en je zet pipelines op om de data geautomatiseerd te bewegen naar dashboards, voorspelmodellen of andere toepassingen. Samen met onze collega’s van pricing, product management en het data driven underwriting team zorg je voor juiste tarieven, het sturen op het rendement en de groei van de portefeuille. Je bent innoverend en maakt gebruik van de nieuwste tools en technieken.\n\nWat je gaat doen:\n\nHet modelleren van veel verschillende databronnen in SQL en Python, waarbij je werkt met de modernste technieken op het Azure data platform\nHet opzetten van pipelines om grote hoeveelheden data te combineren en te verzamelen in een Azure Data Lake\nHet creëren van een gebruikersomgeving op het Azure data platform voor de pricing actuarissen, data analisten en data scientists waar de juiste data te vinden is\nHet automatiseren van processen en data flows, hierbij gebruik makend van nieuwe technieken\n\nWat wij jou bieden\n\nNN investeert in een inclusieve, inspirerende werkomgeving en in vaardigheden en competenties voor de toekomst. Daarbij passen arbeidsvoorwaarden die aansluiten bij wat er vandaag nodig is én die rekening houden met de toekomst. Zo bieden we onze medewerkers de mogelijkheid het beste uit zichzelf te halen. Wij bieden jou:\n\nSalaris tussen € 3.517 en € 5.025 op basis van 36 uur, afhankelijk van jouw kennis en ervaring\n13de maand en vakantiegeld wordt maandelijks uitbetaald bij je salaris\n27 vakantiedagen bij een werkweek van 5 dagen en drie Diversiteitsdagen\nEen moderne pensioenregeling uitgevoerd door BeFrank\nVolop training- en opleidingsmogelijkheden\nNS Business Card 2e klas, waarmee je onbeperkt kunt reizen, ook privé. Reis je liever met eigen vervoer? Declareer dan je kilometers\nThuiswerkvergoedingen voor internet en een goede werkplek\n\nWij werken hybride bij NN (twee dagen per week op kantoor). De officiële locatie van deze functie is Den Haag.\n\nWat je meebrengt\n\nEen afgeronde (technische) HBO of WO opleiding in de richting econometrie, wiskunde, natuur/sterrenkunde, informatica of een gerelateerde studie zoals data science\nKennis van programmeertalen, zoals SQL, Python of vergelijkbaar en ervaring met het Azure platform, Git of CI/CD pipelines is een pré\nAffiniteit in het werken met big data en om dit toe te passen in een commerciële omgeving\nOngeveer 0-5 jaar relevante werkervaring in een gerelateerd veld\nJe bent bereid en in staat om nieuwe technieken te leren in een dynamische omgeving\nJe bent analytisch en statistisch sterk, werkt nauwkeurig en pragmatisch met duidelijke implementatiekracht\nJe bent proactief, innovatief en besluitvaardig in aanpak en uitvoering\n\nMet wie je werkt\n\nHet Pricing en Data team bestaat uit ongeveer 20 data engineers, data scientisten en actuarissen en zorgt voor de juiste data en tarieven. Het team heeft een centrale rol binnen het schade intermediaire bedrijf en werkt veel samen met andere teams binnen de afdeling, maar ook met de operationele teams, marketing en IT.\n\nHeb je vragen?\n\nVoor vragen over de procedure kun je terecht bij Liselotte van der Zeeuw – Senior Talent Acquisition Specialist Tech & Data via liselotte.van.der.zeeuw1@nn-group.com.\n\nHet gaat hier om een permanente positie. Een kandidaat ontvangt een contract van NN en we staan niet open voor interim/freelance opdrachten en/of kandidaten of acquisitie door bureaus. Alvast bedankt voor je begrip.\n\nWe bieden je\n\nNS Business card, ook privé te gebruiken\n27 vakantiedagen en 1 Diversiteitsdag\n13e maand en vakantiegeld\nHybride werken",
      "search_profile": "ml_data",
      "search_query": "ml_data"
    },
    {
      "title": "Senior Fullstack Software Engineer (100% Remote)Senior Fullstack Software Engineer (100% Remote)",
      "company": "Tether.io",
      "location": "Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4362333513/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:48.605155",
      "description": "About the job\n\nJoin Tether and Shape the Future of Digital Finance\n\nAt Tether, we’re not just building products, we’re pioneering a global financial revolution. Our cutting-edge solutions empower businesses—from exchanges and wallets to payment processors and ATMs—to seamlessly integrate reserve-backed tokens across blockchains. By harnessing the power of blockchain technology, Tether enables you to store, send, and receive digital tokens instantly, securely, and globally, all at a fraction of the cost. Transparency is the bedrock of everything we do, ensuring trust in every transaction.\n\nInnovate with Tether\n\nTether Finance: Our innovative product suite features the world’s most trusted stablecoin, USDT, relied upon by hundreds of millions worldwide, alongside pioneering digital asset tokenization services.\n\nBut that’s just the beginning:\n\nTether Power: Driving sustainable growth, our energy solutions optimize excess power for Bitcoin mining using eco-friendly practices in state-of-the-art, geo-diverse facilities.\n\nTether Data: Fueling breakthroughs in AI and peer-to-peer technology, we reduce infrastructure costs and enhance global communications with cutting-edge solutions like KEET, our flagship app that redefines secure and private data sharing.\n\nTether Education: Democratizing access to top-tier digital learning, we empower individuals to thrive in the digital and gig economies, driving global growth and opportunity.\n\nTether Evolution: At the intersection of technology and human potential, we are pushing the boundaries of what is possible, crafting a future where innovation and human capabilities merge in powerful, unprecedented ways.\n\nWhy Join Us?\n\nOur team is a global talent powerhouse, working remotely from every corner of the world. If you’re passionate about making a mark in the fintech space, this is your opportunity to collaborate with some of the brightest minds, pushing boundaries and setting new standards. We’ve grown fast, stayed lean, and secured our place as a leader in the industry.\n\nIf you have excellent English communication skills and are ready to contribute to the most innovative platform on the planet, Tether is the place for you.\n\nAre you ready to be part of the future?\n\nAbout the job:\n\nYou'll work across the JavaScript and TypeScript layer of our local AI stack. Depending on the project, you might build user-facing applications (mobile or desktop) or contribute to the platform layer that bridges our C++ inference engines with the app ecosystem. Either path puts you at the heart of making local AI usable: whether you're crafting polished product experiences or building the SDK and bindings that other developers rely on.\n\nThis role suits engineers who thrive in a full-stack JS environment and want to be part of a system where AI runs privately, locally, and fast.\n\nResponsibilities\n\nOwn React (Expo/Electron) app development with clean, modular architecture\nBuild UI using modern React stack (TypeScript, RN Navigation, Zustand/Recoil/Jotai)\nImplement local first / local only apps\nIntegrate mobile apps with distributed systems, local inference, and p2p layers\nStrong experience with REST/WebSockets, async flows, and secure data storage\nAbility to build native modules (iOS/Android) when needed (with some help)\nGood understanding of offline-first systems, caching, and performance\nComfortable integrating SDKs (payments, crypto, AI models, etc.)\nWrite reliable code: unit tests, E2E tests (Maestro/Appium/Playwright)\nExperience with TypeScript across stack (frontend + backend)\nBonus: experience with distributed/P2P APIs, on-device ML, cryptography\n5+ years of experience in Fullstack development\nExpert-level proficiency in Node.js/JavaScript for backend development and React frontend framework\nExperience with performant data handling on constrained devices (via SQLite or similar)\nProven experience building and scaling distributed systems or event-driven architectures\nExperience with containerization technologies (Docker) and orchestration platforms (Kubernetes)\nProficiency with databases, and a deep understanding of data modeling and optimization\nSolid understanding of networking, security principles, and best practices for production systems\nExperience with real-time data streaming and RPC implementations\nAbility to work independently in a remote environment and communicate effectively across time zones\n\nNice to have:\n\nExperience with peer-to-peer technologies (Hyperswarm, libp2p, WebRTC) or similar distributed communication protocols\nFamiliarity with AI/ML inference APIs and OpenAI-compatible endpoints\nPrevious experience building AI SaaS or PaaS platforms\nKnowledge of GPU resource management and ML framework infrastructure\nUnderstanding of WebAssembly or edge computing paradigms\nContributions to open-source projects in relevant domains\n\nImportant information for candidates\n\nRecruitment scams have become increasingly common. To protect yourself, please keep the following in mind when applying",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Full Stack EngineerFull Stack Engineer",
      "company": "Leap",
      "location": "Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4359519889/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:49.296530",
      "description": "About the job\n\nDescription\n\nAbout Us\n\nLeap’s mission is to combat climate change by enabling a reliable electric grid that runs on clean energy. The electric grid is transforming from dirty (but predictable) fossil fuels to clean (but less predictable) renewable energy. To do so, the grid needs more flexible demand and supply to help maintain stability and reliability.\n\nLeap plays a crucial role in opening up wholesale energy markets to all distributed energy resources, enabling our partners to get paid for providing flexibility to the grid.\n\nLeap is a privately-held tech company with funding from top VCs and well-known energy entrepreneurs. We are a remote distributed workplace with teammates based across the globe, in Europe and North America.\n\nOverview\n\nWe’re looking for a Full Stack Engineer with a strong backend focus and solid DevOps experience to help us build, scale, and operate the core systems that power our platform.\n\nThis is not a narrow role. Initially it’s expected that you’ll spend roughly:\n\n50% on backend development\n40% on DevOps / infrastructure / reliability\n10% on frontend work\n\nWe’re explicitly looking for engineers who already have some hands-on experience across all three areas and enjoy working across the stack, even if they have a clear “home base” in backend or infrastructure.\n\nYou’ll work closely with product and engineering to design scalable systems, ship features end-to-end, and ensure our platform remains reliable, secure, and performant as we grow.\n\nKey Responsibilities\n\nContribute to backend development within our Kotlin-based microservices platform, ensuring high performance, clarity, and reliability.\nWork closely with product and design to understand user needs, shape product direction, and validate ideas quickly through prototypes and experiments.\nPartner with other product teams to ensure new features integrate smoothly with our event-driven architecture, Kafka streams, and domain services.\nParticipate in on-call rotations, incident response, root-cause analysis, and post-incident reviews, driving continuous improvement.\nDesign, build, and maintain cloud infrastructure on AWS using Infrastructure-as-Code (Terraform).\nOperate and improve Kubernetes-based production systems, ensuring availability, performance, and resilience.\nBuild and maintain CI/CD pipelines (GitLab) to enable fast, safe, and repeatable deployments.\nImprove observability across the stack (metrics, logs, tracing, alerting, SLOs, dashboards) using Datadog and other related tooling.\nHelp eliminate toil through automation, tooling, and better processes.\nEnsure security best practices across infrastructure and applications (IAM, networking, secrets, vulnerability scanning).\nMake small to medium frontend (React) changes to support new features or improve UX.\nCollaborate with frontend-focused engineers and designers when needed.\nBe comfortable navigating and modifying existing frontend codebases, even if it’s not your primary focus.\nActively use and advocate for AI-powered development tools (e.g. Claude Code, GitHub Copilot) to improve development velocity, code quality, and leverage across the engineering team.\n\nBenefits\n\nQualifications & Requirements\n\n5+ years of professional experience as a software engineer, with hands-on exposure to backend development, DevOps/infrastructure, and some frontend work.\nStrong backend engineering skills, with proficiency in at least one backend programming language used in production systems.\nAbility and willingness to complete a coding assignment in a JVM-based solution (Kotlin preferred) as part of the interview process. Prior professional Kotlin experience is a plus, but not required.\nSolid hands-on experience with AWS (e.g. EC2, EKS, RDS, S3, VPC, IAM).\nPractical experience with Infrastructure-as-Code, preferably Terraform.\nExperience operating applications in Kubernetes, including deployments, manifests, Helm, and debugging.\nFamiliarity with CI/CD systems, preferably GitLab CI/CD.\nExperience with observability and monitoring tools (e.g. Datadog, Prometheus, Grafana, OpenTelemetry).\nComfortable writing production code and scripts (e.g. Kotlin, Python, Go, Bash).\nBasic familiarity with modern frontend technologies and the ability to make small-to-medium frontend changes.\nStrong understanding of distributed systems, networking fundamentals, and system design trade-offs.\nWorking knowledge of modern security practices, including IAM, secrets management, and infrastructure hardening.\nBased in the European timezone, fluent in English both in spoken and written form.\nProficiency with AI-powered engineering tools (e.g. Claude Code, GitHub Copilot) and a strong belief in their value as a core part of modern software development workflows.\nExperience working in a remote or hybrid environment or demonstrating the ability to be productive and engaged, manage time effectively, work independently and succeed in a fully remote environment.\nWillingness to be flexible in terms of working h",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer, Product Engineering, EU",
      "company": "Ashby",
      "location": "Amsterdam, North Holland, Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4355190865/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:49.952279",
      "description": "About the job\n\nHi 👋🏾 I’m Abhik, Ashby's Co-Founder and VP of Engineering. We’re looking for an ambitious full-stack engineer who is laser-focused on solving customer problems and making the right long-term investments to solve them not only today but in our future features and products.\n\nWhat Ashby gives you in return is the best of both early and growth-stage environments. The agency and no-nonsense of a seed startup: you write product specs, make product and design decisions, and build in an almost-no-meeting culture. While also the product-market fit and scale of a growth-stage startup: tens of thousands of daily users who depend on your software and eagerly await your next feature.\n\nWe have notable customers like Notion, Linear, Shopify, and Snowflake. Our growth and retention metrics are best-in-class among our peers: we have tens of millions in ARR, growing >100% year over year, very low churn, and many years of runway. We’ll share more details once we meet.\n\nYou’ve probably seen this role posted before, and it’s because we’re always expanding the team (we’re on track to double this year). We’re bubbling with ideas on how to support Talent Acquisition through software, and we’ve started the journey of building products beyond Talent Acquisition. We read every application and aim to respond to yours within 3-4 days (often sooner).\n\nAbout The Role And How We Work\n\nOur engineering culture strives to recreate the environments where we did our best work as ICs – where we had the ownership and agency to impact our users with creative and innovative software.\n\nI started my career building software for artists in the Visual Effects industry. It was a formative experience for me as a software engineer because success relied on my ability to be a product manager and designer. I talked to artists to understand their needs. I came up with ideas. I did industry research, designed interfaces, and prototyped ideas. I watched artists use what I built and decided what to tackle in the next iteration. No daily stand-ups, no t-shirt sizing, no planning meetings.\n\nI studied computer science to solve problems, not tickets, and this felt exactly like that. I not only felt creative and fulfilled but the agency and ownership we were given as engineers powered an incredible amount of innovation.\n\nInnovation came differently (or not at all) at technology startups beyond the seed stage, often through an engineer’s force of will and ability to push back against culture (rather than any encouragement from it). Engineering was narrowed to implementation and delivery, partly due to the influence of other departments and partly due to the influx of \"Agile\" processes like sprint planning. In those companies, I felt like a JIRA jockey.\n\nAbout\n\nAt Ashby, we’re building an environment that is optimistic about what engineers can own and achieve. An environment that embraces innovative engineers, and, frankly, often stays out of their way. As a Product Engineer, you’ll take ownership over a large portion of one of our products and own projects end-to-end (wearing hats traditionally worn by product and design). You’ll research competitors, write product specs, make wireframes, and more. To ground it with examples, product engineers at Ashby have:\n\nDesigned and built automated interview scheduling. This feature automates scheduling by calculating possible times from a pool of interviewers and other constraints, and then presenting these times to the candidate for selection via our responsive web app. This solves the “Calendar Tetris” problem I talk about in \"What We're Building.\"\nBuilt a generalized declarative filter architecture that allows users to create complex filters for any record with a consistent UI and compile it to SQL in our backend. Many user-facing features use it.\nSpecced, designed, and implemented a feature that allows users to complete signing offers entirely within Ashby. This project involved talking to customers to understand their requirements, deciding what technologies to use, building a prototype, and working with other team members to integrate the final implementation into additional features.\n\nWhat We’re Building\n\nAs engineers, we are used to tooling that makes us better at what we do. When we started Ashby, we saw the opposite with Talent Acquisition software. Recruiting teams were leveling up how they did their work, but instead of software meeting this new standard, it held them back.\n\nScheduling a final round is an excellent example. Recruiting teams wanted to schedule candidates faster, track interviewer preparation and quality, and do it with half the headcount. A recruiter needed to manually collect availability from the candidate, identify qualified interviewers, perform “Calendar Tetris” to find who is available to interview the candidate, schedule on the earliest date possible, and make any last-minute adjustments as availability changed. They must do this while considering the interview load on each in",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Python Developer (Data Analysis Focus)Python Developer (Data Analysis Focus)",
      "company": "Remote Leverage",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4368380133/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:50.135445",
      "description": "About the job\n\nHiring REMOTE Python Developer (Data Analysis Focus) - Multiple positions immediately available.\n\nCompensation: $1400-$2500 USD Per Month!\n\nWe help US businesses hire applicants from various countries for REMOTE job opportunities, and we have multiple open Data Analyst positions we need to immediately hire. You would be working directly with the business.\n\nResponsibilities:\n\n• Provide accurate and timely information on core business functions to stakeholders\n\n• Track vacancies filled and clients served\n\n• Analyze marketing advertisement effectiveness in generating leads\n\n• Extract data from various business sources like CRMs and ATS, Hubspot, QuickBooks, Stripe and etc.\n\n• Transform data into user-friendly formats such as spreadsheets, reports, and dashboards.\n\nRequired Skills and Tools:\n\n• Python (Intermediate) hands-on experience\n\nComfortable maintaining and extending existing codebases (ETL pipelines, notebooks, Plotly Dash dashboards)\n\nStrong fundamentals and problem-solving skills; able to reason about code rather than relying on copy-paste solutions\n\n• SQL / BigQuery\n\nExperience querying and updating analytical data using SQL\n\nFamiliarity with Google BigQuery or similar analytical databases\n\n• Git / GitHub\n\nWorking knowledge of core GitHub workflows (push, pull, branches, issues)\n\nAbility to collaborate on, maintain, and improve a shared codebase\n\n• Proven experience with Google Cloud Platform (GCP)\n\nQualifications:\n\n• 2–4+ years of professional experience working with Python in a data-focused or backend role\n\n• Experience maintaining and improving existing Python codebases rather than building only greenfield projects\n\n• Strong understanding of ETL concepts and working with data from multiple business systems (CRMs, payment platforms, marketing tools, etc.)\n\n• Comfortable working with SQL-based analytical databases and reasoning about data correctness\n\n• Familiarity with cloud-based infrastructure, preferably Google Cloud Platform\n\n• Experience using Git/GitHub in a collaborative development environment\n\n• Fluent English, both verbal and written\n\n• Stable internet connection, laptop, and headset\n\n• Energetic & upbeat\n\n• Team Player\n\n• Willing to listen to feedback & improve\n\nInterested? Hiring immediately. Apply now!",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Control Software EngineerControl Software Engineer",
      "company": "JBT Marel",
      "location": "Boxmeer, North Brabant, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4353210660/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:50.194041",
      "description": "About the job\n\nNeed more complexity in work? We challenge you!\n\nAs a Control Software Engineer, you will be part of a multidisciplinary team with Control Software Engineers and Mechanical Engineers, located in Boxmeer (NL). You will be responsible for the development and maintenance of the PLC and HMI software of multiple systems. In this role you are working closely with various other disciplines and with our customers.\n\nYour Days Will Look a Lot Like This\n\nDevelopment, maintenance and testing of PLC and HMI software\nProvide technical support to our (internal) customers\nDay to day discussions with other disciplines, like Mechanical and Electrical\nPrepare and upgrade/install our systems at customer locations over the world\nMaintain technical and technological knowledge within your field of expertise\n\nWhat kind of a person are you?\n\nWe Encourage Each Of Our 12,500+ Employees To Bring Their Unique Self To Work And Aim To Make Everyone Feel Recognized, Valued And Free To Explore Their Potential. We’re Committed To Creating An Inclusive Culture And Welcome New Colleagues From All Walks Of Life. You Will Recognize In Yourself That You\n\nHave a Bachelor's degree in, Mechatronics, Electronics, Electrical Engineering or equivalent through experience.\nGained more than 8 years of work experience in a similar role.\nKnowledge and experience in software engineering for HMI and PLC is required\nKnowledge of Exor HMI is a strong advantage (JMobile, Designer)\nKnowledge of Schneider Electric PLC is a strong advantage (Control Expert, PL7 Pro)\nKnowledge of B&R PLC is an additional advantage (Automation Studio)\nKnowledge of additional programming languages like JavaScript, VBA is a pré\nCapability in reading and understanding electrical drawings\nAvailable to travel abroad to our customers for approximately 20% - 30% of the time\nEnjoy working in a dynamic environment\n\nWhat’s in it for you?\n\nThere’s Nothing Like The Feeling You Get When You Do Something Worthwhile For a Living. That Said, Coming Home From Work Knowing You Made a Difference Is Just One Of The Great Things You Can Experience At JBT Marel. You Can Expect\n\nFreedom to take initiative and make a real impact in a growing global business\nAn environment of trust and respect with space to explore and fail\nA network of specialists who are always willing to help\nA healthy work-life balance with 40 vacation days and flexible working arrangements\nEndless possibilities to keep learning: access to Linkedin Learning and Busuu language learning\nTo get a career instead of a job. We have many opportunities for internal growth; and we encourage it!\n\n🏬 Who we are\n\nWe are a global team of problem-solvers, passionate about transforming the future of food. As world leaders in advanced food processing solutions, we can contribute to creating a world where quality food is produced sustainably and affordably –but we need individuals with diverse perspectives and skills to help us get the most out of this opportunity.\n\n📩 How to Apply\n\nWe’re excited to learn how you can contribute to our mission of smarter, safer food inspection. Apply now and join a team transforming the future of food processing.\n\n📧 Questions? Contact: Maarten Krepel – maarten.krepel@marel.com\n\n🌐 Learn more at: marel.com www.jbtc.com\n\n🔗 Follow us on LinkedIn\n\nConnect with Talent Acquisition Specialist: www.linkedin.com/in/maartenkrepel\n\nJBT Marel is an equal opportunity employer and values diversity in the workplace. We encourage all qualified individuals to apply.\n\nJoin us — and be the driving force behind smarter, leaner food production.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer - APIs and Integration",
      "company": "comforte AG",
      "location": "EMEA (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4368754553/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:50.265878",
      "description": "About the job\n\nWe are dedicated to our People\n\nWe care. We put people first and we promote individual freedom. It is why we strive to secure personal data with integrity and passion to make our customer’s everyday life more comfortable and secure\n\n.\nWe empower our people to grow and to learn from their experience, and in return we are rewarded with team spirit and great result\n\ns.\nPurpose of the r\n\nole\nAre you an avid and curious learner, passionate about software development and enjoy working in an internationally distributed remote t\n\neam?\nThen comforte is the right place for\n\nyou!\nIn your role as a Senior Software Engineer you will join a small globally-dispersed team in maintaining, developing and supporting a range of comforte products within the APIs and Integration team. These products are used both internally and by our customers in mission-critical environ\n\nments.\nKey responsibilities an\n\nd tasks\nAnalysis of new feature requests and implementation into\nproductsAnalysis of software defects, design, implementation and testing of defe\nct fixesWorking closely with QA to ensure the quality of the\nproductWorking closely with the DevOps team for maintaining CI p\nipelinesProviding product expertise to the rest of the company for products maintained by\nthe teamProviding 2nd and 3rd level support to customers for a variety of comforte\n\nproducts\n\nProfessional skills and\n\nknowledge\nRequ\n\nired SkillsProgramming: Java (C++, C# and other languages are a\nplus), OOPOperating Systems: Linux, Windows (other OS's\n\nare a plus)\nInterme\n\ndiate SkillsDevOps, CI/CD pri\n\nnciples, Git\nAddi\n\ntional SkillsSecurity concepts, especially in cloud\nenvironmentsContainer technologies (Docke\nr/Kubernetes)Cl\noud computingAgi\n\nle princ\n\niples\nLanguageEnglish: required to be fluent both in oral and written\ncommunicationother language skills helpful but not\n\na requirement\n\nPersonal skills\nWilling to continuously learn and improve skills to keep up with te\nchnology changesHappy to take on a leadership role as and when circumstan\nces require thisComfortable discussing technical topics directl\ny with customersOpen to dealing with new and\nold technologiesSelf-learner with an ability to work independently under min\nimal supervisionand growing\n\ncontrolling team\nValue dr\n\niven p\n\nrofessional\nHumbleReady to listen and to share expertise and best practi\nce across own teamOpen for feedback and fl\n\nexibility\n\nto adaptAmbitiousTaking accountabilit\ny to drive resultsGoing the extra mile for great c\n\nustom\n\ner experienceSmartAbility to prioritize multiple task\ns and to set focusPassionate to find pragmatic solutio\n\nns and\n\nto innovateHumaneCaring for other’s well-being in a remote w\norking environmentAdvocates dive\n\nrsity and fai\n\nrness\n\nQualification\n5+ years of experience in development roles on the\nLinux/Windows platformDegree in computer science, mathematics, enginee\n\nring or a p\n\nure science\nWhy join us\nIndividual freedom – tell us w\nhat’s important for YOU!Culture of trust, appreciation, inno\nvation and opportunitiesThe opportunity to make a difference in an a\ngile and fun environmentWork with clients in various ind\nustries around the worldThe opportunity to grow continuously as our techno\nlogy field is so dynamicCompetitive compensation and benefits package\n\nincluding profit sharing",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer",
      "company": "S[&]T",
      "location": "Delft, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4368742586/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:52.969019",
      "description": "About the job\n\nAt S[&]T we contribute to a safer life on Earth by translating space data into valuable and actionable insights. With this, we help organizations, governments and commercial entities to strengthen their information position and thereby improve their decision-making. We focus on 4 domains: Space & Science, Defence & Security, Environment & Sustainability and the High-Tech Industry. We control all levels of the data value chain from data source to user applications, and apply our expertise within our innovations, customer projects and talent acquisition services. Our headquarters are in Delft, The Netherlands and we have two satellite offices in Oslo, Norway and Rome, Italy with a total of 125 experts employed at S[&]T.\n\nWe are currently looking for a Senior Software Engineer to join the team in Delft.\n\nWe are currently looking for a Senior Software Engineering role for our Space & Science business unit in Delft, the Netherlands, to work on the software development for our Data Processing and Analysis systems and services.\n\nOne of our teams within the Space & Science business unit is working on delivering solutions that facilitate automated processing of Earth Observation (EO) data, and provide both automated and interactive analysis of such data. For example, we provide an interactive environment for scientific end-users to develop and test their own data processors. Similarly, we deliver quality control systems for various missions such as Biomass, Sentinel-1, and Sentinel-5P, that monitor satellite instrument performance and perform validation (for example: https://mpc-vdaf-server.tropomi.eu/). Our toolchains are also used for public services that allow scientists to easily retrieve and analyze EO data, especially data concerned with the atmospheric composition (for example: NO2 over europe (https://maps.s5p-pal.com/).\n\nCurrently, we are looking for people who enjoy working on state of the art (open-source) technologies and have in-depth knowledge of the software engineering domain. You will join a team of 5-7 team members that are looking forward to working with you!\n\nThis role is for you if you are someone who:\n\nEnjoys working in a team within a dynamic, high-tech organization.\nEnjoys working with cloud infrastructure for scientific computing, for example within the field of Earth Observation data processing.\nLikes to come up with their own solutions, and discuss and debate various options within the team.\nLikes to coach other team-members, in particular on the technical aspects.\nAlso enjoys social interactions with colleagues.\n\nResponsibilities\n\nSoftware design and development within various projects and for the common toolstack.\nTogether with the software architect you are the lead engineer responsible for one or more projects in the Earth Observation Domain.\nYou can come up with designs of new solutions and know when to re-use existing ones.\nTake ownership of the software development process (estimation, scope management, release cycle).\nLead team-members within the projects.\nProvide support to (scientific) end-users.\n\nRequirements\n\nYou meet the following requirements:\n\nYou have completed an academic education in Computer Science, Informatics or another relevant degree, or alternatively you have a well-established track record in software engineering and have experience with the complete software engineering lifecycle.\nAt least 7 years of experience with coding in Python and at least one more language like C, C++ or Java.\nYou can provide architectural solutions, and know when to use OO or alternatives.\nExperience working with Linux (including system administration tasks).\nExperience with version management systems/source control (git), continuous integration (Jenkins/Gitlab), project management tools (Redmine), virtualization (VMs), and containerization (Docker).\nYou are fluent in written and spoken English.\n\nIt's an advantage if you:\n\nExperience with Nix/NixOS or declarative programming.\nKnowledge of Django, Jupyterlab, Openstack.\nExperience with front-end development and/or scientific visualisation.\n\nInterested? Then click to apply or send your CV and motivational letter to recruitment@stcorp.nl.\n\nPrivacy Notice: In order to apply for this vacancy you must submit your personal information to Science [&] Technology. Science [&] Technology will collect, use, and process your personal information as mentioned in our Privacy Policy. Our policy and processing of your personal information are compliant with the GDPR.\n\nPlease note that if you do not hear back from us within 10 days of your application, you may assume that we have selected another candidate we would like to interview for this position. We do our best to get back to you individually, however, due to a high volume of responses, it can be that we have not been able to reject your application in person.\n\nWe kindly request that recruitment agencies do not contact us regarding this vacancy. We are not seeking assistance and will no",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Software Engineer | Service teamSoftware Engineer | Service team",
      "company": "TapRaise",
      "location": "Breda, North Brabant, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4358058122/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.015179",
      "description": "About the job\n\nAbout TapRaise\n\nTapRaise is a SaaS company located in the center of Breda, entirely focused on the optimisation of fundraising. Our clients include 100+ NGOs and industry-leading fundraising agencies. We count on an extensive network and have more than ten years of experience in digital product development.\n\nWe are on a mission to increase worldwide social impact and we strive to create a workplace culture that promotes fun, well-being, and employee satisfaction.\n\nWe currently have 11 employees, of which 7 are developers, 1 Product Owner, 1 Scrum Master, 1 Account Executive, and the Founder/Director.\n\nAbout our product\n\nWith our solutions is possible to streamline the entire fundraising process, reducing administrative hassle and leaving more time to make an impact: 'Less administration, more impact.'\n\nOur software enable agencies and sales teams to manage their field marketing operations (schedule shifts, recruit new donors, and calculate salaries).\n\nWe provide real-time insights to both agencies and NGOs about their campaigns’ performance. We also manage dataflows and provide CRM integrations (like Microsoft Dynamics or Salesforce).\n\nOur focus is efficiency, transparency, and data quality.\n\nAbout the role\n\nWe are looking for a dedicated and enthusiastic Software Engineer to join our service LASER Team (Lean Automation for Service Efficiency & Reduction). This is the team that takes care of all customer-service needs, while coming up with smart ways to reduce our overall service load so we can continue to grow. This involves coding, configuration and a lot of customer interaction through both our service portal, email and phone calls.\n\nTogether with 2 other software developers, your main focus will be:\n\nImplementing small changes to the existing customer campaigns.\nOnboarding of new customers.\nProviding answers to general questions the customers might have.\nHelp reduce the overall service load by creating smart / handy tools / improvements.\nMonitoring that data entry runs smoothly.\n\nRequirements\n\nExperience level: 1 to 3 years.\nAvailability to work full-time (40 hours/week) on a hybrid setting (at least 2 days on-site).\nKnowledge of HTML, PHP, and SQL. Knowledge of JavaScript, TypeScript, React or Symfony is a plus, but not required.\nYou enjoy taking on your customers’ challenges and finding effective solutions for them.\nUnderstanding of web development principles and best practices.\nStrong problem-solving skills and attention to detail.\nExcellent communication and teamwork abilities.\nAbility to prioritise and context switching.\nEagerness to learn and adapt to new technologies and tools.\nFull professional proficiency (written and spoken) in both Dutch and English.\n\nWhat we offer\n\nA competitive salary that matches your experience.\nAn opportunity to grow in seniority level and salary increase.\nA yearly personal development budget.\nTravel allowance.\nA healthy work-life balance.\n35 paid vacation days.\nMacBook Pro and other gear.\nQuarterly team-building activities.\nInspiring startup incubator environment.\n\nWe believe work should be an enjoyable and meaningful experience, where collaboration is encouraged. We are committed to understanding your ambitions and working alongside you to help you achieve them.\n\nAt TapRaise, we prioritise transparency, humility, and approachability, embracing these values regardless of age, culture, background, gender, or religion.\n\nIf you think you are a good addition to our team, we would love to hear from you!\n\nYou can send an email to magda@tapraise.com with your CV and a short introduction about yourself.\n\nDisclaimer: we do not accept unsolicited resumes from agencies. All unsolicited resumes will be considered our property, and will not be obligated to pay a referral fee.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior / Staff Full stack engineer | Django / Ruby (Primary) | React (Strong) | Java or Rust (Secondary) | Fully Remote (EU-based) | £500-600/day | 12-month contractSenior / Staff Full stack engineer | Django / Ruby (Primary) | React (Strong) | Java or Rust (Secondary) | Fully Remote (EU-based) | £500-600/day | 12-month contract",
      "company": "Owen Thomas | Pending B Corp™",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4369212364/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.061774",
      "description": "About the job\n\nSenior / Staff Full stack engineer | Django / Ruby (Primary) | React (Strong) | Java or Rust (Secondary) | Fully Remote (EU-based) | £500-600/day | 12-month contract\n\nThe Opportunity\n\nWe’re partnering with a fast-scaling, globally distributed tech business that’s investing heavily in the evolution of its platform - modernising backend services, improving frontend experiences, and setting long-term architectural direction.\n\nThey’re looking for a Senior Full Stack Engineer (Contract) with strong experience in Django or Ruby, who is genuinely comfortable building production-grade UIs with React, and has experience in either Java or Rust (with the willingness to deepen skills in the other).\n\nThis is a high-impact, long-term contract within an experienced product-focused engineering team.\n\nIt’s well suited to a contractor who enjoys owning features end to end, working close to product, and contributing to a platform that values performance, scalability, and clean design - supported by modern, AI-assisted development practices.\n\nWhat You’ll Be Doing as a Senior / Staff Full stack engineer | Django / Ruby (Primary) | React (Strong) | Java or Rust (Secondary) | Fully Remote (EU-based) | £500-600/day | Outside IR35 | 12-month contract\n\nDesigning and building end-to-end features across backend and frontend\nDeveloping backend services primarily in Django or Ruby\nBuilding and maintaining frontend components using React\nContributing to backend systems written in Java or Rust, with scope to grow into the other language\nWorking closely with product, design, and platform teams to deliver customer-facing functionality\nHelping shape technical decisions as the platform evolves\nApplying best practices around clean architecture, performance, reliability, and security\nUsing AI tools in your daily development workflow (e.g. coding assistance, refactoring, testing, debugging)\n\nCore Skills & Experience Senior / Staff Full stack engineer | Django / Ruby (Primary) | React (Strong) | Java or Rust (Secondary) | Fully Remote (EU-based) | £500-600/day | Outside IR35 | 12-month contract\n\nEssential\n\nSenior-level experience as a Full Stack Engineer in production environments\nStrong backend experience with Django or Ruby\nStrong frontend experience building user interfaces with React\nCommercial experience with either Java or Rust\nSolid understanding of APIs, scalable architecture, and modern frontend practices\nExperience working in cloud-native environments\nComfortable using AI-assisted development tools day to day\nContractor mindset: able to onboard quickly, communicate clearly, and deliver value fast\n\nStrongly Preferred\n\nWillingness to learn across languages and layers (Django ↔ Ruby, Java ↔ Rust)\nExperience owning features end to end in product-led teams\nBackground in fast-growing or evolving platforms\n\nNice to Have\n\nExperience with both Django and Ruby\nExposure to performance-sensitive or systems-level backend components\nInterest in improving developer experience or internal tooling\n\nContract Details Senior / Staff Full stack engineer | Django / Ruby (Primary) | React (Strong) | Java or Rust (Secondary) | Fully Remote (EU-based) | £500-600/day | Outside IR35 | 12-month contract\n\nContract Type: LTD Company (UK) / B2B\nLocation: Fully remote (EU-based required for legal & timezone reasons)\nRate: £500–600 per day (Outside IR35)\nDuration: 12 months, with strong extension potential\nStart Date: ASAP\n\nIf you’re a Full Stack Engineer contractor who enjoys building features end to end with Django/Ruby and React, and wants exposure to Java and Rust within a modern, forward-looking platform team, this is a strong long-term opportunity.\n\nApply here, and we’ll be in touch if it looks like a good fit. :)",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer",
      "company": "TOPIC Embedded Systems",
      "location": "Eindhoven, North Brabant, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4358007831/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.107696",
      "description": "About the job\n\nSenior Software Engineer bij TOPIC Embedded Systems\n\nNiet zomaar een functie. Een plek waar je engineering ertoe doet.\n\nJe komt bij TOPIC niet terecht in een productielijn van code.\n\nJe stapt binnen in teams die dagelijks werken aan complexe, hightech systemen waar betrouwbaarheid, veiligheid en architectuur geen bijzaak zijn, maar het vertrekpunt.\n\nWij ontwikkelen Embedded software voor systemen die moeten blijven functioneren, onder alle omstandigheden. Dat doen we samen met toonaangevende hightech klanten, in domeinen waar fouten simpelweg geen optie zijn.\n\nDe technologie waar je middenin zit:\n\nOnze projecten bewegen zich over de hele stack:\n\nlow-level Embedded software en middleware\nreal-time systemen, performance-kritische algoritmes\ndriver control, HMI’s en UI-applicaties\ncomplexe hardware/software-integraties\n\nJe werkt voornamelijk in C++, C en Python, binnen architecturen die ontworpen zijn om lang mee te gaan. Geen snelle hacks, maar doordachte oplossingen die onderhoudbaar, testbaar en schaalbaar zijn.\n\nHet team waarin je werkt:\n\nJe maakt deel uit van een multidisciplinair team van ervaren engineers en architecten.\n\nDe lijnen zijn kort, met elkaar én met de klant. Daardoor heb je invloed op keuzes, zie je het effect van je werk en neem je eigenaarschap over wat je bouwt.\n\n“Wat ik waardeer is het eigenaarschap en de kansen die je krijgt om te groeien. Omdat ons team nauw samenwerkt met klanten, ervaar je de luxe van een familiair bedrijf gecombineerd met hoogwaardige hightech projecten. Het is het beste van twee werelden.”\n\nPeter Barna - Software Architect @ TOPIC\n\nJouw rol in het geheel\n\nAls Senior Software Engineer ben je niet alleen bezig met implementeren.\n\nJe:\n\ndenkt mee over architectuur en oplossingsrichtingen\nontwerpt, implementeert en verifieert softwarecomponenten en subsystemen\nbewaakt codekwaliteit en technische keuzes\nbegeleidt collega-engineers en deelt actief je kennis\n\nJe beweegt je comfortabel tussen ontwerp, code en samenwerking met stakeholders, intern én extern. Agile werken is daarbij geen dogma, maar een manier om samen beter te worden.\n\nDe impact van je werk:\n\nDe systemen waar jij aan werkt:\n\nmoeten voldoen aan hoge eisen op performance, veiligheid en betrouwbaarheid\nworden geïntegreerd in complexe producten van internationale klanten\ndragen direct bij aan slimmere, veiligere en toekomstbestendige technologie\n\nJe ziet wat je bouwt terug in echte toepassingen, geen proof-of-concepts die in een la verdwijnen.\n\nWat bieden wij jou?\n\nDit maakt je slimmer:\n\nStrategische projecten in complexe hightech omgevingen;\nSamenwerken met andere senior engineers en domeinexperts;\nToegang tot geavanceerde trainingen via onze TOPIC Academy;\nBijdragen aan en leiden van tech-events en kennissessies.\n\nDit maakt je beter:\n\nVast contract;\nEen all-in arbeidsvoorwaardenpakket (€57.000 – €72.000), inclusief 13e maand, mobiliteit, pensioen, extra vakantiedagen);\n26 vakantiedagen (mogelijkheid tot bijkopen) en een goede pensioenregeling.\n\nDit houdt je gezond:\n\nGoede werk-privébalans, flexibele werktijden en hybride werken;\nInspirerend kantoor met dagelijks vers fruit en een fitnessruimte;\nThuiswerkondersteuning voor een inspirerende werkplek thuis;\nRegelmatige leuke, sociale en sportieve evenementen.\n\nDit helpt je om hier succesvol te zijn:\n\neen technische Bachelor of Master (Embedded Systems, Electronics of vergelijkbaar)\nmeerdere jaren ervaring met softwareontwikkeling in het hightech/embedded domein\nsterke basis in C++, C en Python\nervaring met OOP, UML, unit testing en ontwerpprincipes\nje werkt graag samen, denkt vooruit en neemt verantwoordelijkheid\nje bent nieuwsgierig en wilt jezelf inhoudelijk blijven ontwikkelen\nje spreekt Nederlands en Engels\n\nOnze organisatie\n\nSinds 1996 bouwen we bij TOPIC aan Embedded systemen die het verschil maken voor hightech bedrijven wereldwijd. Van PCB-ontwerp en FPGA tot low-level Embedded software en applicatiesoftware voor UI, web, mobile en cloud.\n\nOnze technische diepgang en brede expertise hebben ons onder andere de status opgeleverd van Premier Embedded Computing Partner van AMD, iets waar we trots op zijn, maar wat vooral iets zegt over de inhoud van ons werk.\n\nDiversiteit & Inclusie\n\nBij TOPIC geloven we dat echte innovatie ontstaat wanneer mensen met verschillende achtergronden, ideeën en perspectieven samenkomen. Elk talent telt en elke stem doet ertoe. Diversiteit versterkt onze creativiteit en inclusie zorgt ervoor dat iedereen zich welkom en gewaardeerd voelt. We hebben een cultuur waarbij iedereen de ruimte krijgt om bij te dragen en zichzelf te zijn.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer - Frontend - Upload & Stream TeamSenior Software Engineer - Frontend - Upload & Stream Team",
      "company": "Restream",
      "location": "EMEA (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4355500543/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.152431",
      "description": "About the job\n\nRestream is looking for a Frontend Engineer to join us to solve complex challenges and build world-class products. In this role, you will build new features, develop the user interface of our product, and improve the reliability of our systems as we scale.\n\nYou will collaborate with a team of Engineers to drive processes and enhance user-facing features. You understand the importance of simplicity and reliability, and you calculate the impact of every decision on each. We believe in small teams where each member contributes significant value.\n\nWhat You'll Do\n\nCraft beautiful interfaces and interactions in Restream web services\nDesign and implement the UI and business logic necessary to support new and existing features\nPartner with a product designer to build great and user-friendly UI/UX\nGive and receive code review feedback with the team\nMaintain a pulse on emerging technologies and discover hidden opportunities in our environment\n\nWhat We Look For\n\nA scrappy, entrepreneurial attitude that gets high-quality projects done quickly\nStrong design sensibility, attention to detail, and strive for an excellent user experience\nSolid knowledge of JavaScript, TypeScript, and newer specifications of ECMAScript (Experience with other programming languages is a plus)\nExpert in React and its major state management systems\nExperience with CSS preprocessors like LESS or SASS\nBasic backend skills: Node.JS, building REST APIs, working with relational or NoSQL databases\nComfortable working with TypeScript, MobX, AWS, Linux, Docker, Kubernetes, continuous deployment workflow\nStrong written and verbal communication skills\nSelf-directed, analytical, and work well in a team environment\n\nBack in 2015, Restream was founded in Ukraine. We had a burning passion for helping creators to be seen and heard. As the #1 multistreaming solution, Restream inspires over 10 million people worldwide to share their stories through live video and follow their dreams. We believe that a small but highly driven and focused team can make a lasting impact in people's lives.\n\nWhat We Offer\n\nA startup environment and a flat company structure\nWork closely with founders and team to build and grow the product\nOpportunity to make an impact on the evolution of the product\nAbility to create something that influences people's lives\nEquity packages for you to truly be a part of the Restream journey\nThe tech you need to get your job done",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Full Stack Engineer (Libra - Legal AI Assistant)",
      "company": "Wolters Kluwer",
      "location": "Alphen aan den Rijn, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4346053424/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.198624",
      "description": "About the job\n\nAs a Full Stack Engineer, you will be working for our Legal & Regulatory division where we help legal and compliance professionals enhance productivity, mitigate risk, and solve complex problems confidently.\n\nThere are hundreds of thousands of lawyers across Europe — and at Libra, we’re transforming how they work. Our AI platform combines deep legal reasoning with cutting-edge generative technology, fundamentally changing how lawyers research, draft, and deliver legal work.\n\nAbout The Role\n\nWe are looking for exceptional engineers to join our fast-growing team automating knowledge work for legal professionals. As a Full Stack Engineer, you’ll play a central role in developing our product and have high impact and ownership over key product features. You’ll work end-to-end across the stack, contributing to both backend and frontend development in a lean, agile environment.\n\nThis is a unique opportunity to shape the future of legal tech by building intelligent, scalable solutions that empower professionals and transform workflows.\n\nIn your role you’ll be part of high skilled technology organization and a fast growing product organization. An ambitious and thrilling place to be as you’ll be essential to both strategic alignment and local execution. We value collaboration, curiosity, and a bias toward action.\n\nWhat you’ll do:\n\nDesign, implement, and maintain product features across the stack—from backend APIs to frontend interfaces.\nCollaborate closely with product and design teams to deliver intuitive, high-performing user experiences.\nEnsure code quality, security, and scalability through best practices and thoughtful architecture.\nContribute to technical decision-making and help shape the engineering culture.\nExplore and integrate AI tools and agents to enhance developer productivity and product capabilities.\n\nWhat you’ll bring:\n\nEducation\n\nBachelor's degree preferred in Computer Science or Software Engineering.\n\nExperience\n\nMinimum 2-3 years of relevant experience working within product software engineering.\nStrong experience with Python, particularly FastAPI and asynchronous programming.\nSolid proficiency in TypeScript; experience with Svelte is a strong plus.\nFamiliarity with software engineering best practices and security principles.\nExperience using AI coding agents like Cursor or Claude Code.\nBonus: You’ve built or contributed to LLM-powered products.\n\nSkills\n\nEntrepreneurial mindset with strong ownership and urgency.\nA pragmatic approach to problem solving. It’s more important to you to solve the problem than to use new/hyped technology\nAccountability and commitment to high-quality outcomes.\nExcellent communication in English; Dutch is a plus.\n\nWorking together\n\nThis is a hybrid role, where you will spend at least eight days a month at our office, where you'll enjoy the benefits of connecting and collaborating with your colleagues in person.\n\nWhat We Offer\n\nIn just over a year, we’ve established ourselves as Europe’s fastest-growing legal AI company by partnering with leading law firms, corporate legal departments, and publishers, As part of Wolters Kluwer’s Legal & Regulatory Division, Libra is building the operating system for modern legal work — and you can help us write its next chapter.\n\nJoin us, at Wolters Kluwer, and be part of a global technology company that makes a difference every day. Be the difference. If making a difference matters to you, then you matter to us.\n\nOur Interview Practices\n\nTo maintain a fair and genuine hiring process, we kindly ask that all candidates participate in interviews without the assistance of AI tools or external prompts. Our interview process is designed to assess your individual skills, experiences, and communication style. We value authenticity and want to ensure we’re getting to know you—not a digital assistant. To help maintain this integrity, we ask to remove virtual backgrounds and include in-person interviews in our hiring process. Please note that use of AI-generated responses or third-party support during interviews will be grounds for disqualification from the recruitment process.\n\nApplicants may be required to appear onsite at a Wolters Kluwer office as part of the recruitment process.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Software Engineer, React.js & Python (Full Stack)Software Engineer, React.js & Python (Full Stack)",
      "company": "Wellfound",
      "location": "Amsterdam, North Holland, Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4358826981/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.245210",
      "description": "About the job\n\nAs a Founding Full Stack Engineer, you won't just write code – you'll shape the core of a product that's already changing how companies grow. You'll own features end-to-end, from database to UI, and see your work directly drive customer success. You'll build alongside the founders, talk to real users, and make decisions that define our technical direction for years to come.\n\nIf you've been waiting for the right moment to join an early-stage company where your work genuinely matters – this is it.\n\nWhat you’ll drive\n\nThis is not a role where you'll be handed specs and expected to execute. You'll work on a product that's live, growing, and used daily by sales teams across Europe. You'll shape what we build and how we build it.\n\nYou will:\n\nOwn and develop core product features across our entire stack (Python/FastAPI backend, TypeScript/React frontend)\nCollaborate directly with founders and customers to conceptualize, design, and ship new features\nMake architectural decisions that balance speed, scalability, and maintainability\nDebug production issues, optimize performance, and ensure our platform stays reliable as we scale\nContribute to a codebase that leverages cutting-edge AI – and help us push its boundaries further\nTake on whatever the moment demands – in an early-stage startup, the lines between roles blur, and that's the point\n\nYou won't just build features. You'll help build a company.\n\nWho thrives here\n\nYou've built and shipped real products before. You understand what it takes to move fast. You're energized by ambiguity, not paralyzed by it – and you'd rather ask for forgiveness than wait for permission.\n\nYou're someone who learns constantly, experiments boldly, thinks in systems – and earns trust through delivery, not promises.\n\nYou bring:\n\nSignificant experience as a full-stack engineer, ideally at a medior/senior level\nStrong backend skills in Python\nSolid knowledge in TypeScript and React\nExperience operating software at scale in production environments\nFluent English with the ability to communicate complex technical concepts clearly\n\nMultiple opportunities to join a fantastic business, please send CVs directly to the job advertisement or to david@getwellfound.co",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Software EngineerSoftware Engineer",
      "company": "Mercor",
      "location": "Brabantine City Row (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4369211181/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.292039",
      "description": "About the job\n\nAbout The Job\n\nMercor connects elite creative and technical talent with leading AI research labs. Headquartered in San Francisco, our investors include Benchmark, General Catalyst, Peter Thiel, Adam D'Angelo, Larry Summers, and Jack Dorsey.\n\nPosition: Software Engineer\n\nType: Freelance\n\nCompensation: $70–$80/hour\n\nDuration: 1–2 months\n\nCommitment: 15–25 hours/week, with flexibility up to 40 hours/week\n\nRole Responsibilities\n\nWrite realistic, self-contained prompts for client-side web apps, games, tools, and simulations.\nCreate precise, binary rubrics tagged by verification type.\nEnsure all rubric items are pass/fail and verifiable from screenshot and code inspection.\nDevelop high-quality vibe coding data to train models on client-side web development skills.\nShape model performance on tasks like state management, interactivity, UI correctness, and robustness.\nWork independently and asynchronously to meet deadlines while improving AI model performance.\n\nQualifications\n\nMust-Have\n\n2+ years of experience in frontend/full-stack development or technical content creation.\nBachelor's degree in Software Engineering, Computer Science, or a related field.\nStrong proficiency in JavaScript, TypeScript, React, or vanilla JS.\nComfortable writing precise technical specifications and evaluation criteria.\n\nStart Date\n\nImmediate\n\nApplication Process (Takes 20–30 mins to complete)\n\nUpload resume\nAI interview: A short, 15-minute conversational session to understand your background, experience, and interest in the role\nFollow-up communication within a few days with next steps and onboarding details\n\nResources & Support\n\nFor details about the interview process and platform information, please check: https://talent.docs.mercor.com/welcome/welcome\nFor any help or support, reach out to: support@mercor.com\n\nPS: Our team reviews applications daily. Please complete your AI interview and application steps to be considered for this opportunity.\n\n,",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer - Python/MongoDB",
      "company": "Canonical",
      "location": "EMEA (Remote)",
      "url": "https://www.linkedin.com/jobs/view/3912561352/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.338687",
      "description": "About the job\n\nWe're enabling high-performing, rock-solid MongoDB deployments on any cloud or platform our customers choose. We want to create the world's best open source analog to MongoDB Altas or Amazon DocumentDB, which can be owned, controlled and operated by end-users on their own multi-cloud or on-premise environments.\n\nCanonical is looking for an experienced Python developer with a background in MongoDB who will help us to build a fully managed MongoDB solution based on Juju. We're aiming to build the most reliable and secure way to deploy and operate MongoDB on machines, VMs, public cloud and Kubernetes. The MongoDB team is small, meaning you will be a key contributor and your work will have a significant impact on the product and the broader ecosystem.\n\nWho you are\n\nYou love technology and working with brilliant people.\nYou are an accomplished senior Python programmer that enjoys challenging projects in mission-critical environments.\nYou have experience operating and managing MongoDB clusters.\nYou are experienced with modern infrastructure deployment automations or with traditional Linux systems administration, operations, and package management.\nYou are passionate about quality and automatic testing.\n\nWork with one of the industry's pioneers in open source with intelligent engineers at every level from engineer to CTO and CEO level. At Canonical we've honed our remote-first culture since 2004, established in the company from the very beginning. Enjoy a competitive salary, the flexibility to work and live where you wish, and the chance to work exclusively on impactful open source projects.\n\nCanonical is proud to foster a workplace free from discrimination. We truly believe that diversity of experience, perspectives, and background will lead to a better environment for our employees and a better platform for our users and customers. This is something we value deeply and we encourage everyone to come be a part of the world of Ubuntu.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Senior Software Engineer - MetaMask (Growth)Senior Software Engineer - MetaMask (Growth)",
      "company": "Consensys",
      "location": "EMEA (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4325258625/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.384617",
      "description": "About the job\n\nConsensys is the leading blockchain and web3 software company founded by Joe Lubin, CEO of Consensys and Co-Founder of Ethereum. Since 2014, Consensys has been at the forefront of innovation, pioneering technological developments within the web3 ecosystem.\n\nThrough our product suite, including the MetaMask platform, Infura, Linea, Diligence, and our NFT toolkit Phosphor, we have become the trusted collaborator for users, creators, and developers on their path to build and belong in the world they want to see.\n\nWhether building a dapp, an NFT collection, a portfolio, or a better future, the instinct to build is universal. Consensys inspires and champions the builder instinct in everyone by making web3 universally easy to use and develop on.\n\nOur mission is to unlock the collaborative power of communities by making the decentralized web universally easy to access, use, and build on.\n\nYou’ll get to work on the tools, infrastructure, and apps that scale these platforms to onboard one billion participants and 5 million developers. You’ll be constantly exposed to new concepts, ideas, and frameworks from your peers, and as you work on different projects — challenging you to stay at the top of your game. You’ll join a network of builders that reaches the edge of our ecosystem. Consensys alumni have moved on to become tech entrepreneurs, CEOs, and team leads at tech companies.\n\nAbout MetaMask\n\nMetaMask aims to create a thriving engineering organization that supports the well-being of our engineers while empowering them to do work they are proud of and enjoy. We strive for an environment that gives our people high trust and autonomy, while also facilitating collaboration, communication and camaraderie among teams and teammates. We aspire to build a diverse engineering team, inclusive to people from all backgrounds and demographics. It is also of great importance to us that working at MetaMask is an experience that catalyzes career growth and learning.\n\nWhat You’ll Do\n\nAs a senior engineer, you will:\n\nBuild and enhance MetaMask's growth engine to drive user engagement and improve retention\nImplement user-centric solutions across MetaMask Clients including Extension, Mobile, and Web\nContribute to backend APIs and middlewares that power these consumer experiences\nHelp create intuitive, efficient, and secure Web3 interactions that delight users\nCollaborate with product managers, designers, and other engineers to deliver high-quality features\nParticipate in code reviews and help maintain high code quality standards\n\nWould be great if you brought this to the role\n\n3+ years working with mobile-based technologies\n3+ years building websites and/or applications\nExperience with React and React Native\nStrong knowledge of modern Javascript (ES6/TypeScript/etc.)\nFamiliarity with blockchain fundamentals and Web3 integration\nWorking knowledge of cross platform/browser compatibility\nExperience working with APIs and middleware services\nExperience working in an agile development team\nExperience developing applications with clean code practices, testing, and adherence to coding standards\nUnderstanding of web-based security considerations\n\nBonus Points\n\nExperience with in-app marketing and engagement strategies, including push notifications, carousel banners, and in-app modals.\nExperience with DeFi protocols, token swaps, or fiat on/off ramps\nKnowledge of financial products in the digital space\nInterest in blockchain technologies and Web3\nBasic understanding of cryptography principles\nExperience working in distributed teams\nPrevious experience working in Web3\nFamiliarity with the Web3 wallet ecosystem\nExperience with performance optimization\n\nOther Skills To Demonstrate\n\nGood verbal and written communication in English\nTeamwork, flexibility, and organization\nEagerness to learn and grow your technical skills\nAbility to balance technical quality with business needs and user experience\n\nDon't meet all the requirements? Don't sweat it. We’re passionate about building a diverse team of humans and as such, if you think you've got what it takes for our chaotic-but-fun, remote-friendly, start-up environment—apply anyway, detailing your relevant transferable skills in your cover letter. While we have a pretty good idea of what we need, we're ready for you to challenge our thinking on who needs to be in this role.\n\nIt is a requirement of employment in this position that applicants will be required to submit to background checks including but not limited to employment, education and criminal record checks. Further details will be provided to applicants that successfully meet the criteria for the position as determined by the company in its sole discretion. By submitting an application for employment, you are acknowledging and consenting to this requirement.\n\nThe salary range for US-based candidates only will be determined throughout the interview process depending on experience and skills.\n\nUS pay range (not including bonus, equity o",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Lead Java Software EngineerLead Java Software Engineer",
      "company": "Kestra",
      "location": "European Economic Area (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4345999030/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.431271",
      "description": "About the job\n\nAbout Kestra\n\nAt Kestra, we’re on a mission to make orchestration and automation simpler for everyone. Our open-source platform helps teams manage complex workflows with confidence, and we’re already making a big impact in businesses around the world. Now, we’re looking for a Full Stack Engineer to help us take things to the next level.\n\nWhat You’ll Do\n\nAs a Lead Software Engineer at Kestra, you’ll get to:\n\nBuild and improve our core platform backend using Java.\nWork on enterprise solutions, crafting products that scale with our customers’ needs.\nYou oversee engineers as Team Leader. This involves conducting code reviews, unblocking developers, and providing technical mentorship to help junior and senior staff grow.\nYou act as the translator between technical and non-technical departments. You’ll work with Product Managers to define roadmaps and ensure technical debt is balanced with feature delivery.\nYou own the quality of the software. This includes overseeing CI/CD pipelines, defining SLOs/SLAs (Service Level Objectives), and leading \"Post-Mortems\" when systems fail.\nYou work closely with customers to understand and fix their pain.\n\nYou’ll be working in an environment where speed and agility are key, and where delivering value to our customers is always the top priority.\n\nOur Tech Stack\n\nBackend: Java, Micronaut\nFrontend: Vue.js, Bootstrap\nDatastore: Kafka, Elasticsearch, PostgreSQL, MySQL\nInfrastructure: Docker, Kubernetes, Terraform\nCloud: GCP, AWS, Azure\nTools: GitHub for repo management, actions, and issues\n\nWe work with a variety of modern technologies, and you’ll get the opportunity to explore new tools and approaches as we grow.\n\nWhat We’re Looking For\n\n10+ years of experience in both backend (Java).\nSomeone who can lead major architecture decisions and drive key initiatives.\nSomeone who keeps things simple and straightforward. We are not here to celebrate beautiful complexity.\nStrong experience with testing and automation, and familiar with agile development practices.\nA love for building great products that solve real problems.\nTrack record of quickly learning new technologies and concepts.\nThe ability to work well both independently, remotely and as part of a team.\nExcellent communication skills, both written and spoken, in English.\n\nBonus Points If You Have\n\nContributed to or maintained an open-source project.\nExperience with front-end technology (like Vue.js or React), allowing you to develop full-stack features.\nExperience with high performance application or Micronaut.\nKnowledge of Docker, Kubernetes, and public cloud services (AWS, GCP, Azure).\nFamiliarity with relational and NoSQL databases (PostgreSQL, MySQL).\nExperience working with high-performance, distributed systems.\n\nPerks & Benefits\n\nWork from anywhere: We’re a remote-first company, so you can work from wherever feels like home. Plus, you’ll have access to coworking spaces worldwide if you ever need a change of scenery.\nHealth coverage: From medical support, dental, and vision, we've got you covered.\nHome office setup on us: We’ll provide all the equipment you need to work comfortably.\n\nOur Hiring Process\n\nWe aim to move quickly (2-3 weeks), but we can adjust the timeline if needed.\n\nIntro call with the hiring manager (30 min)\nTechnical test (2 hour, homework done in async)\nTeam chat with two of your future colleagues (30 min)\nFinal discussion with one of our co-founders (30 min)\n\nWe’re here to make the process smooth and transparent for you.\n\nWhy Kestra?\n\nAt Kestra, we’re passionate about solving real-world challenges through orchestration and automation. We move fast, we learn constantly, and we’re always looking for ways to improve. If you’re excited by the idea of building something meaningful and being part of a dynamic team, we’d love to hear from you!",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Full Stack EngineerFull Stack Engineer",
      "company": "TechShack",
      "location": "European Union (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4369063797/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.477419",
      "description": "About the job\n\nB2B | Senior Full Stack Engineer | €350-400 per day | 3 Month Rolling Contract | Remote in Europe\n\nI’ve partnered with an Music startup who are looking for a Senior Full Stack Engineer to take a real-time audio streaming platform to production ready low latency product.\n\nYou will be responsible for taking prototype-level systems to production, debugging real-world imperfect systems, fixing playback issues such as dropouts, buffering, sync etc and building with stability, reliability and scalability in mind.\n\nRequired Experience\n\n🔧Vue or React\n\n🔧Strong Python experience\n\n🔧Experience with Superpowered or similar Audio SDK's\n\n🔧Experience with \"real-time\" audio playback in the browser\n\n🔧Work with Web Audio API / AudioWorklets\n\nThe client wants someone with strong audio (in browser) experience or strong experience on streaming platforms.\n\nThe interview process is 2 stages, and the client is offering a 3-month rolling contract with a clear long-term roadmap.\n\nIf you are interested in finding out more about the role please DM me with your CV and highlight any relevant audio/streaming experience.\n\nB2B | Senior Full Stack Engineer | €350-400 per day | 3 Month Rolling Contract | Remote in Europe",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Software Engineer",
      "company": "Salt",
      "location": "Amsterdam Area (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4358882667/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.524941",
      "description": "About the job\n\nSalt is currently hiring a Software Engineer for our client in Amsterdam.\n\nExperience: 3+ years\n\nContract: ZZP (KVK registration required)\n\nPay: €88 per hour.\n\nTech Stack: Java, Node.js, TypeScript, JavaScript, AWS\n\nRole Overview\n\nAs a Software Developer, you will work closely with the Engineering Manager and Product Owner to deliver high-quality technical solutions. You will be part of a development team, contributing to production and test code while following established engineering best practices.\n\nKey Responsibilities\n\nDevelop, test, and maintain software applications using Java, Node.js, TypeScript, and JavaScript\nWrite clean, readable, and reusable code following SOLID and DRY principles\nApply appropriate design patterns and refactor code when needed\nEnsure application quality through standard testing practices\nSupport end-to-end ownership of services, including monitoring, deployment, and basic operational tasks\nAssist in resolving production incidents and contribute to root cause analysis\nCollaborate effectively with team members and communicate progress clearly\nFollow company standards for data security, integrity, and quality\n\nRequirements\n\nMinimum 2/3 years of professional software development experience\nHands-on experience with AWS\nSolid understanding of software design principles and testing methodologies\nAbility to work independently with limited supervision\nStrong analytical and problem-solving skills\nKVK registration / ZZP status is mandatory",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Python Software Engineer - Marketplaces teamPython Software Engineer - Marketplaces team",
      "company": "Channable",
      "location": "Utrecht, Utrecht, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4328995463/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.570757",
      "description": "About the job\n\nYour job:\n\nIn this position, you will be part of our diverse product team that works on our main application.\n\nThe Marketplaces Development team is responsible for our Python backend, which powers our API and serves as the main entry point for our services. You will also be working on our API integration channels like Amazon, Bol and eBay, through which we process hundreds of millions of products and orders every day for our customers.\n\nThe team regularly builds new user-facing features, for which you will collaborate with the product management team. The team is working closely together with our Infrastructure development and DevOps teams, which are developing many other services that power Channable under the hood, and all together we build our powerful tool!\n\nYour challenges:\n\nContribute to our Python components and support new marketplace API’s\nDesign, develop, and test new product features\nCollaborate with and review PRs of other team members\nImprove the reliability and robustness of our application\nWork on scalability and performance improvements\nWork together with Product Managers on requirements and issues\nCollaborate with the Integrations department about technical matters\nOwn feature or project implementation from initial design to production delivery\n\nWe use the following technologies and tools:\n\nLanguages: Python(3.13), SQL\nLibraries: Pydantic, typing, asyncio, aiohttp, requests, logging, Flask, fastapi, pytest\nTools: Postgres, Redis, GCS, Alembic, mypy, Sentry, Icepeak, Prometheus, Grafana, Loki\n\nWant to read more about our development adventures? Then visit our inspiring tech blog: https://www.channable.com/tech\n\nAnd if this makes you enthusiastic, you can also take a look at some of our open-source work at https://github.com/channable to get a feeling of how we work together and what our code looks like.\n\nWho are you?\n\nYou are an enthusiastic developer and a critical thinker. You will interact with a lot of new and external HTTP APIs, you are not afraid of experimenting with them to learn how they work. At Channable we help each other to become better as a team. That's something you believe in as well. Besides the skills you currently have, an eager-to-learn mindset is just as important.\n\nAdditionally, you have:\n\nAt least 2 years of experience developing applications in Python\nAt least 2 years of experience working with web APIs and related technologies, as we both consume external and build our own web APIs\nGood understanding of HTTP and REST / GraphQL frameworks.\nFamiliarity with SQL and relational databases, as we use Postgres heavily\nGood working knowledge of Linux, git and the command-line\nHigh engineering standards: do you like to leave your code cleaner than you found it? So do we!\nEU citizenship or a valid work permit for the Netherlands; you are preferably already living in the Netherlands\nAvailable for at least 32 hours a week\n\nAnd then some things are ‘nice to have’:\n\nExperience with concurrent applications, because we do a lot of IO via asyncio!\nHaving worked with distributed systems before\nDevOps mentality: we believe that software teams should be able to complete the software development cycle themselves, and enable them to bring their code to production themselves, and to do so every day.\nExperience with the LGTM stack from Grafana labs (Loki, Grafana, Tempo, Mirmir) as we use this for monitoring, alerting and visualization\n\nImportant note: we understand that studies show women may only apply for roles when they feel they meet 100% of the requirements, therefore, we strongly encourage you to apply even if you don't check every box, as we are looking for passionate individuals with potential and a willingness to grow.\n\nWho are we?\n\nChannable was founded in 2014 in the heart of Utrecht. We are now a strong team of 320+ diverse individuals, and more than 40+ nationalities.\n\nJoining Channable means you’re looking for a bit more than just a job. Diverse as we are, we all share our love for growth, to help, to take ownership, and create an awesome journey together. Feel free to take a further look at who we are here and on our Instagram or LinkedIn! Wanna get to know us even more? Give our Culture Playbook a read.\n\nWhat do we do?\n\nChannable is a fast-growing B2B SaaS platform that offers a fully integrated way to market your products online. We empower marketers and online businesses to manage, scale, and optimize their marketing.\n\nWhat do we offer?\n\nGross monthly salary ranging from € 3.900 to € 5.400 based on a 40-hour work week. The salary is determined based on your experience.\n8% holiday allowance - 8% of your yearly salary, which is paid together with your May salary.\nStock Appreciation Rights: eligible employees can financially profit from Channable’s success.\nAnnual L&D budget of €1000 to spend on anything you want to learn. You can take full advantage of this to grow professionally.\nSaving for old age - we have a savings scheme for old age, which can accrue up",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Scientific Software Engineer",
      "company": "TMC",
      "location": "Delft, South Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4346044346/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.616584",
      "description": "About the job\n\nAbout This Vacancy\n\nAls Scientific Software Engineer ontwerp, bouw en optimaliseer je software die wetenschappelijke processen ondersteunt of aanstuurt. Je werkt nauw samen met onderzoekers, engineers en data scientists aan innovatieve oplossingen die kennis direct toepasbaar maken. Denk aan:\n\nHet ontwikkelen van simulatie- en modelleringstools voor fysica, chemie of materiaalkunde.\nAutomatiseren van experimenten en testopstellingen via embedded software of industriële interfaces.\nVisualiseren van complexe datasets en het bouwen van gebruiksvriendelijke dashboards.\nOptimaliseren van algoritmes voor numerieke berekeningen, beeldverwerking of machine learning.\n\nWhat We Expect From You\n\nJe hebt een trackrecord van 3 tot 8 jaar aan succesvolle scientific-softwareprojecten bij hightech- en onderzoeksorganisaties in de Randstad.\nAantoonbare ervaring met minimaal twee programmeertalen, zoals C++, Fortran, C, Python of MATLAB.\nEen afgeronde Masteropleiding of promotie (PhD) in een bèta-/technisch vakgebied (bijvoorbeeld natuurkunde, wiskunde, informatica of werktuigbouwkunde).\nGrondige kennis van design- en ontwikkelprincipes zoals OOP, TDD, BDD, SOLID.\nErvaring met professionele ontwikkelprocessen (Scrum, Agile, SAFe).\nUitstekende beheersing van de Nederlandse taal.\nSterke analytische vaardigheden en een gestructureerde, nauwkeurige werkstijl.\n\nWhat You Can Expect From Us\n\nEen arbeidsovereenkomst voor onbepaalde tijd, zodat je stabiliteit hebt in een dynamische omgeving;\nEen uitgebreide individuele winstdeling;\nEen individueel opleidingsbudget van €2.200 per jaar, zodat je jezelf continu kunt blijven ontwikkelen;\nDe kans om samen te groeien met onze ervaren professionals in onze gezellige kleinschalige business-cel;\nToegang tot ons TMC Entrepreneurial Lab, waar je je eigen ideeën en projecten tot leven kunt brengen;\nEen omgeving waar jouw stem telt en waar jouw dromen werkelijkheid kunnen worden.\n\nBij TMC werk je in een uniek model waarin ondernemerschap, persoonlijke ontwikkeling en technologische innovatie samenkomen. Jij bepaalt de koers, wij zorgen voor de support en de mogelijkheden.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Software Engineer (Remote)Software Engineer (Remote)",
      "company": "Keystone Recruitment",
      "location": "EMEA (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4369070453/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:37:53.664166",
      "description": "About the job\n\nRole: Software Engineering Specialist (Remote)\nLocation: 100% Remote (Global)\nCompensation: USD 50-150 per hour (paid weekly via Stripe/Wise)\n\nExperienced software engineers validate AI-generated code, refine technical prompts, and benchmark algorithms for leading AI research labs. This part-time remote contract leverages 2+ years of engineering expertise to improve intelligent system capabilities through structured technical review.\n\nKey Responsibilities\n\nReview AI-generated code, prompts, responses for technical accuracy and best practices\nValidate algorithms and software concepts across multiple programming languages\nProvide detailed feedback on solution quality, clarity, and implementation feasibility\nOrganize content by topic, difficulty level, and programming language proficiency\nSupport model benchmarking to assess technical capabilities and limitations\n\nEssential Qualifications\n\n2+ years software engineering, technical research, or content development experience\nBachelor's degree in Software Engineering, Computer Science, or related field\nStrong proficiency in Python, JavaScript, Java, C++, or equivalent languages\nProven debugging, testing, and code validation experience\nExcellent technical writing with attention to implementation detail\n\nProject Details\n\nTimeline: Immediate start, 1-2 months duration\nCommitment: 15-25 hours/week (flexible up to 40 hours)\nFormat: Remote platform with clear evaluation guidelines\nOnboarding: Resume submission + 15-minute AI interview\n\nEqual Opportunity\n\nAll qualified software professionals considered regardless of protected characteristics. Selection based on technical expertise and evaluation performance.",
      "search_profile": "backend_data",
      "search_query": "backend_data"
    },
    {
      "title": "Quantitative Developer",
      "company": "IMC Trading",
      "location": "Amsterdam, North Holland, Netherlands (Hybrid)",
      "url": "https://www.linkedin.com/jobs/view/4358307489/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:47:14.413509",
      "description": "About the job\n\nAt IMC, technology is at the core of everything we do. Our innovative in-house software drives millions of trading decisions daily, allowing us to outperform the competition through faster, more effective decision-making.\n\nIn 2023, IMC acquired Altas Technologies, a rapidly growing algorithmic trading firm with the ambition of creating tomorrow’s most technically advanced trading stack. By combining their highly advanced trading strategies with IMC’s execution and scaling capabilities, this move strengthens our position in the market and is an important step towards ensuring stability and long-term growth for the firm.\n\nYour Core Responsibilities:\n\nYou will become part of a core Quantitative Development team consisting of ~5 people working with cutting-edge technologies on both greenfield projects as well as optimizing existing systems and applications. The team has full end-to-end ownership of their stack. In this role you will:\n\nBuild, optimize and deploy fully automated, low-latency, high-throughput trading systems to execute cryptocurrency trades, including integrating real-time machine learning prediction systems.\nDesign and maintain scalable data infrastructure for efficient ingestion, processing, and analysis of large datasets to support trading and research needs.\nCollaborate with researchers to translate advanced machine learning models and trading strategies into high-performance, production-grade implementations.\nOptimize market connectivity and exchange interactions to ensure low-latency, reliability, and execution efficiency in dynamic trading environments.*\n\nYour Skills and Experience:\n\n+3 years of work experience in a professional work setting.\nHighly experienced in Python combined with experience with either C++ and/or Rust.\nExperience with asynchronous/concurrent/multi-threaded and shared memory programming\nExperience with deployment tools and Bash/scripting abilities\nHands-on experience with ML pipelines in high-performance environments (preferably with real-time, low-latency systems)\nExperience with data processing pipelines, automated scheduling tools, and feature calculation engines is a strong plus\nExperience in architecting significant scale container-style Microservice Architectures from design and testing (CI/CD) to execution, and deployment.\nSerious about clean code, simple but well-architected systems, and continuous improvement\nA track record of contributing to open-source projects in machine learning, data science, or distributed systems is a plus\n\nAbout Us\n\nIMC is a global trading firm powered by a cutting-edge research environment and a world-class technology backbone. Since 1989, we’ve been a stabilizing force in financial markets, providing essential liquidity upon which market participants depend. Across our offices in the US, Europe, Asia Pacific, and India, our talented quant researchers, engineers, traders, and business operations professionals are united by our uniquely collaborative, high-performance culture, and our commitment to giving back. From entering dynamic new markets to embracing disruptive technologies, and from developing an innovative research environment to diversifying our trading strategies, we dare to continuously innovate and collaborate to succeed.",
      "search_profile": "quant",
      "search_query": "quant"
    },
    {
      "title": "Quantitative Analyst (Fully Remote)Quantitative Analyst (Fully Remote)",
      "company": "RGG Capital",
      "location": "Amsterdam, North Holland, Netherlands (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4357562528/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:47:14.600020",
      "description": "About the job\n\nPosition: Quantitative Analyst\n\nCompensation: USD $130,000 per annum + up to 15% Performance Bonus\n\nTotal Annual Package: Up to USD $149,500\n\nLocation: Remote\n\nWe are seeking a Quantitative Analyst to join our data-driven research team focused on leveraging alternative data and sentiment analysis for market insights. This role emphasizes in-depth quantitative research, model development, and rigorous backtesting of signals to drive actionable strategies. The ideal candidate will have a passion for financial markets and expertise in transforming raw data into clear, data-informed insights.\n\nThis position is remote, with the option to work from our Dubai office (with 0% income tax), if preferred (relocation and visa sponsorship support available).\n\nKey Responsibilities:\n\nHedge Funds:\n\nConduct comprehensive quantitative analysis of hedge fund returns, risk metrics, and factor exposures to evaluate manager skill and strategy persistence\nDevelop and maintain proprietary analytical frameworks to decompose hedge fund performance, identify style drift, and assess risk-adjusted returns across market cycles\nPerform detailed attribution analysis to validate managers' stated investment processes and verify alignment with reported results\nBuild and maintain risk factor models to evaluate strategy correlations, beta exposures, and potential portfolio overlaps across our manager universe\nAnalyze portfolio-level characteristics including liquidity profiles, position-level concentration, and counterparty exposures\nProvide quantitative support to the CIO for manager evaluation and ongoing monitoring\nCreate detailed analytical reports for the investment committee, synthesizing complex quantitative findings into actionable insights\n\nOther Asset Classes:\n\nAcquire, clean, and normalize various alternative datasets (e.g., sentiment, social media, and ESG sources)\nDevelop and refine predictive models and signals using time-series analysis, statistical modeling, and machine learning\nCreate robust backtesting frameworks to evaluate model performance and incorporate transaction cost or market impact\nBuild and monitor risk models, conduct stress testing under different market scenarios\nDocument and present research findings, methodologies, and performance metrics to stakeholders\n\nRequired Qualifications\n\nMaster's degree in Finance, Economics, Mathematics, Computer Science, Engineering, Financial Engineering, Statistics, or a related quantitative field (required)\n3+ years of experience in quantitative research, data science, or analytics within a leading financial institution (e.g., top-tier investment bank, asset manager, hedge fund, or proprietary trading firm)\nProven track record of building and validating quantitative models in real-world market environments.\nProficiency in Python for data analysis (pandas, numpy, scipy) and modeling (statsmodels, scikit-learn).\nExperience with databases (SQL or NoSQL) and large-scale data processing frameworks.\nFamiliarity with statistical techniques (time-series analysis, regression, factor modeling, signal processing).\nSolid understanding of financial market structure, pricing, and liquidity.\nKnowledge of key asset classes (equities, fixed income, or derivatives).\nCandidates must have completed all academic programs; those currently enrolled in part-time or full-time degree programs (e.g., part-time Master's, MPhil, PhD coursework) are not eligible\n\nPreferred Qualifications\n\nPhD in a quantitative field (Financial Engineering, Statistics, or similar).\nExperience analyzing sentiment or alternative data (news feeds, social media, ESG, etc.).\nBackground in machine learning, deep learning, or NLP for financial forecasting.\nFamiliarity with cloud computing environments (AWS, GCP, or Azure) for large-scale data processing.\nExperience with portfolio optimization, risk analytics, or factor investing.",
      "search_profile": "quant",
      "search_query": "quant"
    },
    {
      "title": "Quantitative DeveloperQuantitative Developer",
      "company": "Albert Bow",
      "location": "European Economic Area (Remote)",
      "url": "https://www.linkedin.com/jobs/view/4356515538/",
      "source": "LinkedIn",
      "scraped_at": "2026-02-05T01:47:14.744036",
      "description": "About the job\n\nRust Quant Developer | HFT Crypto | Hybrid (1 week/month in London or Paris) | Up to €140k + Bonus\n\nIf you're into Rust, HFT, and DeFi, this one should be on your radar 🔍\n\nWe’re working with a fast-growing crypto trading firm backed by a world-class team, including one of the top HFT minds in the space and they’re building a next-gen trading platform from scratch in Rust.\n\nThey're looking for a sharp Quant Dev to help architect and optimise ultra-low-latency systems, build algo trading infrastructure, and connect to DeFi venues in real time.\n\nResponsibilities\n\nBuild & improve Rust-based HFT trading algorithms\nCreate front-office systems for risk, data, execution, post-trade\nIntegrate with real-time DeFi market data\nBacktest, monitor, and debug live trading systems\nOwn performance across the full stack\n\nRequirements\n\nStrong Rust skills (or top-tier C++/low-level background with Rust exposure)\n2+ years building trading systems or working on latency-critical infra\nDeep understanding of order books, state machines, and trading flows\nPerformance tuning, real-time data handling, and debugging chops\nBonus points for crypto market familiarity\n\nWhat’s on Offer\n\nGreenfield systems in Rust, owned by a proven HFT leadership team\nHybrid setup: remote with 1 week/month in London or Paris\nInternational team, top-tier equipment, and full health coverage\nA firm that values autonomy, curiosity, and ownership over politics\n\nIf you are interested please apply with an up-to-date CV below or directly to myself – chrisgorry@albertbow.com. Initial interviews are happening ASAP.",
      "search_profile": "quant",
      "search_query": "quant"
    }
  ]
}