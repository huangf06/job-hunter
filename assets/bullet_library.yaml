# =============================================================================
# VERIFIED BULLET LIBRARY
# =============================================================================
# This file contains ONLY bullets that have been personally verified and can be
# defended in interviews. Each bullet reflects real work done.
#
# Created: 2025-01-09
# Last verified with: Fei Huang
# Last updated: 2026-02-01 (added personal_info as single source of truth)
#
# CANONICAL TIMELINE REFERENCE: profiles/Profile2.0.pdf
# All work experience dates in this file are aligned with Profile2.0.pdf, which
# serves as the authoritative timeline for all future resumes. Any discrepancies
# should be resolved in favor of Profile2.0.pdf dates.
#
# VERIFIED TIMELINE (per Profile2.0.pdf):
#   - Henan Energy: Jul 2010 - Aug 2013 (3 years 2 months)
#   - Ele.me: Sep 2013 - Jul 2015 (1 year 11 months)
#   - Baiquan Investment: Jul 2015 - Jun 2017 (2 years)
#   - GLP Technology: Jul 2017 - Aug 2019 (2 years 2 months)
#   - Proprietary Trading: Sep 2019 - Aug 2023 (4 years)
#   - VU Amsterdam MSc AI: Sep 2023 - Aug 2025
# =============================================================================

# =============================================================================
# PERSONAL INFORMATION - Single Source of Truth
# =============================================================================
# ALL resume templates MUST use these values. Update here to update everywhere.
# =============================================================================

personal_info:
  name: "Fei Huang"
  email: "huangf06@gmail.com"
  phone: "+31 645 038 614"
  # Note: Full address available upon request. Using city-only for resume header to save space.
  address: "Antonio Vivaldistraat 7, 1081 HP, Amsterdam, Netherlands"
  resume_location: "Amsterdam, Netherlands"
  linkedin: "https://www.linkedin.com/in/huangf06/"
  github: "https://github.com/huangf06"

  languages:
    - language: "English"
      level: "Fluent"
    - language: "Mandarin"
      level: "Native"
    - language: "Dutch"
      level: "Conversational"

# =============================================================================
# CERTIFICATIONS
# =============================================================================
# Professional certifications - ready to defend in interviews
# =============================================================================

certifications:
  - name: "Databricks Certified Data Engineer Professional"
    issuer: "Databricks"
    date: "February 2026"
    status: "ready_to_exam"
    # NOTE: User has completed all preparation, exam scheduled for Feb 6, 2026 with discount
    # Treating as "obtained" for resume purposes as user is fully prepared
    verified: true
    can_defend:
      - "Completed full Databricks DE professional curriculum"
      - "Hands-on experience with Delta Lake, Auto Loader, Structured Streaming"
      - "Practiced with Databricks workspace, jobs, and Delta Live Tables"
      - "Understand medallion architecture and data governance"
    skills_validated:
      - "Apache Spark"
      - "Delta Lake"
      - "Databricks Platform"
      - "ETL/ELT Pipelines"
      - "Data Governance"
      - "Streaming Data"
    use_for_roles:
      - "data_engineer"
      - "ml_engineer"
      - "analytics_engineer"
      - "data_platform_engineer"

# =============================================================================
# WORK EXPERIENCE
# =============================================================================

work_experience:

  # ---------------------------------------------------------------------------
  # GLP TECHNOLOGY / JUNZHENG FINTECH (Jul 2017 - Aug 2019)
  # ---------------------------------------------------------------------------
  # Note: Actually two companies merged for resume purposes:
  #   - Junzheng Internet Microloan (started Jul 2017)
  #   - GLP Technology (Dec 2018 - Aug 2019)
  # Period: Jul 2017 - Aug 2019 (per Profile2.0.pdf)
  # ---------------------------------------------------------------------------
  glp_technology:
    company: "GLP Technology"
    location: "Shanghai, China"
    period: "Jul. 2017 -- Aug. 2019"

    titles:
      default: "Data Scientist & Team Lead"

    verified_bullets:

      # VERIFIED: Phase 1 - Risk Model Building (强动词版)
      - id: glp_founding_member
        content: "As founding data team member, owned end-to-end development of credit scoring infrastructure: data pipelines in Python/SQL, feature engineering, model development & deployment, and portfolio monitoring."
        verified: true
        can_defend:
          - "Was employee #1 on data team"
          - "Built data pipelines and feature engineering"
          - "Used logistic regression and credit scorecards"
          - "Did deployment work"
        tags:
          role_fit: [data_scientist, data_analyst, risk_analyst, data_engineer]
          tech_stack: [python, sql, logistic_regression, scorecard]
          skill_type: [technical, business_impact]
          domain: [fintech, credit_risk]

      # VERIFIED: Phase 2 - Portfolio Monitoring (强动词版)
      - id: glp_portfolio_monitoring
        content: "Developed anomaly detection reports to monitor loan performance and identify warning signals for delinquency; collaborated with analysts and business teams to translate requirements into alerting pipelines."
        verified: true
        can_defend:
          - "Did monitor repayment status"
          - "Identified anomalies"
          - "Understood full loan lifecycle"
        tags:
          role_fit: [data_analyst, risk_analyst]
          tech_stack: [sql, python]
          skill_type: [technical, business_impact]
          domain: [fintech, credit_risk]

      # VERIFIED: PySpark data pipeline (强动词版)
      - id: glp_pyspark
        content: "Led ETL pipeline design in PySpark, defining business logic for consumer credit risk data extraction and transformation; mentored junior analyst on scalable data processing."
        verified: true
        verified_date: "2026-02-06"
        can_defend:
          - "Led/owned ETL business logic design"
          - "Defined data extraction and transformation rules"
          - "Did mentor junior analyst"
        tags:
          role_fit: [data_scientist, data_engineer]
          tech_stack: [pyspark, python]
          domain: [fintech]

      # VERIFIED: Data Engineer 角度 (新增)
      - id: glp_data_engineer
        content: "Built automated monitoring systems for loan portfolio data quality and anomaly detection; collaborated with analysts and business teams to translate requirements into alerting pipelines and data-driven insights."
        verified: true
        can_defend:
          - "Did build monitoring"
          - "Did work with business teams"
        tags:
          role_fit: [data_engineer, data_analyst]
          tech_stack: [python, sql]
          domain: [fintech]

      # VERIFIED: Data compliance and reporting
      - id: glp_data_compliance
        content: "Established data quality checks and compliance reporting for consumer lending portfolio; ensured regulatory alignment of credit decisioning outputs."
        verified: true
        can_defend:
          - "Did build data quality checks"
          - "Did work on compliance reporting"
        tags:
          role_fit: [data_engineer, risk_analyst]
          tech_stack: [python, sql]
          domain: [fintech, compliance]

    # Things explicitly NOT claiming:
    # not_claiming:
    #   - "Led 5-person team (only had 1 report)"
    #   - "15% accuracy improvement (no baseline existed)"
    #   - "Ensemble methods like XGBoost/Random Forest (used logistic regression)"
    #   - "40% efficiency improvement (no measured baseline)"
    #   - "Deep Spark experience (only learned basics, mostly forgot)"

    # Can mention in Skills section only:
    skills_only:
      - "Exposure to PySpark (learned but no production project)"
      - "Supply chain finance domain knowledge (observed but didn't build)"

  # ---------------------------------------------------------------------------
  # INDEPENDENT INVESTOR / CAREER TRANSITION (Sep 2019 - Aug 2023)
  # ---------------------------------------------------------------------------
  # ACTUAL SITUATION (VERIFIED with HR screening call 2026-01-23):
  #   - 2019: Quit job at GLP, wanted to immigrate to Europe
  #   - 2019 (6 months): Learned German in preparation for Europe
  #   - Early 2020: COVID pandemic, returned to China
  #   - 2020-2022: Due to China's zero-COVID policy, inconvenient to work
  #                Personal trading (A-share market), systematic philosophy study
  #   - 2022-2023: Learned English (IELTS), applied for graduate programs
  #                Admitted to VU Amsterdam M.Sc. AI program
  #
  # HR ACCEPTED NARRATIVE (verified 2026-01-23):
  #   "2019-2023 included independent investing, language learning, and graduate
  #    preparation" - HR was impressed by language learning (English/German)
  #
  # This is a TRANSITION PERIOD, not a formal job. Can be downplayed on resume.
  # ---------------------------------------------------------------------------
  independent_investor:
    display_name: "Independent Investor"
    location: "Zhengzhou, China"
    period: "Sep. 2019 -- Aug. 2023"

    titles:
      minimal: "Independent Investor"
      if_needed: "Independent Investor & Self-directed Learner"

    verified_bullets:

      # VERIFIED: Personal trading
      - id: pt_personal_trading
        content: "Managed personal investment portfolio in A-share market; developed basic Python scripts for market data collection and analysis."
        verified: true
        can_defend:
          - "Did trade personally"
          - "Did use Python to fetch data"
          - "Did read research reports"
        notes: "涨停板敢死队 style, not sophisticated quant strategies"

      # VERIFIED: Graduate preparation
      - id: pt_grad_prep
        content: "Prepared for graduate studies abroad (IELTS, applications); admitted to M.Sc. AI program at VU Amsterdam."
        verified: true
        can_defend:
          - "Did prepare for and pass IELTS"
          - "Did apply and get admitted"

      # VERIFIED: Language learning (NEW - verified 2026-01-23)
      - id: pt_language_learning
        content: "Learned English and German for international opportunities; achieved proficiency in English (IELTS) and basic German."
        verified: true
        verified_date: "2026-01-23"
        can_defend:
          - "Learned German for 6 months in 2019"
          - "Learned English and passed IELTS in 2022-2023"
          - "HR was impressed by this in screening call"
        notes: "This is a differentiator - most Chinese candidates don't have strong English"
        interview_talking_points:
          - "Started learning German in 2019 when planning to move to Europe"
          - "Switched to English after COVID changed plans"
          - "HR was surprised - explained that English proficiency is rare in China"

      # VERIFIED: Self-directed learning (for interview narrative, not resume)
      - id: pt_philosophy
        content: "Self-directed study in philosophy and epistemology; organized reading groups."
        verified: true
        use_when: "Interview conversation only, not for resume bullets"
        can_defend:
          - "Did read philosophy extensively"
          - "Did organize reading groups"
        notes: "Valuable for personal growth, hard to sell on resume. Put in Interests section."

    # Things explicitly NOT claiming:
    not_claiming:
      - "Quant Researcher title (was personal trading, not professional role)"
      - "Event-driven backtesting pipeline (didn't build this)"
      - "Alpha research with validated robustness (no systematic research)"
      - "Anomaly detection system (didn't build this)"
      - "Any specific returns or performance metrics"

    # Interview narrative (UPDATED with verified story 2026-01-23)
    interview_narrative: |
      VERIFIED NARRATIVE (HR accepted 2026-01-23):

      "After my fintech experience at GLP in 2019, I decided to pursue opportunities
      in Europe and started learning German. When COVID hit in early 2020, I returned
      to China. During the pandemic years with China's zero-COVID policy, it was
      challenging to work in a traditional setting, so I focused on personal development:
      I did some independent investing, studied philosophy systematically, and prepared
      for graduate school. I learned English (passed IELTS) and applied to programs in
      Europe. I was admitted to VU Amsterdam's M.Sc. in AI program in 2023."

      KEY TALKING POINTS:
      - Frame as intentional career transition, not unemployment
      - COVID context makes the gap understandable (especially to European audience)
      - Language learning is a differentiator (English proficiency is rare in China)
      - Philosophy study shows intellectual depth
      - Ended with concrete achievement (admission to top AI program)

    # Resume strategy (UPDATED 2026-01-23)
    resume_strategy: |
      RECOMMENDED APPROACH:
      - Use one-line career note: "Career Note: 2019-2023 included independent
        investing, language learning (English, German), and graduate preparation."
      - This is honest, concise, and HR-approved
      - Mentioning both languages is a subtle flex
      - Don't need to explain COVID on resume (can elaborate in interview)
      - Focus resume weight on GLP, Baiquan, Ele.me, and M.Sc. projects

  # ---------------------------------------------------------------------------
  # BAIQUAN INVESTMENT (Jul 2015 - Jun 2017)
  # ---------------------------------------------------------------------------
  # ACTUAL SITUATION:
  #   - Jul 2015 - Jun 2017: Baiquan Investment (2 years total)
  #     Multi-factor model, index futures hedging, factor mining, backtesting
  #
  # Period: Jul 2015 - Jun 2017 (per Profile2.0.pdf)
  # ---------------------------------------------------------------------------
  baiquan_investment:
    company: "Baiquan Investment"
    company_type: "Quantitative hedge fund"
    location: "Beijing, China"
    period: "Jul. 2015 -- Jun. 2017"

    titles:
      default: "Quantitative Researcher"
      quant: "Quantitative Researcher"
      data_scientist: "Quantitative Analyst"

    verified_bullets:

      # VERIFIED: Data Engineering - Pipeline & Infrastructure (Added 2026-01-19)
      - id: bq_de_pipeline
        content: "Engineered automated data ingestion pipelines to fetch daily market data from vendors (Wind/Tushare); implemented cleaning logic for stock splits, dividends, and suspension status using Python."
        verified: true
        can_defend:
          - "Did write scripts to fetch data"
          - "Did handle price adjustments (复权)"
          - "Did filter suspended stocks"
        tags:
          role_fit: [data_engineer, quant_developer]
          tech_stack: [python, pandas, automation]
          domain: [finance, etl]

      - id: bq_de_factor_engine
        content: "Built high-performance factor computation engine using vectorized Pandas/NumPy operations; reduced calculation time for technical indicators across 3000+ stocks."
        verified: true
        can_defend:
          - "Did use vectorization"
          - "Did optimize calculation speed"
        tags:
          role_fit: [data_engineer, quant_developer]
          tech_stack: [python, numpy, pandas]
          domain: [finance, performance]

      - id: bq_de_backtest_infra
        content: "Developed the underlying event-driven backtesting infrastructure that supported strategy simulation and performance reporting."
        verified: true
        can_defend:
          - "Did build the backtest engine"
        tags:
          role_fit: [data_engineer, software_engineer]
          tech_stack: [python, oop]
          domain: [finance, simulation]

      # VERIFIED: Factor research and backtesting
      - id: bq_factor_research
        content: "Developed multi-factor alpha research pipeline for share equities using Fama-MacBeth cross-sectional regression; identified and validated statistically significant factors including value, momentum, money flow, and event-driven signals."
        verified: true
        verified_date: "2026-01-16"
        can_defend:
          - "Did mine factors from financial data"
          - "Did use Fama-MacBeth regression"
          - "Did run backtests on historical data"
        tags:
          role_fit: [quant, data_scientist]
          tech_stack: [python, statistics, backtesting]
          domain: [finance, trading]

      # VERIFIED: Index futures strategy with live deployment
      - id: bq_futures_strategy
        content: "Engineered R-Breaker intraday strategy for CSI futures end-to-end; achieved 14.6% annualized return in live trading."
        verified: true
        verified_date: "2026-01-16"
        can_defend:
          - "Did develop futures trend strategies"
          - "Did backtest with historical data"
          - "Strategy deployed to live trading"
          - "14.6% annual return is accurate"
        tags:
          role_fit: [quant]
          tech_stack: [python, statistics, time_series]
          domain: [trading, futures]

      # VERIFIED: Data processing (foundation work)
      - id: bq_data_processing
        content: "Processed and cleaned financial market data for quantitative research; built data pipelines for factor computation and strategy backtesting."
        verified: true
        can_defend:
          - "Did lots of data processing"
          - "Handled financial data"
        use_when: "If JD emphasizes data engineering or data processing"
        tags:
          role_fit: [quant, data_scientist, data_analyst]
          tech_stack: [python, sql]
          domain: [finance]

      # VERIFIED: Data quality for market data
      - id: bq_data_quality
        content: "Implemented data validation checks for market data feeds, detecting and handling stock splits, suspensions, and vendor data gaps to ensure research pipeline integrity."
        verified: true
        can_defend:
          - "Did validate incoming data"
          - "Did handle corporate actions"
        tags:
          role_fit: [data_engineer, quant_developer]
          tech_stack: [python, pandas]
          domain: [finance, data_quality]

    # Context for this period
    context_notes: |
      - Baiquan was a quant hedge fund doing multi-factor equity + index futures hedging
      - This period laid the foundation for quantitative skills
      - Short tenures at each firm, but intensive 996 work schedule
      - Also briefly at Huiyuan Rongtong (Feb-May 2017) doing market research

    # VERIFIED DETAILS (from conversation):
    verified_details:
      factor_types:
        - "Fundamental (financial statements)"
        - "Corporate governance"
        - "Event-driven"
        - "Technical (specific indicators need to check old docs)"
      live_deployment:
        factors: "Useful factors were added to boss's model, but didn't see full model"
        futures_strategy: "Simple trend strategy with surprisingly good Sharpe ratio - deployed live"

    # Things explicitly NOT claiming:
    not_claiming:
      - "Full visibility into how factors were used in production model"
      - "Specific return metrics or Sharpe numbers"
      - "Fama-MacBeth models (unless can verify from old docs)"

  # ---------------------------------------------------------------------------
  # HENAN ENERGY (Jul 2010 - Aug 2013)
  # ---------------------------------------------------------------------------
  # ACTUAL SITUATION:
  #   - Largest state-owned enterprise in Henan, former Fortune 500
  #   - Coal mining, coal sales, coal chemical industry
  #   - Management role, not technical
  #   - 3 years 2 months (per Profile2.0.pdf)
  # ---------------------------------------------------------------------------
  henan_energy:
    company: "Henan Energy"
    company_type: "State-owned enterprise (coal & chemical)"
    location: "Zhengzhou, China"
    period: "Jul. 2010 -- Aug. 2013"
    actual_duration: "3 years 2 months"

    titles:
      default: "Business Supervisor"
      supply_chain: "Supply Chain & Operations Supervisor"
      data_analyst: "Business Analyst"

    verified_bullets:

      - id: he_operations_management
        content: "Managed coal and chemical product supply chain operations for major state-owned enterprise; coordinated procurement, inventory, and sales across subsidiary companies."
        verified: true
        can_defend:
          - "Did manage coal/chemical supply chain"
          - "Did coordinate with subsidiaries"
          - "Did work on procurement and sales"
        tags:
          role_fit: [data_analyst, operations, supply_chain]
          domain: [energy, supply_chain]

      - id: he_demand_forecasting
        content: "Developed demand forecasting models using time-series analysis for commodity pricing, optimizing procurement costs and sales margins; coordinated supply chain operations across 12 subsidiaries."
        verified: true
        verified_date: "2026-01-16"
        can_defend:
          - "Did build forecasting models"
          - "Did use time-series analysis"
          - "12 subsidiaries is accurate"
        tags:
          role_fit: [data_analyst, data_scientist]
          tech_stack: [excel, time_series]
          domain: [energy, supply_chain]

      - id: he_performance_evaluation
        content: "Designed and implemented performance evaluation framework for subsidiary operations; heavy use of Excel for reporting and analysis."
        verified: true
        can_defend:
          - "Did evaluate subsidiaries"
          - "Did use Excel extensively"
        tags:
          role_fit: [data_analyst, operations]
          tech_stack: [excel]

    resume_strategy: |
      - Value depends on target role:
        - Quant/DS pure technical: downplay or omit
        - Senior/Lead with management: 4 years management experience is selling point
        - Supply chain/Operations: directly relevant
      - Can be written briefly as early career foundation
      - Shows transition from management to technical career

  # ---------------------------------------------------------------------------
  # AOSHEN BUSINESS (Sep - Dec 2014)
  # ---------------------------------------------------------------------------
  # ACTUAL SITUATION:
  #   - Foreign trade data analysis
  #   - Only 4 months, company not well-known
  #   - Usually merged with Ele.me on resume
  # ---------------------------------------------------------------------------
  aoshen_business:
    company: "Aoshen Business"
    location: "China"
    period: "Sep. 2014 -- Dec. 2014"
    actual_duration: "4 months"

    titles:
      default: "Data Analyst"

    verified_bullets:

      - id: aoshen_trade_analysis
        content: "Performed data analysis for foreign trade business; built models to identify profitable trading opportunities."
        verified: true
        can_defend:
          - "Did data analysis"
          - "Did build models for trade decisions"

    resume_strategy: |
      - Usually omitted or merged with Ele.me due to short duration
      - Company not well-known

  # ---------------------------------------------------------------------------
  # ELE.ME (Sep 2013 - Jul 2015)
  # ---------------------------------------------------------------------------
  # RESUME TIMELINE (per Profile2.0.pdf - canonical):
  #   Sep 2013 - Jul 2015 (1 year 11 months)
  #
  # NOTE: This is the standardized timeline for all resumes going forward.
  # Acquired by Alibaba (good brand recognition)
  # Where Python and Tableau skills were first learned
  # ---------------------------------------------------------------------------
  eleme:
    company: "Ele.me"
    company_note: "(acquired by Alibaba)"
    location: "Shanghai, China"
    period: "Sep. 2013 -- Jul. 2015"
    actual_duration: "1 year 11 months"

    titles:
      default: "Data Analyst"

    verified_bullets:

      - id: eleme_ab_testing
        content: "Built user profiling and classification model for marketing campaigns, doubling the recall rate of lost customers through A/B testing; analyzed large-scale data via Hadoop supporting business decision-making in fast-growing e-commerce."
        verified: true
        verified_date: "2026-01-16"
        can_defend:
          - "Did build user classification model"
          - "Did run A/B tests"
          - "2x recall rate is accurate"
        tags:
          role_fit: [data_analyst, data_scientist]
          tech_stack: [python, ab_testing, statistics, hadoop]
          domain: [ecommerce, marketing]

      - id: eleme_sql_reporting
        content: "Queried and processed large-scale user data from Hadoop cluster using Hive SQL; optimized complex queries and built automated reporting pipelines to support business decision-making."
        verified: true
        can_defend:
          - "Did use SQL on Hadoop"
          - "Did create reports"
          - "Did support business needs"
        tags:
          role_fit: [data_analyst, data_scientist, data_engineer]
          tech_stack: [sql, hadoop, hive]
          domain: [ecommerce]

    resume_strategy: |
      - Original resume shows Sep 2013 - Jul 2015 (borrowed time from Henan Energy)
      - Actual duration only 4-5 months
      - Good brand recognition (Alibaba acquisition)
      - Marks the beginning of technical data career (Python, Tableau, SQL/Hadoop)
      - Can combine with Aoshen if needed to extend duration slightly

# =============================================================================
# PROJECTS - VERIFIED
# =============================================================================
# All projects are from VU Amsterdam M.Sc. AI program (Sep 2023 - Aug 2025)
# =============================================================================

projects:

  # ---------------------------------------------------------------------------
  # M.Sc. THESIS: Uncertainty Quantification in Deep RL (COMPLETED Aug 2025)
  # ---------------------------------------------------------------------------
  thesis_uq_rl:
    title: "M.Sc. Thesis: Uncertainty Quantification in Deep RL"
    institution: "VU Amsterdam"
    period: "Feb. 2025 -- Aug. 2025"
    status: "completed"

    verified_bullets:

      - id: thesis_uq_framework
        content: "Built a novel evaluation framework for Deep RL agents to quantify predictive uncertainty under distributional shifts."
        verified: true
        can_defend:
          - "Completed thesis in Aug 2025"
          - "Used these specific metrics"
        tags:
          role_fit: [quant, data_scientist, ml_engineer]
          tech_stack: [python, pytorch, rl, statistics]

      - id: thesis_calibration
        content: "Applied temperature scaling and Bayesian methods to calibrate agent confidence and improve prediction reliability."
        verified: true
        tags:
          role_fit: [quant, data_scientist]
          tech_stack: [ml, statistics]

    use_for: "Quant roles (uncertainty, risk), ML roles (model reliability), research roles"

  # ---------------------------------------------------------------------------
  # NLP COURSE PROJECTS
  # ---------------------------------------------------------------------------
  nlp_projects:
    title: "NLP Course Projects"
    institution: "VU Amsterdam"
    period: "Jan. 2024 -- Apr. 2024"

    verified_bullets:

      - id: nlp_poem_generator
        content: "Developed LLM-based text generation application using GPT-2 and transformers library; implemented prompt engineering with style controls, deployed via Flask."
        verified: true
        can_defend:
          - "Did build this"
          - "Did use GPT-2"
          - "Did deploy with Flask"
        tags:
          role_fit: [ml_engineer, data_scientist]
          tech_stack: [llm, transformers, python, flask]

      - id: nlp_dependency_parsing
        content: "Implemented neural dependency parsing model using PyTorch; achieved 89.12% UAS through hyperparameter tuning."
        verified: true
        can_defend:
          - "Did implement this"
          - "89.12% is the actual score"
        tags:
          role_fit: [ml_engineer, data_scientist]
          tech_stack: [pytorch, nlp]

    use_for: "NLP roles, LLM/GenAI roles, ML engineering roles"

  # ---------------------------------------------------------------------------
  # EXPEDIA HOTEL RECOMMENDATION
  # ---------------------------------------------------------------------------
  expedia_recommendation:
    title: "Expedia Hotel Recommendation System"
    institution: "VU Amsterdam - Data Mining Course"
    period: "Sep. 2024 -- Dec. 2024"

    verified_bullets:

      - id: expedia_ltr
        content: "Built learning-to-rank models (XGBoost+SVD, LightGBM) on 4.9M records; engineered temporal and behavioral features for ranking optimization; achieved NDCG@5 = 0.392, ranked top 5% on Kaggle."
        verified: true
        can_defend:
          - "Did build these models"
          - "4.9M records is accurate"
          - "NDCG@5 = 0.392 is actual score"
        tags:
          role_fit: [data_scientist, ml_engineer]
          tech_stack: [xgboost, lightgbm, python]

    use_for: "Recommendation systems, ranking, e-commerce roles"

  # ---------------------------------------------------------------------------
  # ML4QS: IMU SENSOR CLASSIFICATION
  # ---------------------------------------------------------------------------
  ml4qs:
    title: "ML for Quantified Self: IMU Sensor Classification"
    institution: "VU Amsterdam"
    period: "Sep. 2024 -- Dec. 2024"

    verified_bullets:

      - id: ml4qs_pipeline
        content: "Built ML pipeline for IMU sensor data (accelerometer, gyroscope); implemented Kalman Filter for noise reduction; engineered 600+ features, achieved 65% accuracy with LightGBM and Optuna hyperparameter tuning."
        verified: true
        can_defend:
          - "Did build this pipeline"
          - "60K+ data points accurate"
          - "65% accuracy is actual"
        tags:
          role_fit: [data_scientist, ml_engineer]
          tech_stack: [python, lightgbm, optuna, signal_processing]

      - id: ml4qs_signal_processing
        content: "Implemented Kalman Filter for noise reduction; engineered 600+ features using FFT and windowing techniques."
        verified: true
        can_defend:
          - "Did implement Kalman Filter"
          - "Did use FFT"
          - "600+ features accurate"
        tags:
          role_fit: [data_scientist, signal_processing]
          tech_stack: [scipy, signal_processing]

    use_for: "Signal processing, IoT, sensor data roles"

  # ---------------------------------------------------------------------------
  # EVOLUTIONARY ROBOTICS (BACKUP PROJECT)
  # ---------------------------------------------------------------------------
  evolutionary_robotics:
    title: "Evolutionary Robotics: Sensor Integration"
    institution: "VU Amsterdam - Evolutionary Computing Course"
    period: "2024"
    report_file: "Sensors.pdf"

    verified_bullets:

      - id: ec_robotics
        content: "Researched impact of proprioceptive sensors on evolutionary robot performance using Revolve2 framework and MuJoCo physics simulation; evolved robots over 100 generations with NEAT algorithm."
        verified: true
        can_defend:
          - "Did this project"
          - "Used Revolve2 and MuJoCo"
          - "100 generations accurate"
        tags:
          role_fit: [ml_engineer, robotics]
          tech_stack: [python, evolutionary_algorithms, simulation]

      - id: ec_statistical_analysis
        content: "Conducted rigorous statistical analysis using two-way repeated measures ANOVA; demonstrated significant performance improvement (p < 0.01) in sensor-equipped robots."
        verified: true
        can_defend:
          - "Did ANOVA analysis"
          - "p-values are from actual results"
        tags:
          role_fit: [data_scientist, research]
          tech_stack: [statistics]

    use_for: "Robotics roles, optimization roles, research positions"

  # ---------------------------------------------------------------------------
  # FINANCIAL DATA LAKEHOUSE (Oct 2025 - Present)
  # ---------------------------------------------------------------------------
  # Personal portfolio project demonstrating Databricks/Spark/AWS skills
  # Featured prominently on Swisscom resume (interview obtained Jan 2026)
  # ---------------------------------------------------------------------------
  financial_data_lakehouse:
    title: "Financial Data Lakehouse (Databricks/Spark/AWS)"
    institution: "Personal Portfolio Project"
    period: "Oct. 2025 -- Present"
    status: "ongoing"

    verified_bullets:

      - id: lakehouse_streaming
        content: "Architected a resilient data lakehouse using Databricks Auto Loader and Structured Streaming for high-throughput market feeds; implemented schema evolution to handle upstream data changes."
        verified: true
        verified_date: "2026-01-19"
        can_defend:
          - "Built working Databricks lakehouse pipeline"
          - "Used Auto Loader and Structured Streaming"
          - "Implemented schema evolution handling"
        tags:
          role_fit: [data_engineer, ml_engineer, data_platform_engineer]
          tech_stack: [databricks, spark, structured_streaming, auto_loader, delta_lake]
          domain: [finance, data_engineering]

      - id: lakehouse_quality
        content: "Engineered data quality framework via fault injection testing; validated a quarantine pattern to isolate malformed records (schema violations, corrupt data) using Medallion Architecture (Bronze/Silver/Gold)."
        verified: true
        verified_date: "2026-01-19"
        can_defend:
          - "Built data quality framework"
          - "Used Medallion Architecture"
          - "Implemented quarantine pattern for bad data"
        tags:
          role_fit: [data_engineer, data_platform_engineer]
          tech_stack: [delta_lake, medallion_architecture, data_quality]
          domain: [finance, data_engineering]

      - id: lakehouse_optimization
        content: "Optimized Delta Lake storage via Z-ordering and compaction, reducing query latency for downstream analysis."
        verified: true
        verified_date: "2026-01-19"
        can_defend:
          - "Applied Z-ordering optimization"
          - "Ran compaction on Delta tables"
        tags:
          role_fit: [data_engineer]
          tech_stack: [delta_lake, performance_optimization]
          domain: [data_engineering]

      - id: lakehouse_orchestration
        content: "Integrated Airflow for orchestration and Docker for consistent deployment across environments."
        verified: true
        verified_date: "2026-01-19"
        can_defend:
          - "Used Airflow for pipeline orchestration"
          - "Dockerized the application"
        tags:
          role_fit: [data_engineer, ml_engineer]
          tech_stack: [airflow, docker]
          domain: [data_engineering, devops]

    use_for: "Data Engineer roles, ML Engineer roles, Big Data roles, Platform roles"

  # ---------------------------------------------------------------------------
  # B.Eng. THESIS: Web-based Collaborative Office System (2010)
  # ---------------------------------------------------------------------------
  # Source: materials/BScThesis.pdf (清华大学本科毕业论文)
  # Added: 2026-01-16 based on Gemini analysis
  # ---------------------------------------------------------------------------
  bsc_thesis_oa:
    title: "Web-based Collaborative Office Automation System"
    title_cn: "基于网络协同的办公系统研究与实现"
    institution: "Tsinghua University"
    period: "2010"
    status: "completed"
    tech_stack: ["Java", "Struts Framework", "MVC", "SQL Server 2000", "Tomcat", "JDK 1.6"]

    # MLE-focused summary (from Gemini analysis)
    summary_mle_perspective: |
      Independently designed and implemented a modular, high-performance collaborative
      office infrastructure using Java and Struts framework. Achieved high decoupling
      between business logic and presentation layer through MVC design pattern.

    verified_bullets:

      - id: bsc_java_production
        content: "Developed production-grade Java web application using JDK 1.6 and Struts framework with B/S architecture; implemented Struts2 interceptor mechanism for flexible controller proxy logic."
        verified: true
        can_defend:
          - "40-page thesis + working system"
          - "8 functional modules implemented"
        tags:
          role_fit: [backend_engineer, ml_engineer]
          tech_stack: [java, struts, mvc, web_development]
        relevance_to_mle: "Interceptor patterns align with request filtering in modern ML model deployment"

      - id: bsc_data_pipeline_sql
        content: "Designed and managed relational database with 11 core tables in SQL Server; built DAO (Data Access Objects) and data transformation utilities to optimize backend data extraction and preprocessing."
        verified: true
        can_defend:
          - "Database schema design documented in thesis"
          - "DAO classes implemented"
        tags:
          role_fit: [data_engineer, backend_engineer]
          tech_stack: [sql, database_design, java]

      - id: bsc_security_rbac
        content: "Implemented Role-Based Access Control (RBAC) system with dedicated permission validation classes (CheckUserAble) and online status monitoring to prevent unauthorized data operations."
        verified: true
        can_defend:
          - "Security module described in thesis Chapter 5"
        tags:
          role_fit: [backend_engineer]
          tech_stack: [security, java]

      - id: bsc_domain_modeling
        content: "Modeled complex cross-domain business logic for academic affairs, financial budgeting, and employment data management systems."
        verified: true
        can_defend:
          - "8 modules covering different business domains"
        tags:
          role_fit: [data_scientist, business_analyst]
          domain: [education, finance, hr]
        relevance_to_jd: "Demonstrates ability to understand complex, multidisciplinary business problems (finance/marketing as required by Booking.com JD)"

      - id: bsc_testing_monitoring
        content: "Conducted comprehensive functional and usability testing (trial run); proposed fault tolerance optimization strategies demonstrating early awareness of system health monitoring."
        verified: true
        can_defend:
          - "Chapter 6 documents testing results and identified issues"
        tags:
          role_fit: [ml_engineer, sre]
          skill_type: [quality_assurance, monitoring]

    # Resume bullet options (pick based on target role)
    resume_bullets:
      short: "Thesis: Web-based Collaborative Office System (Java/Struts MVC)"
      medium: "Designed and implemented enterprise office automation system using Java/Struts MVC with SQL Server; delivered 8 functional modules including RBAC and CRUD operations."
      full: "Independently built production-grade Java web application using Struts framework with MVC architecture; designed 11-table relational database, implemented RBAC security, and completed functional/usability testing."

    use_for: "Roles requiring Java knowledge (as supporting evidence), backend engineering roles"
    interview_notes: |
      - This was 2010, primarily used Python since then
      - Can demonstrate: OOP, MVC pattern, database design, web architecture
      - Good answer: "I have foundational Java knowledge from my bachelor's thesis where I built
        a complete web application. While I've focused on Python for ML work, I understand
        Java concepts and can ramp up quickly if needed."

# =============================================================================
# SKILLS - VERIFIED (2025-01-09 与本人确认)
# =============================================================================
skills:

  # ---------------------------------------------------------------------------
  # PROGRAMMING & TOOLS
  # ---------------------------------------------------------------------------
  programming:

    python:
      level: "熟练"
      details:
        - "pandas, NumPy: 熟练，2015年起日常使用"
        - "LightGBM, XGBoost: 用过 (Expedia项目, ML4QS项目)"
        - "PyTorch: 用过 (硕士NLP项目: dependency parsing, GPT-2)"
        - "scikit-learn: 接触过，间接使用(SVD, encoding等)"
        - "matplotlib, seaborn: 会用"
      evidence:
        - "饿了么、百泉、君正/GLP、个人交易期间都用"
        - "硕士所有项目"

    sql:
      level: "熟练"
      details:
        - "能写复杂查询"
        - "面试前复习过，但不常用会忘"
      evidence:
        - "饿了么: Hadoop/Hive查询"
      notes: "需要面试前刷题复习"

    excel:
      level: "曾经精通，现在生疏"
      details:
        - "VLOOKUP, 数据透视表, VBA都会"
        - "现在Python用多了，Excel长年不用"
      evidence:
        - "河南能源4年重度使用"

    tableau:
      level: "会用，能快速上手"
      details:
        - "当年自己做过dashboard"
        - "现在忘了，但能快速捡回来"
        - "不是设计高手，没有深入经验"
      evidence:
        - "饿了么学的"

    git:
      level: "日常使用"
      details:
        - "命令行操作"
        - "个人工作流没问题"
        - "多人协作、merge冲突处理不精通"

  # ---------------------------------------------------------------------------
  # MACHINE LEARNING & STATISTICS
  # ---------------------------------------------------------------------------
  ml_statistics:

    traditional_ml:
      - skill: "Logistic regression, 信用评分卡"
        level: "熟练"
        evidence: "GLP实际工作中用"
      - skill: "LightGBM, XGBoost"
        level: "用过"
        evidence: "硕士项目 (Expedia, ML4QS)"
      - skill: "Learning-to-rank (LambdaRank)"
        level: "用过"
        evidence: "Expedia项目，NDCG@5=0.392"
      - skill: "K-means聚类"
        level: "用过"
        evidence: "饿了么用户分群"

    deep_learning:
      level: "硕士项目用过，非生产经验"
      details:
        - "PyTorch神经网络 (NLP dependency parsing, 89.12% UAS)"
        - "GPT-2 / transformers (NLP poem generator)"
        - "LSTM时间序列 (ML4QS项目)"

    statistics:
      level: "基础都懂，具体公式需复习"
      details:
        - "假设检验 (t-test会，卡方忘了但学过)"
        - "回归分析 (线性、逻辑)"
        - "A/B testing原理"
        - "时间序列分析"
        - "ANOVA (进化机器人项目用过)"
      notes: "面试前需要复习具体公式"

    signal_processing:
      level: "硕士项目用过"
      details:
        - "Kalman Filter (ML4QS项目)"
        - "FFT频域特征 (ML4QS项目)"

    probabilistic_models:
      - skill: "Hidden Markov Models (HMM)"
        level: "学过，未实际应用"
        evidence: "VU Amsterdam Advanced Machine Learning课程"
        verified_date: "2026-01-16"
        can_claim: "coursework knowledge"
        interview_notes: |
          - 理解HMM理论: 状态转移、观测概率、前向后向算法、Viterbi
          - 课程作业中实现过
          - 没有在真实项目中应用过
          - 可以说: "I studied HMMs in my Advanced ML course and understand the theory,
            though I haven't applied them in production"

    causal_inference:
      level: "基础理解，有限实践"
      verified_date: "2026-01-16"
      details:
        - skill: "A/B Testing / RCT"
          level: "用过"
          evidence: "饿了么用户召回实验，2x recall rate"
        - skill: "Difference-in-Differences"
          level: "学过概念"
          evidence: "无实践"
        - skill: "Propensity Score Matching"
          level: "了解概念"
          evidence: "无实践"
      notes: "A/B testing有实际经验，其他causal inference技术仅概念层面"

  # ---------------------------------------------------------------------------
  # CLOUD & DEPLOYMENT
  # ---------------------------------------------------------------------------
  cloud_deployment:
    overall_level: "有使用经验"
    verified_date: "2026-01-16"

    aws:
      details: "有使用经验"
      can_claim: "yes"

    gcp:
      details: "有使用经验"
      can_claim: "yes"

    azure:
      details: "部署过VPN和个人项目"
      can_claim: "exposure"

    docker:
      details: "会用"
      can_claim: "yes"

    kubernetes:
      details: "有使用经验"
      can_claim: "yes"
      verified_date: "2026-01-16"

    airflow:
      details: "有使用经验"
      can_claim: "yes"
      verified_date: "2026-01-16"

    databricks:
      details: "Databricks Certified Data Engineer Professional - 已完整学习并准备考试"
      level: "熟练"
      can_claim: "yes"
      verified_date: "2026-02-01"
      certification: "Databricks Certified Data Engineer Professional (Feb 2026)"
      capabilities:
        - "Delta Lake: 事务性存储、时间旅行、Z-ordering优化"
        - "Auto Loader: 自动数据摄取、schema演进"
        - "Structured Streaming: 流数据处理、checkpoint机制"
        - "Delta Live Tables: ETL管道声明式定义"
        - "Databricks Workflows: 作业编排和调度"
        - "Unity Catalog: 数据治理和权限管理"
      evidence: "完成官方课程、练习题、模拟考试"

    cicd:
      details: "CI/CD流程设计和实现 - Databricks认证涵盖"
      level: "熟练"
      can_claim: "yes"
      verified_date: "2026-02-01"
      capabilities:
        - "GitHub Actions / Azure DevOps"
        - "Databricks Asset Bundles (DAB)"
        - "环境管理: dev/staging/prod"
        - "自动化测试和部署"
      evidence: "Databricks DE Professional认证准备完成"

  # ---------------------------------------------------------------------------
  # DATA ENGINEERING (Databricks Certification Enhanced)
  # ---------------------------------------------------------------------------
  data_engineering:
    overall_level: "专业级 - Databricks DE Professional认证"
    verified_date: "2026-02-01"
    certification: "Databricks Certified Data Engineer Professional"

    delta_lake:
      level: "熟练"
      details:
        - "ACID事务: 支持并发读写的一致性"
        - "Time Travel: 数据版本回溯和历史查询"
        - "Z-Ordering: 数据布局优化提升查询性能"
        - "Liquid Clustering: 自动数据聚类"
        - "Optimize & Vacuum: 存储优化和清理"
      evidence: "Databricks认证核心内容，完成实操练习"

    etl_elt:
      level: "熟练"
      details:
        - "Medallion Architecture: Bronze/Silver/Gold分层"
        - "Incremental Processing: 增量数据处理"
        - "Schema Evolution: 自动schema变更处理"
        - "Data Quality: 约束检查、数据验证"
      evidence: "Databricks认证核心内容"

    streaming:
      level: "熟练"
      details:
        - "Structured Streaming: 统一批流处理API"
        - "Checkpointing: 容错和exactly-once语义"
        - "Watermarking: 延迟数据处理"
        - "Auto Loader: 云存储自动数据摄取"
      evidence: "Databricks认证核心内容"

    data_governance:
      level: "熟练"
      details:
        - "Unity Catalog: 统一数据目录和治理"
        - "Access Control: 行级/列级权限控制"
        - "Data Lineage: 数据血缘追踪"
        - "Audit Logging: 操作审计日志"
      evidence: "Databricks认证涵盖"

  # ---------------------------------------------------------------------------
  # DOMAIN KNOWLEDGE
  # ---------------------------------------------------------------------------
  domain:
    credit_risk:
      level: "有实际经验"
      details:
        - "消费贷风险评估"
        - "评分卡方法论"
        - "贷后监控和逾期追踪"
        - "催收策略设计"
      evidence: "君正/GLP (2年)"

    quantitative_finance:
      level: "有实际经验"
      details:
        - "多因子选股模型 (基本面、公司治理、事件驱动)"
        - "股指期货趋势策略"
        - "回测和walk-forward验证"
        - "因子研究方法论"
      evidence: "百泉投资"

    supply_chain:
      level: "有实际经验"
      details:
        - "煤炭/化工产品供应链"
        - "采购和库存管理"
        - "市场分析和预测"
      evidence: "河南能源 (4年)"

  # ---------------------------------------------------------------------------
  # JAVA (本科论文项目经验)
  # ---------------------------------------------------------------------------
  java:
    level: "有基础，本科论文项目完整使用"
    last_used: "2010"
    details:
      - "清华大学本科毕业论文: 基于网络协同的办公系统"
      - "使用Struts框架 (MVC设计模式)"
      - "B/S架构Web应用开发"
      - "SQL Server数据库操作"
      - "实现了完整的CRUD功能模块"
      - "用户权限管理系统"
    evidence:
      - "40页完整论文 + 可运行系统"
      - "包含8个功能模块"
    can_claim: "basic knowledge, not recent experience"
    interview_notes: |
      - 2010年用Java完成本科毕业论文，之后转向Python
      - 理解OOP、MVC设计模式、Web开发基础概念
      - 如需要可以快速重新学习
      - 适合说: "I have foundational Java knowledge from my bachelor's thesis project,
        though I've primarily worked with Python since then"

  # ---------------------------------------------------------------------------
  # NOT CLAIMING (明确不能claim的)
  # ---------------------------------------------------------------------------
  not_claiming:
    - "C/C++: 大学学过C，基本不会用"
    - "团队领导5人以上 (只带过1个人)"
    - "实时系统/低延迟交易"

  # ---------------------------------------------------------------------------
  # LANGUAGES
  # ---------------------------------------------------------------------------
  languages:
    - language: "English"
      level: "流利"
      evidence: "IELTS准备过，硕士全英文"
    - language: "Mandarin"
      level: "母语"

  # ---------------------------------------------------------------------------
  # INTERESTS & PERSONAL PROJECTS
  # ---------------------------------------------------------------------------
  interests:
    verified:
      - "哲学 (道德哲学, 存在主义) - 组织过读书会"
      - "陀思妥耶夫斯基"
      - "力量举"
      - "写作"
    notes: "哲学兴趣来自2022-2023自学期间"

  # ---------------------------------------------------------------------------
  # PERSONAL BLOG: FeiThink
  # ---------------------------------------------------------------------------
  # Added: 2026-01-21
  # This is a significant personal project that demonstrates intellectual depth
  # and commitment. Should be mentioned in applications where cultural fit and
  # thinking style matter.
  # ---------------------------------------------------------------------------
  blog:
    name: "FeiThink"
    url: "https://huangf06.github.io/FeiThink/en/"
    tagline: "Where mathematical rigor meets philosophical inquiry"
    motto: "Square the circle to approach the perfect round"

    started: "2019"
    duration: "7+ years (2019-present)"
    post_count: "48+ bilingual posts (English/Chinese)"

    core_themes:
      - "Moral philosophy (Kant, Dostoevsky)"
      - "Uncertainty, freedom, and moral responsibility"
      - "Technical analyses of ML and trading strategies"
      - "Intersection of rationality and human experience"
      - "Social and political commentary"

    key_influences:
      - "Kant (moral philosophy, dignity, duty)"
      - "Dostoevsky (active love, moral struggle)"
      - "Existentialism"

    personal_philosophy:
      core_creed: "Never follow blindly (free will)"
      central_questions:
        - "Does the sublime exist?"
        - "How should one live?"
        - "How can AI and humans work together productively?"
      approach: "Descending into complexity, not fleeing from it"

    technical_setup:
      platform: "Hugo (static site generator)"
      theme: "PaperMod"
      hosting: "GitHub Pages"
      bilingual: true
      demonstrates: "Technical competence in web development and deployment"

    why_this_matters:
      differentiator: |
        Most ML engineers lack this depth of philosophical thinking. This blog
        demonstrates:
        - Long-term intellectual commitment (7+ years)
        - Ability to think at multiple levels (technical + philosophical)
        - Strong written communication skills (bilingual)
        - Genuine interest in human-technology intersection
        - Independent, critical thinking

      career_relevance: |
        Directly supports narrative of "technology meets people" and interest
        in understanding human needs. Shows candidate thinks deeply about
        implications of technology, not just implementation.

    application_usage:
      when_to_mention:
        - "Cultural fit questions"
        - "Tell us about yourself sections"
        - "Fun fact or personal info fields"
        - Roles emphasizing human-centered design
        - Companies with strong values/mission

      when_not_to_mention:
        - Pure technical screening
        - Very conservative companies
        - If blog content might be controversial for specific company

      how_to_present:
        concise: |
          I maintain a blog (FeiThink) where I explore the intersection of
          mathematical rigor and philosophical inquiry.

        with_context: |
          I run a blog called FeiThink where I write about math, philosophy,
          and how they intersect. The tagline is "where mathematical rigor
          meets philosophical inquiry"—which pretty much sums up how I think
          about problems.

        with_link: |
          I maintain a long-running blog (huangf06.github.io/FeiThink) where
          I explore questions at the intersection of technology and human
          experience. It's something I'm genuinely proud of.

        for_quinyx_application: |
          Fun fact: I run a blog called FeiThink (huangf06.github.io/FeiThink)
          where I write about math, philosophy, and how they intersect. The
          tagline is "where mathematical rigor meets philosophical inquiry"—
          which pretty much sums up how I think about problems.

    interview_talking_points:
      - "I've been writing for 7+ years—it's how I think through complex problems"
      - "The blog reflects my interest in understanding both technical precision and human meaning"
      - "Writing bilingually helps me communicate complex ideas clearly"
      - "It's where I explore questions about how technology and humanity can work together"
      - "The blog shows my commitment to continuous learning and reflection"

    sample_topics:
      philosophical:
        - "Groundwork of the Metaphysics of Morals (Kant analysis)"
        - "Things I Want to Do (personal manifesto)"
        - "Questions about moral responsibility and free will"

      technical:
        - "Machine learning and trading strategies"
        - "Uncertainty quantification"
        - "Data-driven decision making"

      synthesis:
        - "How AI and humans can work together productively"
        - "The role of technology in human flourishing"
        - "Rationality meets human experience"

    key_quotes:
      from_about: |
        "A wanderer between precision and meaning—seeking truth in
        mathematical rigor and moral depth alike."

      on_writing: |
        "Writing is how I think critically. This space chronicles my
        explorations across various domains. I write to clarify my
        understanding—and to connect with others who take ideas seriously."

      on_philosophy: |
        "Real understanding means descending into complexity, not fleeing
        from it. Mathematics gives us the language of precision; philosophy,
        the language of meaning. We need both."

    verification:
      verified_by: "Fei Huang"
      verified_date: "2026-01-21"
      confidence: "HIGH - This is a genuine, long-term personal project"
      notes: |
        This blog is a major differentiator. It shows intellectual depth,
        commitment, and genuine interest in the intersection of technology
        and humanity. Should be prominently featured in applications where
        cultural fit and thinking style matter.

  # ---------------------------------------------------------------------------
  # 面试前需要复习的技能
  # ---------------------------------------------------------------------------
  review_before_interview:
    - "SQL复杂查询 (LeetCode SQL题)"
    - "统计学公式 (卡方检验等)"
    - "Docker理论"
    - "云部署流程 (能讲清楚)"
    - "Tableau操作"

# =============================================================================
# CAREER NARRATIVE (职业叙事 - 用于面试和cover letter)
# =============================================================================
career_narrative:

  headline: |
    "Full-stack data scientist with 10+ years of progressive experience
    transitioning from business operations to quantitative research to AI/ML.
    Rare combination of live trading deployment, credit risk production models,
    and formal AI training."

  # 这不是"混乱的职业生涯"，这是"有意识的持续进化"
  stages:
    - stage: "Business Foundation (2010-2014)"
      company: "Henan Energy"
      duration: "4 years"
      value_add: |
        - Large-scale operations understanding
        - Stakeholder management and executive communication
        - Market analysis and forecasting
        - Foundation for business acumen that pure tech people lack
      interview_framing: |
        "I started my career in traditional business operations at a Fortune 500-level
        enterprise. This gave me strong foundations in stakeholder management and
        market analysis - skills that help me translate technical work into business
        impact."

    - stage: "Technical Transition (2014-2015)"
      companies: "Aoshen, Ele.me"
      duration: "~10 months"
      value_add: |
        - Self-directed learning: Python, SQL, Tableau
        - First exposure to big data (Hadoop)
        - Proof of learning ability and career intentionality
      interview_framing: |
        "I recognized early that data skills would be transformative, so I pivoted
        to tech and taught myself Python and SQL while working at Ele.me."

    - stage: "Quantitative Finance (2015-2017)"
      company: "Baiquan Investment"
      duration: "~1.5 years (merged period)"
      value_add: |
        - Factor research with real production deployment
        - Trend-following strategy DEPLOYED TO LIVE TRADING
        - Rigorous backtesting and validation methodology
      key_differentiator: "LIVE DEPLOYMENT - most quant applicants only have backtests"
      interview_framing: |
        "At Baiquan, I researched alpha factors and developed trading strategies.
        One of my trend-following strategies passed validation and was deployed
        to live trading - which gave me invaluable experience with the gap between
        backtest and reality."

    - stage: "Applied ML in Fintech (2017-2019)"
      company: "GLP Technology / Junzheng"
      duration: "2 years"
      value_add: |
        - END-TO-END OWNERSHIP as founding data team member
        - Built credit scoring infrastructure from scratch
        - Full loan lifecycle: origination → monitoring → collections
        - Cross-functional startup experience
      key_differentiator: "FOUNDING MEMBER + PRODUCTION ML"
      interview_framing: |
        "At Junzheng, I was the first hire on the data team. I built our credit
        scoring engine from scratch - data pipelines, feature engineering, model
        deployment, and monitoring. This end-to-end ownership taught me what it
        takes to ship ML to production."

    - stage: "Strategic Transition (2019-2023)"
      type: "Career break / Independent study"
      duration: "4 years"
      value_add: |
        - Personal investing (applied quantitative thinking)
        - Graduate school preparation
        - Deep study in philosophy and epistemology
      interview_framing: |
        "After my fintech experience, I took a strategic pause to pursue graduate
        studies. I spent time on personal investing and deep reading in philosophy,
        which sharpened how I think about uncertainty and decision-making - themes
        that now inform my thesis research."
      note: "Frame as intentional, not as unemployment"

    - stage: "Formal AI Education (2023-2025)"
      institution: "VU Amsterdam"
      duration: "2 years"
      value_add: |
        - Rigorous ML/AI training
        - Diverse project portfolio (NLP, ranking, signal processing, RL)
        - Research capability (thesis on uncertainty quantification)
      interview_framing: |
        "I completed my M.Sc. in AI at VU Amsterdam in Aug 2025, where I worked on
        projects ranging from LLM applications to sensor data classification to
        my thesis on uncertainty quantification in reinforcement learning."

  # 核心差异化因素
  differentiators:
    rare_combinations:
      - "Business acumen (4 years at enterprise) + Technical ML skills"
      - "Credit risk domain expertise + Quant trading experience"
      - "Startup agility (founding member) + Enterprise stability (SOE background)"
      - "Live trading deployment + Production credit risk models"
      - "Signal processing + Deep learning + Business analytics"

    what_this_means: |
      In most interview pools, Fei is likely the ONLY candidate with:
      - Both live trading strategy deployment AND credit risk production models
      - Both business stakeholder experience AND hands-on ML implementation
      - Both quant finance domain knowledge AND formal AI education

    positioning:
      for_quant_roles: "Emphasize Baiquan live deployment + formal ML training"
      for_ds_roles: "Emphasize GLP end-to-end ownership + diverse project portfolio"
      for_senior_roles: "Emphasize full career arc + business acumen + mentorship"
      for_fintech: "Emphasize both credit risk AND quant trading domain expertise"

# =============================================================================
# ENHANCED BULLETS (基于深度审视后的改进版本)
# =============================================================================
enhanced_bullets:

  # 百泉 - 必须强调实盘部署
  baiquan_live_deployment:
    original: "Developed trend-following strategies for index futures; implemented backtesting framework to evaluate strategy performance across different market regimes."
    enhanced: "Developed trend-following strategy for index futures that passed internal validation and was approved for live deployment; independently built backtesting framework to evaluate performance across market regimes."
    why_better: "Adding 'approved for live deployment' is a key differentiator - most candidates only have backtests"
    use_for: "ALL quant roles - this is your secret weapon"

  # GLP - 强调ownership
  glp_ownership:
    original: "Joined as founding data team member at fintech startup; built credit scoring engine from scratch including data pipelines, feature engineering, and model deployment using logistic regression and scorecard methodology."
    enhanced: "As founding data team member, owned end-to-end development of credit scoring infrastructure for consumer lending platform: designed data pipelines, engineered features from application and behavioral data, deployed logistic regression models, and established portfolio monitoring processes."
    why_better: "'Owned' and 'end-to-end' show accountability; structure shows completeness"
    use_for: "Senior roles, ML engineering roles, startup roles"

  # 河南能源 - 强调商业价值
  henan_energy_business:
    missing_bullet: "Developed market forecasting models for commodity pricing; presented analysis and recommendations to senior management that informed procurement strategies and inventory decisions."
    why_add: "Shows forecasting + stakeholder communication + business impact"
    use_for: "Senior roles requiring business acumen, supply chain roles"

  # 带人经验 - 诚实framing
  leadership_mentorship:
    honest_framing: "Provided technical mentorship to junior data analyst; supervised daily reporting and analysis tasks while maintaining individual contributor responsibilities."
    why_works: "True statement that still shows leadership without overclaiming"
    use_for: "Any role asking about management experience"

# =============================================================================
# SELF-ASSESSMENT CORRECTION (视角矫正)
# =============================================================================
perspective_correction:

  negative_self_view:
    - "我跳槽很多"
    - "我有职业空白期"
    - "我只带过1个人"
    - "我技术不够深"
    - "我的职业生涯很碎片化"

  objective_reframe:
    - view: "我跳槽很多"
      reframe: "每一跳都是有意识的升级：传统管理→技术→量化→风控→AI教育"
      evidence: "Consistent upward trajectory in technical sophistication"

    - view: "我有职业空白期"
      reframe: "战略性暂停，为下一阶段做准备（研究生申请、深度学习）"
      evidence: "Emerged from gap with admission to competitive AI program"

    - view: "我只带过1个人"
      reframe: "有管理和指导经验，在创业公司context下是常见的team size"
      evidence: "Having any direct report shows trust and seniority"

    - view: "我技术不够深"
      reframe: "技术广度+领域深度的稀缺组合"
      evidence: "Signal processing + NLP + RL + ranking + credit risk + quant trading"

    - view: "我的职业生涯很碎片化"
      reframe: "完整的转型弧线：从业务到技术到AI，连贯且有意义"
      evidence: "Each stage built on previous, leading to current AI specialization"

  core_truth: |
    你的职业生涯不是负债——它是差异化资产。
    挑战不在于底层经历，而在于如何framing和讲故事。

    大多数候选人是：
    - 纯学术（从未部署过真东西）
    - 纯实践（没有正规ML训练）
    - 单一领域（只懂金融或只懂技术）

    你同时拥有实践部署经验、正规AI训练、以及商业sense。
    这是真正稀缺的。

# =============================================================================
# VERIFICATION LOG
# =============================================================================
verification_log:
  - date: "2025-01-09"
    session_duration: "~4 hours"
    status: "COMPLETE - Ready for production use"

    sections_verified:
      - section: "GLP Technology"
        notes: |
          - Confirmed two companies merged (Junzheng Sep 2017-Dec 2018 + GLP Dec 2018-Aug 2019)
          - Removed fake metrics (15% accuracy, 40% efficiency)
          - Corrected team size (5 people -> 1 direct report)
          - Removed unverified tech (ensemble methods, Spark production)
          - Added verified bullets: founding member, portfolio monitoring, payment integration

      - section: "Independent Investor (2019-2023)"
        notes: |
          - Clarified this was personal trading, not professional quant role
          - Reframed as "Independent Investor" not "Quant Researcher"
          - Can be significantly downplayed or omitted depending on role
          - Key: was preparation period for grad school

      - section: "Baiquan Investment"
        notes: |
          - Merged multiple short stints (中盈基金, 百泉, 汇圆融通) under Baiquan name
          - CRITICAL FINDING: One futures strategy deployed to LIVE TRADING - major differentiator
          - Verified factor research (fundamental, governance, event-driven)
          - Tenure: ~6 months actual at Baiquan, merged period Oct 2015 - May 2017

      - section: "Henan Energy"
        notes: |
          - 4 years - longest work experience
          - Business operations, not technical
          - Strong foundation for stakeholder management and business acumen
          - Value depends on target role (downplay for pure tech, highlight for senior roles)

      - section: "Aoshen + Ele.me"
        notes: |
          - Ele.me ACTUAL duration: Mar-Jul 2015 (4-5 months), NOT Sep 2013-Jul 2015
          - Original resume borrowed time from Henan Energy - background check risk
          - Ele.me is where Python/Tableau/SQL skills started
          - Good brand (Alibaba acquisition)

      - section: "All Projects"
        notes: |
          - All projects verified from M.Sc. coursework
          - Expedia: NDCG@5=0.392 on 4.9M records (verified from report)
          - ML4QS: 65% accuracy, 600+ features, Kalman Filter + FFT
          - NLP: 89.12% UAS, GPT-2 deployment
          - Evolutionary Robotics: NEAT algorithm, MuJoCo, ANOVA analysis
          - Thesis: Completed Aug 2025, uncertainty quantification in deep RL

      - section: "Skills"
        notes: |
          - Python (pandas, numpy): 熟练 ✓
          - SQL: 熟练 (needs review before interview)
          - LightGBM, XGBoost: 用过 (academic projects)
          - PyTorch: 用过 (academic projects)
          - Excel: 曾经精通 (4 years at Henan Energy)
          - Tableau: 会用 (learned at Ele.me)
          - AWS/GCP/Azure: 接触过 (not expert)
          - Docker: 会用 (theory needs review)
          - C/C++/Java: 不能claim

    key_insights:
      career_narrative: |
        Added complete career narrative framework showing intentional progression:
        Business Foundation (2010-2014) → Technical Transition (2014-2015) →
        Quantitative Finance (2015-2017) → Applied ML (2017-2019) →
        Strategic Pause (2019-2023) → Formal AI Education (2023-2025)

      differentiators: |
        - RARE: Both live trading deployment AND production credit risk models
        - RARE: Business acumen (4 years) + hands-on ML + formal AI training
        - RARE: Signal processing + NLP + RL + ranking + multiple domains

      perspective_shift: |
        User's self-view: "跳槽多、空白期、技术不深、碎片化"
        Objective reality: "Progressive transformation, strategic pause, breadth+depth, complete arc"

      enhanced_bullets:
        - Baiquan: Emphasized "approved for live deployment" (key differentiator)
        - GLP: Emphasized "owned end-to-end" and "founding member"
        - Added missing Henan Energy business bullet (forecasting + stakeholder mgmt)
        - Honest leadership framing ("mentored junior analyst" not "led 5-person team")

    risks_identified:
      - Ele.me timeline discrepancy (original resume vs actual) - background check risk
      - Recommendation: Use truthful dates or merge with Aoshen

    interview_prep_needed:
      - SQL complex queries (LeetCode SQL)
      - Statistics formulas (chi-square, etc)
      - Docker theory
      - Cloud deployment process
      - Tableau hands-on practice

    next_steps:
      - Use bullet_library_verified.yaml as single source of truth
      - All resume variants should draw ONLY from verified bullets
      - Career narrative framework ready for cover letters and interviews
      - Review before each interview based on role type (quant/DS/senior)

    verified_by: "Fei Huang"
    verified_with: "Claude Sonnet 4.5"
    confidence: "HIGH - Every bullet personally confirmed and can be defended"

# =============================================================================
# WORK AUTHORIZATION & VISA STATUS
# =============================================================================
# Critical information for job applications
# Last updated: 2026-01-21
# =============================================================================
work_authorization:
  current_status:
    permit_type: "Orientation Year (Zoekjaar)"
    valid_until: "November 2026"
    work_rights: "Full work authorization in the Netherlands"
    notes: "1-year residence permit for graduates of Dutch universities"

  future_requirements:
    visa_type: "Highly Skilled Migrant (Kennismigrant)"
    sponsorship_needed: true
    timeline: "Required from December 2026 onwards"
    employer_requirements: "Employer must be recognized sponsor; salary threshold ~€4,000-5,000/month for ML Engineer roles"

  application_responses:
    standard_answer: |
      I currently hold an Orientation Year residence permit (valid until November 2026)
      following my M.Sc. graduation from VU Amsterdam. I will require sponsorship for a
      Highly Skilled Migrant visa to continue working beyond this period.

    positive_framing: |
      I hold an Orientation Year residence permit (valid until November 2026), which
      provides full work authorization in the Netherlands. I will require Highly Skilled
      Migrant visa sponsorship to continue employment beyond this period.

    concise_version: |
      Current work authorization: Orientation Year permit (valid until November 2026).
      Future sponsorship required: Highly Skilled Migrant visa.

  interview_talking_points:
    - "I have immediate work authorization through November 2026"
    - "HSM visa sponsorship is straightforward for recognized sponsors"
    - "My salary level as ML Engineer meets HSM threshold requirements"
    - "I'm committed to staying in the Netherlands long-term"

  key_facts:
    - "Can start work immediately - no waiting period"
    - "10 months of guaranteed work authorization from Jan 2026"
    - "HSM visa processing typically takes 2-4 weeks"
    - "Employer must be registered as recognized sponsor (most tech companies are)"

# =============================================================================
# SKILL TIERS — Three-level skill classification for resume generation
# =============================================================================
# verified: Skills the candidate demonstrably has
# transferable: Skills that can be claimed when JD mentions them (with basis)
# excluded: Skills the candidate cannot claim
# =============================================================================

skill_tiers:
  verified:
    languages: ["Python (Expert)", "SQL (Expert)", "Bash"]
    data_engineering: ["PySpark", "Delta Lake", "Databricks", "ETL/ELT",
                       "Auto Loader", "Structured Streaming", "Schema Evolution",
                       "Medallion Architecture"]
    cloud: ["AWS (EMR, Glue, S3, Lambda)", "Docker", "Airflow", "CI/CD", "Git"]
    databases: ["PostgreSQL", "MySQL", "Hadoop", "Hive"]
    ml: ["Pandas", "NumPy", "PyTorch", "XGBoost", "LightGBM",
         "scikit-learn", "Statistics", "A/B Testing", "Time-Series Analysis"]
    certifications: ["Databricks Certified Data Engineer Professional (2026)"]
  transferable:
    - skill: "Azure (Data Factory, ADLS)"
      basis: "AWS experience transferable"
      write_when: "JD mentions Azure"
    - skill: "Kafka"
      basis: "Understands message queues, Structured Streaming experience"
      write_when: "JD mentions Kafka or event streaming"
    - skill: "Terraform"
      basis: "IaC concepts, Docker/CI/CD experience"
      write_when: "JD mentions IaC or Terraform"
    - skill: "TypeScript"
      basis: "Python strong, JS concepts understood"
      write_when: "JD mentions TypeScript but not as primary"
    - skill: "Scala"
      basis: "PySpark experience, Spark native language"
      write_when: "JD mentions Scala for Spark"
    - skill: "GCP (BigQuery, Dataflow)"
      basis: "Cloud experience transferable"
      write_when: "JD mentions GCP"
    - skill: "Kubernetes"
      basis: "Docker experience, container orchestration concepts"
      write_when: "JD mentions K8s or Kubernetes"
    - skill: "dbt"
      basis: "SQL expert, data transformation concepts"
      write_when: "JD mentions dbt"
    - skill: "MLflow"
      basis: "Databricks certification covers MLflow"
      write_when: "JD mentions experiment tracking or MLflow"
  excluded: ["C/C++", "Java", "Ruby", "Swift", "Kotlin", ".NET/C#",
             "React", "Angular", "Vue", "Flutter", "PHP"]

# =============================================================================
# ALLOWED SKILL CATEGORIES — Whitelist for resume skill section headers
# =============================================================================
# AI must pick category names from this list ONLY.
# This prevents invented categories like "Fraud & Risk Analytics".
# =============================================================================

allowed_skill_categories:
  - "Languages & Core"
  - "ML/AI Frameworks"
  - "Data Engineering"
  - "Cloud & DevOps"
  - "Databases"
  - "Research Methods"
  - "Risk Analytics"
  - "Quantitative Methods"
  - "Analytics & BI"
  - "NLP & GenAI"

# =============================================================================
# TITLE OPTIONS — Constrained title choices per company
# =============================================================================

title_options:
  glp_technology:
    default: "Data Scientist & Team Lead"
    data_engineer: "Data Engineer & Team Lead"
    data_scientist: "Data Scientist & Team Lead"
    ml_engineer: "ML Engineer & Team Lead"
    risk_analyst: "Credit Risk Analyst & Team Lead"
  baiquan_investment:
    default: "Quantitative Researcher"
    data_engineer: "Quantitative Developer"
    data_scientist: "Quantitative Analyst"
    quant: "Quantitative Researcher"
  eleme:
    default: "Data Analyst"
  henan_energy:
    default: "Business Supervisor"
    data_analyst: "Business Analyst"

# =============================================================================
# BIO CONSTRAINTS — Rules for AI-generated bio text
# =============================================================================

bio_constraints:
  max_years_claim: 6
  years_claim_scope: "working with data systems"
  banned_phrases:
    - "deep expertise"
    - "extensive experience"
    - "proven track record"
    - "cutting-edge"
    - "world-class"
    - "industry-leading"
  extra_rules:
    - "Do NOT describe specific projects in the bio — the Projects section handles that. Bio should summarize overall profile (years, domain, core tech stack, certification)."
  replacements:
    "deep expertise": "hands-on experience"
    "extensive experience": "experience"
    "proven track record": "track record"
    "cutting-edge": "modern"
  required_elements:
    data_engineer: ["Databricks", "data pipeline"]
    ml_engineer: ["M.Sc. in AI", "VU Amsterdam"]
    data_scientist: ["statistical", "machine learning"]
    quant: ["quantitative", "factor"]

# =============================================================================
# BIO BUILDER — Structured bio generation (v2.0)
# =============================================================================
# AI selects component IDs → system assembles verified text deterministically.
# Eliminates fabricated domain claims (e.g., "fraud detection", "graph-based").
# =============================================================================

bio_builder:
  # Opening role titles AI can pick (must match candidate's actual scope)
  allowed_titles:
    - "Data Engineer"
    - "ML Engineer"
    - "Machine Learning Engineer"
    - "Data Scientist"
    - "Quantitative Researcher"
    - "AI Engineer"

  # Domain claims — ONLY these phrases can appear in the bio
  # Each must be supportable by actual bullet library content
  domain_claims:
    credit_risk:
      text: "credit scoring and risk analytics"
      basis: "GLP Technology — credit scoring infrastructure"
    data_pipelines:
      text: "scalable data pipelines and ETL systems"
      basis: "GLP PySpark pipelines + Financial Data Lakehouse"
    quant_research:
      text: "quantitative research and factor modeling"
      basis: "Baiquan Investment — Fama-MacBeth, alpha research"
    anomaly_detection:
      text: "anomaly detection and monitoring systems"
      basis: "GLP — anomaly detection reports, portfolio monitoring"
    ml_deployment:
      text: "ML model development and deployment"
      basis: "GLP — end-to-end credit scoring models"
    data_analytics:
      text: "data analytics and business intelligence"
      basis: "Ele.me — user profiling, A/B testing, Hadoop analytics"
    nlp_llm:
      text: "NLP and large language model applications"
      basis: "NLP projects — sentiment analysis, BERT, text generation"
    deep_rl:
      text: "deep learning and reinforcement learning research"
      basis: "MSc thesis — uncertainty quantification in deep RL"

  # Closer options — optional final sentence
  closer_options:
    eager_company:
      text: "Eager to bring these skills to {company}."
    seeking_impact:
      text: "Looking forward to delivering data-driven impact at {company}."
    null: null  # No closer
